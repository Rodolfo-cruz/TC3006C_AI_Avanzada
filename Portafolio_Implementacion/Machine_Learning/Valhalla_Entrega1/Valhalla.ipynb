{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebf5f41",
   "metadata": {},
   "source": [
    "# Challenge 01: Conversor de Celsius a Valks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cc9cc",
   "metadata": {},
   "source": [
    "**Autor:** Rodolfo Jesús Cruz Rebollar\n",
    "\n",
    "**Matrícula:** A01368326\n",
    "\n",
    "**Grupo:** 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ebef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías para el análisis, manipulación y graficación de datos\n",
    "\n",
    "import pandas as pd # Pandas para análisis y manipulación de datos\n",
    "\n",
    "import numpy as np # numpy para realizar operaciones matemáticas y matriciales\n",
    "\n",
    "import matplotlib.pyplot as plt # Matplotlib para realizar gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23797d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.4720</td>\n",
       "      <td>-139.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.5790</td>\n",
       "      <td>-156.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.3013</td>\n",
       "      <td>73.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.3380</td>\n",
       "      <td>-165.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.2360</td>\n",
       "      <td>-75.835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celsius    Valks\n",
       "0  61.4720 -139.740\n",
       "1  70.5790 -156.600\n",
       "2  -7.3013   73.269\n",
       "3  71.3380 -165.420\n",
       "4  43.2360  -75.835"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar los datos a analizar, leyéndolos del archivo csv\n",
    "\n",
    "celsius_valks = pd.read_csv(\"Valhalla23.csv\")\n",
    "\n",
    "# Mostrar primeros 5 registros del dataframe para asegurar que los datos se hayan importado correctamente\n",
    "\n",
    "celsius_valks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e679550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Celsius  100 non-null    float64\n",
      " 1   Valks    100 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Mostrar características generales de la base de datos\n",
    "\n",
    "celsius_valks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72506b00",
   "metadata": {},
   "source": [
    "Al observar las características generales de la base de datos, se puede notar que en total se tienen 100 registros de datos con 2 columnas, correspondientes a la temperatura en Celsius y Valks respectivamente, además, se aprecia que ambas columnas de información no presentan datos faltantes, ya que todos los datos en ambas son no nulos, motivo por el cual, al no detectar ninguna inconsistencia o error en la estructura de los datos, a continuación se procederá a separar el conjunto principal de datos en 2 subconjuntos, 1 para el entrenamiento del modelo de regresión lineal y otro para ponerlo a prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad58a46",
   "metadata": {},
   "source": [
    "## Creación del conjunto de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533bf74",
   "metadata": {},
   "source": [
    "### Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682543b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>69.0900</td>\n",
       "      <td>-140.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45.5740</td>\n",
       "      <td>-81.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5.1084</td>\n",
       "      <td>35.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-14.6050</td>\n",
       "      <td>91.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64.9130</td>\n",
       "      <td>-142.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "64  69.0900 -140.640\n",
       "20  45.5740  -81.557\n",
       "77   5.1084   35.183\n",
       "91 -14.6050   91.536\n",
       "22  64.9130 -142.020"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librería random que contiene funciones para elegir aleatoriamente elementos de estructuras de datos o generar\n",
    "# valores aleatorios\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "# Generar el conjunto de datos de entrenamiento para el modelo (el 70% de los datos originales se destinará para entrenamiento)\n",
    "\n",
    "train_data = celsius_valks.iloc[rnd.choices(range(celsius_valks.shape[0]), k = round(0.7 * celsius_valks.shape[0])), :]\n",
    "\n",
    "# Mostrar los primeros registros del subconjunto de datos para entrenar el modelo \n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0189379",
   "metadata": {},
   "source": [
    "En términos generales, para generar el subconjunto de datos para entrenar el modelo, lo primero que se realizó fue calcular cuántos registros (filas) tiene el conjunto total de datos con ayuda de la función shape que devuelve una tupla con dos elementos, el primero es la cantidad de filas del dataframe y el segundo es la cantidad de columnas del mismo, por lo que en este caso particular, se toma solamente el primer elemento de la tupla devuelta por la función shape (tiene como índice 0) que coresponde a la cantidad de registros del dataframe original, para luego en base a la cantidad de filas, la función range() genera una secuencia de números enteros desde 0 hasta la cantidad de filas menos 1, por lo que al tener 100 filas, range devolverá una secuencia de enteros desde 0 hasta 99 y dicha secuencia de enteros es recibida por la función choices() del módulo random, la cual escoge aleatoriamente una cierta cantidad de elementos de una lista, especificada en su parámetro k, que en este caso, dicha cantidad k se calcula obteniendo el 70% de la cantidad de filas del dataframe original y luego redondeando dicho resultado al entero más cercano, esto con el objetivo de evitar tener errores de formato numérico al momento de ejecutar el renglón de código en caso de que al calcular el porcentaje de datos para entrenamiento, se obtenga una cantidad con decimales. Además de lo anterior, después de calcular el valor k y definir la secuencia de enteros aleatorios para la función choices(), se procede a que la función choices() elige aleatoriamente k valores enteros de la secuencia definida previamente y envía dicha lista de enteros aleatorios al método iloc para decirle que extraiga las filas especificadas en la lista que recibe dicho método , mismas que se encuentran identificadas por su índice numérico (son los enteros aleatorios obtenidos antes) y a su vez también extraiga todas las columnas que conforman a dichas filas. Es importante recalcar que el método iloc identifica filas y columnas mediante su índice numérico en lugar de sus nombres. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4ab63",
   "metadata": {},
   "source": [
    "### Conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cabfb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.472</td>\n",
       "      <td>-139.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.579</td>\n",
       "      <td>-156.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-10.246</td>\n",
       "      <td>83.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.688</td>\n",
       "      <td>-55.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>75.751</td>\n",
       "      <td>-182.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celsius    Valks\n",
       "0   61.472 -139.740\n",
       "1   70.579 -156.600\n",
       "5  -10.246   83.437\n",
       "7   34.688  -55.108\n",
       "8   75.751 -182.820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El conjunto de prueba estará conformado por todos los datos que no fueron seleccionados de forma aleatoria al momento de \n",
    "# generar el conjunto de entrenamiento\n",
    "\n",
    "# Obtener los índices numéricos de las filas que no fueron seleccionadas al generar el conjunto de entrenamiento\n",
    "\n",
    "# la función lambda en conjunto con la función filter, verifican si cada índice de fila del dataframe completo \n",
    "# se encuentra entre los índices de fila del subconjunto de entrenamiento, de no ser así, se selecciona dicho índice para\n",
    "# incluir la fila correspondiente al mismo, al conjunto de prueba, esto garantiza que el subconjunto de prueba tenga datos que\n",
    "# el modelo aún no haya visto y finalmente se incluyen los índices filtrados en una nueva lista\n",
    "\n",
    "filas_no_elegidas = list(filter(lambda x: x not in train_data.index.values, celsius_valks.index.values))\n",
    "\n",
    "# Extraer las filas que no estén en el subconjunto de entrenamiento con todas sus columnas\n",
    "\n",
    "test_data = celsius_valks.iloc[filas_no_elegidas, :]\n",
    "\n",
    "# Mostrar los primeros registros del conjunto de prueba para asegurar que los datos estén bien estructurados\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726bc0c",
   "metadata": {},
   "source": [
    "**Nota:** la cantidad de registros extraídos para el conjunto de prueba, corresponde al 30% de la cantidad de registros de la base de datos original (30 registros de 100). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ab3e5",
   "metadata": {},
   "source": [
    "## Regresión lineal con gradiente descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02aa054",
   "metadata": {},
   "source": [
    "Para implementar un modelo de regresión lineal con gradiente descendente para resolver la problemática planteada, en primera instancia es necesario tomar en consideración aquellas ecuaciones en las que está basado el funcionamiento del modelo en sí mismo, entre las que se encuentran: la función de costo denotada como J, las funciones correspondientes a las derivadas parciales respecto a $\\theta_{0}$ y $\\theta_{1}$ de dicha función de costo, además de aquellas otras ecuaciones correspondientes  al cálculo tanto del parámetro $\\theta_{0}$ como del parámetro $\\theta_{1}$, mismos que irán actualizándose a medida que el algoritmo necesite una mayor cantidad de iteraciones para encontrar el punto de convergencia, mismo que se define como el momento en el cual la función de costo J alcanza su mínimo valor posible para los datos en cuestión.\n",
    "\n",
    "Debido a lo anterior, a continuación se mencionan las ecuaciones que se utilizarán para la implementación efectiva del modelo de regresión lineal:\n",
    "\n",
    "**Función de costo J:**\n",
    "\n",
    "$J_{\\theta} = \\frac{1}{2n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})^{2}}$\n",
    "\n",
    "Donde $h_{\\theta}(x_{i}) = \\theta_{0} + \\theta_{1}x_{i}$\n",
    "\n",
    "**Derivadas parciales de J:**\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\theta_{0}} = \\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})}$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\theta_{1}} = \\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})x_{i}}$\n",
    "\n",
    "**Cálculo de $\\theta_{0}$ y $\\theta_{1}$ mediante gradiente descendente:**\n",
    "\n",
    "$\\theta_{0} = \\theta_{0} - \\alpha\\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})}$\n",
    "\n",
    "$\\theta_{1} = \\theta_{1} - \\alpha\\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})x_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573f571",
   "metadata": {},
   "source": [
    "Para definir la función del método de gradiente descendente a continuación, los parámetros $\\theta_{0}$ y $\\theta_{1}$ tendrán ambos un valor inicial de 1, esto debido principalmente a que al asignar inicialmente valores unitarios a dichos parámetros del modelo, se comienza el algoritmo con un modelo básico en el sentido de que al comienzo de todo el proceso iterativo, al no saber todavía con certeza cuáles serán los valores adecuados para los parámetros del modelo, el hecho de asignar un valor unitario a éstos garantiza que al iniciar el proceso, tanto la ordenada al origen como el coeficiente de la variable x tengan una cierta contribución, peso o influencia en las primeras predicciones derivadas del algoritmo, esto mientras se calculan nuevos valores para los parámetros del modelo a medida que avanzan las iteraciones del algoritmo, por lo que después de la primera iteración del algoritmo, los valores unitarios iniciales se reemplazarán por los nuevos valores calculados en dicha iteración y así sucesivamente, por lo cual, se seleccionaron valores iniciales de 1 para los $\\theta$ solamente para comenzar el algoritmo con un \"modelo por default\". \n",
    "\n",
    "Además de lo anterior, para implementar el modelo de regresión lineal con gradiente descendente se necesita definir un parámetro adicional llamado $\\alpha$ que será la tasa de aprendizaje del modelo (rapidez con la que aprende el modelo a identificar patrones en los datos) y otro parámetro conocido como $\\epsilon$ que se refiere al límite máximo de error permitido para el modelo, es decir, el criterio que se utilizará para definir si la función de costo J converge, por lo que en caso de que llegue un momento en el cual el valor de ambas derivadas de la función J sean inferiores al valor de $\\epsilon$, se alcanzará la convergencia del algoritmo y en ese punto terminará todo el proceso iterativo, es decir, terminará el algoritmo en sí. Por otro lado, utilizaremos una tasa de aprendizaje $\\alpha = 0.003$ debido a que es un valor que no es excesivamente pequeño pero tampoco muy grande, esto en el sentido de que garantizará que el algoritmo aprenda a un ritmo moderado, es decir, que no sea excesivamente rápido o lento, dado que en caso de que dicho valor $\\alpha$ sea muy pequeño, se corre el riesgo de que el algoritmo al aprender a un ritmo muy lento, necesite demasiadas iteraciones, lo cual implicaría que el algoritmo demore mucho tiempo en proporcionar una respuesta a tal punto de que dicha respuesta al no llegar a tiempo, retrase los procesos por ejemplo de alguna empresa, o industria y perjudicando su capacidad para operar de forma eficente, por lo que en resumen un valor de $\\alpha$ muy pequeño puede provocar que el algoritmo se vuelva prácticamente ineficiente sobretodo en situaciones en las que se requiere una respuesta a la brevedad posible. Sin embargo, si se elige un valor de $\\alpha$ grande, se corre el riesgo de que durante el proceso iterativo del algoritmo, se pase por alto el punto mínimo en el que la función J alcanza un valor inferior al $\\epsilon$, provocando que al final de todo el algoritmo, el modelo de regresión lineal resultante no sea el que mejor se ajuste a los datos en cuestión, por lo que en pocas palabras, un $\\alpha$ grande reduciría la capacidad del algoritmo para encontrar el mejor modelo posible para los datos además de que el modelo derivado del mismo no arrojaría predicciones de temperatura suficientemente confiables, lo que podría ocasionar que en vez de resolver la crisis del calentamiento global mencionada en el challenge 1, el planeta Tierra se podría calentar o enfriar en exceso y por consiguiente afectar negativamente a la vida en la Tierra.\n",
    "\n",
    "Adicionalmente, también cabe mencionar que en cuanto al parámetro de error máximo $\\epsilon$, éste mismo tendrá un valor de 0.01 para el problema en cuestión, ya que entre más pequeño sea el valor de éste parámetro, el algoritmo buscará obtener un modelo en su gran mayoría confiable en cuanto a las predicciones que arroje, sin embargo, $\\epsilon$ tampoco puede ser 0, debido a que por la propia naturaleza de los datos involucrados, tampoco resulta posible encontrar algún modelo que prediga correctamente la temperatura en Valks para absolutamente todos los datos en grados celsius, por lo que 0 no es un valor adecuado para el parámetro $\\epsilon$. No obstante si en cambio el valor de $\\epsilon$ es grande, tampoco es recomendable dado que estaríamos permitiendo que el modelo resultante del algoritmo tenga mayor margen de error, lo cual puede causar que las predicciones derivadas del mismo no tengan un grado de confiabilidad suficiente para convertir grados celsius a valks, lo que de nuevo puede llevar a una toma de decisiones errónea y nuevamente eso agravaría la crisis del cambio climático que se desea resolver en la problemática abordada, por lo que 0.01 resulta ser una elección que no es un valor excesivamente pequeño pero tampoco muy grande, por lo que resulta adecuado como valor para el parámetro de error máximo admisible $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8881f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una serie de pandas que contenga ambos valores de theta a lo largo del algoritmo\n",
    "\n",
    "# Incialmente ambos hiperparámetros theta tendrán un valor de 1\n",
    "\n",
    "theta = pd.Series([1, 1], index = [\"theta0\", \"theta1\"])\n",
    "\n",
    "# Definir la tasa de aprendizaje alpha\n",
    "\n",
    "alpha = 0.003\n",
    "\n",
    "# Definir la máxima proporción permitida de error épsilon\n",
    "\n",
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea158e9d",
   "metadata": {},
   "source": [
    "### Función de hipótesis h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc08f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer una función anónima lambda para evaluar los datos de la variable independiente (Celsius) en la función de hipótesis\n",
    "\n",
    "h = lambda x: theta[\"theta0\"] + theta[\"theta1\"] * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84164d20",
   "metadata": {},
   "source": [
    "### Función de costo J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a95f23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de costo que recibe 2 parámetros de entrada: número de registros del dataframe y datos de entrenamiento\n",
    "\n",
    "def J_function(n, data):\n",
    "    \n",
    "    # Calcular el valor de la función J para los datos: primero los datos de temperatura en grados Celsius se multiplican por \n",
    "    # el valor del parámetro theta 1 y después a dichos resultados se les suma el valor de theta 0, para después a dichos \n",
    "    # resultdos restarles los datos de temperatura en Valks, elevar los valores resultantes al cuadrado, sumarlos y finalmente\n",
    "    # multiplicar el resultado de la suma por 1/2n\n",
    "    \n",
    "    J  = (1 / (2 * n)) * (((h(data[\"Celsius\"]) - data[\"Valks\"]) ** 2).sum())\n",
    "    \n",
    "    # Devolver el valor de la función J\n",
    "    \n",
    "    return J\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830a1e5",
   "metadata": {},
   "source": [
    "### Derivadas parciales de J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1391cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular derivada parcial de J respecto a theta0 que recibe como parámetros de entrada: número de datos de entre-\n",
    "# namiento (n) y los datos de entrenamiento (data)\n",
    "\n",
    "def J_partial_theta0(n, data):\n",
    "    \n",
    "    # Calcular la derivada de J respecto a theta0, primero calculando los residuos del modelo \n",
    "    # (Valks predichos con función h menos Valks reales), luego sumando los residuos obtenidos por muestra y\n",
    "    # por último, multiplicando dicha suma por 1/n\n",
    "    \n",
    "    derivada_theta_0 = (1 / n) * ((h(data[\"Celsius\"]) - data[\"Valks\"]).sum())\n",
    "    \n",
    "    # Devolver el valor de la derivada de J respecto a theta0\n",
    "    \n",
    "    return derivada_theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05ad0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que calcula el valor de la derivada de J respecto a theta1, recibiendo como parámetros de entrada: cantidad de datos\n",
    "# de entrenamiento (n) y los datos de entrenamiento en sí (data)\n",
    "\n",
    "def J_partial_theta1(n, data):\n",
    "    \n",
    "    # Calcular valor de la derivada de J respecto a theta1, primero calculando para cada registro de datos, la diferencia entre\n",
    "    # los Valks predichos con función h menos los Valks reales, después multiplicando las diferencias por los datos de celsius\n",
    "    # luego sumando los productos obtenidos y finalmente multiplicando el resultado de la suma por 1/n\n",
    "    \n",
    "    derivada_theta_1 = (1 / n) * (((h(data[\"Celsius\"]) - data[\"Valks\"]) * data[\"Celsius\"]).sum())\n",
    "    \n",
    "    # Devolver el valor de la derivada de J respecto a theta1\n",
    "    \n",
    "    return derivada_theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4df50",
   "metadata": {},
   "source": [
    "### Función de gradiente descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79eddd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular los parámetros adecuados para el modelo de regresión lineal mediante el método del gradiente descendente\n",
    "\n",
    "\"\"\"La función recibe 4 argumentos de entrada: datos para entrenamiento, tasa de aprendizaje alpha, límite máximo de error \n",
    "   permitido para definir la convegencia del algoritmo y el número máximo de iteraciones para generar el modelo (100).\"\"\"\n",
    "\n",
    "# El parámetro i = 500 indica que se entrenará el modelo con 500 iteraciones (más del mínimo solicitado de 100 iteraciones)\n",
    "\n",
    "def gradiente_descendente(data, alpha, epsilon, i = 500):\n",
    "    \n",
    "    # Longitud de conjunto de datos para entrenamiento\n",
    "    \n",
    "    n = len(data) \n",
    "    \n",
    "    # Definir variable booleana convergencia que indicará si se alcanza o no la convergencia del algoritmo\n",
    "    \n",
    "    convergencia = False # se inicializa en false dado que aún no se encuentra ningún modelo para los datos\n",
    "    \n",
    "    # Inicializar en 1 la variable k que contará el número de iteraciones del ciclo while\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    # Ejecutar el algoritmo mientras que no se alcance el máximo de iteraciones y no se encuentre convergencia\n",
    "    # Esto con el propósito de que en caso de que el algoritmo converga, entonces se detenga el algoritmo aunque no se\n",
    "    # alcance el número máximo de iteraciones establecido. Además, el ciclo también se detendrá en caso de que a pesar de \n",
    "    # que el algoritmo no converga, se llegue a la cantidad máxima establecida de iteraciones, lo cual será solamente un paro\n",
    "    # de emergencia en el caso de que no suceda la convergencia y para que el algoritmo no itere infinitamente, sino que arroje\n",
    "    # una respuesta en el máximo de iteraciones establecido aunque no sea el modelo que mejor se ajuste a los datos\n",
    "    \n",
    "    while (k <= i) & (convergencia == False):\n",
    "        \n",
    "        # Calcular el valor de J (función de costo)\n",
    "        \n",
    "        J = J_function(n, data)\n",
    "        \n",
    "        # Calcular el valor de la derivada de J respecto a theta0\n",
    "        \n",
    "        deriv_theta_0 = J_partial_theta0(n, data)\n",
    "        \n",
    "        # Calcular el valor de la derivada de J respecto a theta1\n",
    "        \n",
    "        deriv_theta_1 = J_partial_theta1(n, data)\n",
    "        \n",
    "        # Calcular el valor actualizado del hiperparámetro theta0\n",
    "        \n",
    "        theta[\"theta0\"] -= alpha * deriv_theta_0\n",
    "        \n",
    "        # Calcular el valor actualizado del hiperparámetro theta1\n",
    "        \n",
    "        theta[\"theta1\"] -= alpha * deriv_theta_1\n",
    "        \n",
    "        # Verificar si el valor de las derivadas es inferior al límite máximo epsilon\n",
    "        \n",
    "        if (deriv_theta_0 < epsilon) & (deriv_theta_1 < epsilon):\n",
    "            \n",
    "            # De ser así, se habrá encontrado la convergencia del algoritmo para los datos\n",
    "            \n",
    "            convergencia = True\n",
    "        \n",
    "        # Actualizar el valor del número de iteración k\n",
    "        \n",
    "        k += 1\n",
    "        \n",
    "    # Desplegar el modelo de regresión lineal calculado para los datos\n",
    "    \n",
    "    print(f'El modelo para los datos es: Valks = {theta[\"theta0\"]} + {theta[\"theta1\"]} * Celsius')\n",
    "    \n",
    "    # Mostrar el valor óptimo de la función de costo J\n",
    "    \n",
    "    print(f'Valor J para el conjunto de datos: J = {J}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b77b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo para los datos es: Valks = 2.4247347523859704 + 78.20939979482725 * Celsius\n",
      "Valor J para el conjunto de datos: J = 253678.71585944213\n"
     ]
    }
   ],
   "source": [
    "# Crear y entrenar el modelo de regresión lineal con gradiente descendente\n",
    "\n",
    "# El modelo se crea en base a los datos de entrenamiento, por lo que se envía el dataset de entrenamiento como argumento a la\n",
    "# función de gradiente_descendente() además del valor de alpha y de epsilon\n",
    "\n",
    "# Nota: el resto de los argumentos ya no es necesario enviarlos porque ya tienen asignado un valor por defecto\n",
    "\n",
    "# Además, el modelo se entrenará con 500 iteraciones como se establece anteriormente\n",
    "\n",
    "gradiente_descendente(train_data, alpha, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210ceeb",
   "metadata": {},
   "source": [
    "## Prueba del modelo implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fbc1338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo para los datos es: Valks = 32.945394258120174 + 1847.6431462425403 * Celsius\n",
      "Valor J para el conjunto de datos: J = 143718546.57103246\n"
     ]
    }
   ],
   "source": [
    "# Calcular el modelo de regresión lineal que se ajuste a los datos del subconjunto de prueba\n",
    "\n",
    "gradiente_descendente(test_data, alpha, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2aec800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     113611.264880\n",
       "1     130437.751013\n",
       "5     -18898.006282\n",
       "7      64123.990851\n",
       "8     139993.761365\n",
       "9     141357.322007\n",
       "12    139930.941498\n",
       "18    109452.220158\n",
       "19    140359.594708\n",
       "23    135648.104685\n",
       "Name: Celsius, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular las predicciones para los Valks a partir de los celsius en base al modelo arrojado para los datos de prueba\n",
    "\n",
    "\"\"\"Nuevamente usar la función de hipótesis h para realizar las predicciones (los coeficientes calculados por el algoritmo se \n",
    "   encuentran en la lista original de valores theta\"\"\"\n",
    "\n",
    "pred_valks = h(test_data[\"Celsius\"])\n",
    "\n",
    "# Mostrar las primeras 10 predicciones en Valks para los datos de prueba\n",
    "\n",
    "pred_valks.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34250aec",
   "metadata": {},
   "source": [
    "### Graficar los Valks reales vs los predichos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c6d53be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxdUlEQVR4nO3deZxcVZ3//9ebTggJO0lUSMii4JIE0iEhyBcJSxAiIgjCEAyCCgYS+InjV0SM85XRLzP4HUeW0QBBZG0NAiMwGpRVBJUlLCICQoAkNEQISYCEsGT5/P64p5LqTlV1dXctvbyfj0c9uurce0+deyupT53lnqOIwMzMrBY2q3cBzMys93DQMTOzmnHQMTOzmnHQMTOzmnHQMTOzmnHQMTOzmnHQsR5B0iWS/qVA+j9J+p2kfh3M9xxJ16bnwyStktTQ2fK28Z77S2qu5nu0970kfVvST2tRplqSFJJ2Sc+vlPR/612mns5Bx9okaaGkt9MX7j/Sf86t6l2ufBFxakR8Pz9N0jjgJODIiHi3Au+xOCK2ioh1nc2rkpT5qqQnJL0lqVnS9ZJ2q9R7RMS/RcTJlcqvUtIPiu8VSD8i/VvtU49yWXEOOlauz0TEVkAjMA44u9JvUOkviIh4NCIOiYjVlcy3C7oQOAP4KrAD8GHgJuDTdSxTrVwJfEGSWqV/AWiKiLW1L5KV4qBj7RIR/wB+RxZ8AJD0cUl/kvS6pL9I2j9v20hJf5C0UtIdkn6S11w1IjVvnCRpMXBXSv+ypKckrUi/ZIendEk6X9Krkt6Q9LikMWlbi6YRSV+RtEDSckm3SNopb1tIOlXSs+k9flLgS2sTeeXtk17/XtL3Jf0xnd9tkgaVeV2+lM5xpaTnJZ3Svk9iQz67AqcBx0XEXRHxbkSsjoimiDgv7dNP0g8lLZb0SmqK7F8kv7MkvZTK9XdJk1N6fjPjJk1yqTZ8UHo+UdJ8SW+m9/tRkfd6StJhea/7SHpN0h6StpB0raRl6fo9JOn9BbK5iSzQ7puXz/bAYcDVqSx/TnkskfRjSZuXcV23lnS3pIvSv7tDJT2ZrstLkr7RVh5WmIOOtYukocCngAXp9RDgN8D/JfvP/w3gRkmD0yE/Bx4EBgLnkP0CbW0/4GPAIZI+C3wbOAoYDNwL/CLtdzAwieyX/HbAscCyAmU8EPh34J+AHYFFwNxWux0G7AmMTfsdUuYlaO3zwJeA9wGbk51/Odfl1VSGbdLx50vao9AbSJotaXaR958MNEfEgyXK+AOya9YI7AIMAf5Pgff5CHA6sGdEbE12TRaWyLeYC4ELI2Ib4EPAL4vs9wvguLzXhwCvRcQjwInAtsDOZP92TgXebp1BRLyd8j8hL/mfgKcj4i/AOuCfgUHA3mTXa2apwksaCNwJ/DEivhrZXGGXA6ek6zKG9APJ2s9Bx8p1k6SVwItkX5jfTenHA/MiYl5ErI+I24H5wKGShpF9sf+fiHgvIu4DbimQ9zkR8Vb6AjkF+PeIeCo1jfwb0JhqO2uArYGPAkr7LCmQ3zTgZxHxSOrLORvYW9KIvH3Oi4jXI2IxcDd5Nbd2uiIinsn78svlU/S6AETEbyLiucjcA9xG3q/1fBExMyKKfVEOBApdAyCrHQJfAf45IpZHxEqyazq1wO7rgH7AKEl9I2JhRDxX+vQLWgPsImlQRKyKiPuL7Pdz4HBJA9Lrz6e0XB4DgV0iYl1EPBwRbxbJ5yrgmLza2wkpjXTc/RGxNiIWApeS/cgpZifgHuD6iPhOq3MaJWmbiFiRAqN1gIOOleuz6Vfe/mRf+rlmpOFk/+Ffzz2AT5DVMHYClrfqU3mxQN75acOBC/PyWg4IGBIRdwE/Bn4CvCJpjqRtCuS3E1ntBoCIWEVWIxqSt88/8p6vBjo6MKJYPqWuC5I+Jen+1Pz3OlkwGkT7LcvlWcRgYADwcF45fpvSW4iIBcDXyGqkr0qam98s2Q4nkdWsnk7NYocV2im931PAZ1LgOZyNQecasmbcuZJelvT/JPUtks99wFLgCEkfJPuh83MASR+W9GtlgwreJAu4pa7zp4H+wCWt0j9H9hktknSPpL3buAZWhIOOtUv6VX4l8MOU9CJwTURsl/fYMvUnLAF2yPslC1lzySbZ5j1/kawZIz+//hHxp/T+F0XEeGA02RfbmQXye5nsSx8ASVuS/Wp+qSPn3EFFr4uy4ds3kl3D90fEdsA8suDaXncCQyVNKLL9NbJmqdF55dg2DQrZRET8PCI+QXb9gqxprrW3yAIZAMqGkG8IYhHxbEQcR9bk+APghvQZFJJrYjsCeDIFIiJiTUT8a0SMAv4XWVPkCUXyALg6bf8CcFtEvJLSLwaeBnZNzX3fpvR1vowsKM/LL3NEPBQRR6RzuoniTYbWBgcd64gLgE9KagSuJfuleoikhtQBvL+koRGxiKxJ6RxJm6dfh59pI+9LgLMljQaQtK2kY9LzPSXtlX7xvgW8Q9Yk1NrPgS9Jakxf8P8GPJCaV2ql6HUh6/vpR/brfK2kT5H1V7VbRDwLzAZ+kfLfPL3XVEnfioj1ZF+k50t6H2T9TZI26cOS9BFJB6Zr9g5ZsCp0fZ8BtpD06fRZfCedTy6f4yUNTu/9ekouNsx8bjr3GWys5SDpAEm7pYD2JlnzVqmh6lcDB5E1JV6Vl751On6VpI+m92nL6cDfgV9L6p+u6TRJ20bEmpRflxo235046Fi7RcRSsv/k/xIRL5L9Sv022Zfoi2S1j9y/rWlkHbjLyDrVrwOK3jMTEb8i+3U8NzWHPEE2cAGyTvfLgBVkzWfL2Fjjys/jTuBfyGoTS8g6swv1YVRNqeuS+lW+SvZreQVZX0ahvi5gw42vrZt78n2Vjc2OrwPPAUcC/5O2n0U28OP+dE3vAD5SIJ9+wHlktaN/kP2q/3aBc3uDrDP+p2S1x7eA/NFsU4C/SVpFNqhgakS8U6jgqU/uz2S1mevyNn0AuIHsC/4psn6Wa4tdgPSD4k/AlrS8lt8gu74ryf7tXLfJwZvmFcB0ss/sZmALshrUwnT9TiXrs7MOUHgRN6shSdeRjSz6bps7m1mP45qOVVVqEvuQpM0kTSH79X9TnYtlZnXiKSKs2j4A/DdZR34zMCMiHq1vkcysXty8ZmZmNePmNTMzqxk3r7UyaNCgGDFiRL2LYWbWrTz88MOvRcQmNx235qDTyogRI5g/f369i2Fm1q1IWtT2Xm5eMzOzGnLQMTOzmnHQMTOzmnGfThnWrFlDc3Mz77xTcCYPq5EtttiCoUOH0rdvwcmGzawbcNApQ3NzM1tvvTUjRoxAbS8waVUQESxbtozm5mZGjhxZ7+KYWQe5ea0M77zzDgMHDnTAqSNJDBw40LVNs2poaoIRI2CzzbK/TU1VeyvXdMrkgFN//gzMKmzmTLj0Uli/fmPaokUwfXr2fNq0ir+lazpmZr3RzJlw8cUtA07O6tUwa1ZV3tZBp5toaGigsbGRMWPG8JnPfIbXX3+9Q/lceeWVnH766ZUtnJl1P5eUWqIJWLy4Km/roNNN9O/fn8cee4wnnniCHXbYgZ/85Cf1LpKZdWdtTfY8bFhV3tZBpwqq3Se3995789JLLwHw3HPPMWXKFMaPH8++++7L008/DcD//M//sNdeezFu3DgOOuggXnnllU3yWbp0KZ/73OfYc8892XPPPfnjH/8IwD333ENjYyONjY2MGzeOlStXVvYEzKxrGzAAzj23OnlHhB95j/Hjx0drTz755CZpxVx7bcSAARHZz4jsMWBAlt4ZW265ZURErF27No4++ui49dZbIyLiwAMPjGeeeSYiIu6///444IADIiJi+fLlsX79+oiIuOyyy+LrX/96RERcccUVcdppp0VExHHHHRf33ntvREQsWrQoPvrRj0ZExGGHHRb33XdfRESsXLky1qxZ07nCV1B7PgszKyH/S6r1owNfWMD8KOM71qPXKmzWrKwPLl+uT64zA0HefvttGhsbWbhwIePHj+eTn/wkq1at4k9/+hPHHHPMhv3effddILu36Nhjj2XJkiW89957Be9tueOOO3jyySc3vH7zzTdZuXIl++yzD1//+teZNm0aRx11FEOHDu14wc2sfpqasi+fxYuz5rJzz934RTRjRjaQoLUZM6oyam2DciJTb3p0tqYjFf7hIJWdRUG5ms7rr78en/jEJ+LCCy+MN954Iz7wgQ8U3H+//faLm2++OSIi7r777thvv/0iomVNZ+DAgbF69eqCxz/++ONx3nnnxZAhQ+Kpp57qXOEryDUdszKV0+wyY0ZEQ0O2raEhe91BlFnTcZ9OhRXre6tUn9y2227LRRddxA9/+EP69+/PyJEjuf7664HsB8Rf/vIXAN544w2GDBkCwFVXXVUwr4MPPpgf//jHG14/9thjQNZPtNtuu3HWWWcxYcKEDf1EZtaNlGp2yZk9G9auzULS2rXZ6ypz0Kmwc8/N+uDyVbpPbty4cYwdO5a5c+fS1NTE5ZdfztixYxk9ejQ333wzAOeccw7HHHMM++67L4MGDSqYz0UXXcT8+fPZfffdGTVqFJekIZQXXHABY8aMYezYsfTv359PfepTlSu8mVVeodFLxYY8V2kodLmU1YosZ8KECdF6EbennnqKj33sY2XnUaoZ1TqnvZ+FWY/X1JTNIJBfqxkwAPr3h2XLNt1/+HBYuLDixZD0cERMaGs/DySogmnTHGTMrEaKNaP1758Fn9bBqFpDocvk5jUzs+4o16S2qMgq0cuXw5w5Wc1Gyv7OmVP3X8Su6ZiZdTeFmtRaGzasSza7uKZjZtbdFGpSy9cFmtGKcdAxM+tuSo1A6yLNaMW4ec3MrLsZNqxwX06VRqZVkms63UT+0gbHHHMMq0tVrdvwxS9+kRtuuAGAk08+ucVUOOU69NBDO7y8gpl1Ui1uCKySqgcdST+T9KqkJ/LS/kPS05Iel/QrSdul9BGS3pb0WHpcknfMeEl/lbRA0kVKy0hK6ifpupT+gKQRececKOnZ9Dix2udaTflLG2y++eYbbuTMWbduXYfy/elPf8qoUaPafdy8efPYbrvtOvSeZtZJ06Z1yZFp5ahFTedKYEqrtNuBMRGxO/AMcHbetuciojE9Ts1LvxiYDuyaHrk8TwJWRMQuwPnADwAk7QB8F9gLmAh8V9L2lTyxoqq8tsG+++7LggUL+P3vf88BBxzA5z//eXbbbTfWrVvHmWeeyZ577snuu+/OpZdeCmTT45x++umMGjWKT3/607z66qsb8tp///3J3Qz729/+lj322IOxY8cyefJkAFatWsWXvvQldtttN3bffXduvPFGAEaMGMFrr70GwI9+9CPGjBnDmDFjuOCCCwBYuHAhH/vYx/jKV77C6NGjOfjgg3n77beB4ssxXH/99RtmQpg0aVJFr5lZjzNtWtaUtn599rcbBBygNhN+AiOAJ4psOxJoKrUfsCPwdN7r44BL0/PfAXun532A1wDl75O2XQoc11ZZOzvhZ7XWNshN+LlmzZo4/PDDY/bs2XH33XfHgAED4vnnn4+IiEsvvTS+//3vR0TEO++8E+PHj4/nn38+brzxxjjooINi7dq18dJLL8W2224b119/fURkE4M+9NBD8eqrr8bQoUM35LVs2bKIiPjmN78ZZ5xxxoZyLF++PCIihg8fHkuXLo358+fHmDFjYtWqVbFy5coYNWpUPPLII/HCCy9EQ0NDPProoxERccwxx8Q111wTEcWXYxgzZkw0NzdHRMSKFSsKXgdP+GnWNdGNJvz8MnBr3uuRkh6VdI+kfVPaEKA5b5/mlJbb9iJARKwF3gAG5qcXOKYFSdMlzZc0f+nSpZ07m3Im2euA3NIGEyZMYNiwYZx00kkATJw4ccOyBbfddhtXX301jY2N7LXXXixbtoxnn32WP/zhDxx33HE0NDSw0047ceCBB26S//3338+kSZM25LXDDjsA2fIHp5122ob9tt++ZWXxvvvu48gjj2TLLbdkq6224qijjuLee+8FYOTIkTQ2NgIwfvx4Fi5c2GI5hsbGRk455RSWLFkCwD777MMXv/hFLrvssg43F5pZ11bX0WuSZgFrgVz70xJgWEQskzQeuEnSaLKaS2u5SeOKbSt1TMvEiDnAHMjmXiv/DAqo0iR7uT6d1rbccssNzyOC//qv/+KQQw5psc+8efNIXWBFRUTBfYql528vpl+/fhueNzQ08Pbbb7N+/Xq22267gudyySWX8MADD/Cb3/yGxsZGHnvsMQYOHFiy3GbWvdStppM69g8DpqWqGRHxbkQsS88fBp4DPkxWS8lfSWwo8HJ63gzsnPLsA2wLLM9PL3BM9VR7bYMSDjnkEC6++GLWrFkDwDPPPMNbb73FpEmTmDt3LuvWrWPJkiXcfffdmxy79957c8899/DCCy8AsHz5cmDT5Q9WrFjR4rhJkyZx0003sXr1at566y1+9atfse+++1LMNttsU3Q5hueee4699tqL733vewwaNIgXX3yxaD5m1j3VJehImgKcBRweEavz0gdLakjPP0g2YOD5iFgCrJT08TRq7QTg5nTYLUBuZNrRwF0piP0OOFjS9mkAwcEprbrqOJTx5JNPZtSoUeyxxx6MGTOGU045hbVr13LkkUey6667sttuuzFjxgz222+/TY4dPHgwc+bM4aijjmLs2LEce+yxAHznO99hxYoVGzr4WwesPfbYgy9+8YtMnDiRvfbai5NPPplx48aVLGex5RjOPPNMdtttN8aMGcOkSZMYO3Zsha6MmXUZ5XT8dOYB/IKs2WwNWe3jJGABWX/LY+lxSdr3c8DfgL8AjwCfyctnAvAEWe3nx2xclmEL4PqU54PAB/OO+XJKXwB8qZzydnogQUQ2aGD48Gy50OHDOz2IwDbyQAKzrokyBxJ4PZ1WKrGejlWPPwuzrqnc9XS6wug1MzPrJRx0yuQaYf35M7Buo8o3iHdnDjpl2GKLLVi2bJm/9OooIli2bBlbbLFFvYtiVlpurZtFi7Lbwxctyl478AC4T6e1Qn06a9asobm5mXfeeadOpTLIgv/QoUPp27dvvYtiVlyx1Ty7wQzQnVFun46XNihD3759N9ypb2bWQlNTNuPI4sXFlxyATt8g3lM46JiZdVTrZaMXLcpmfS7UglSDG8S7A/fpmJl1VKG5FiOywJOvm6x1UwsOOmZmHVWsySyiW651UwsOOmZm5Sg0DLpYk1lu0EB3W+umBhx0zMzaMnMmfOELmw6DPvTQbrtsdL046JiZldLUBJdcsunggNWrYd68brtsdL34Pp1WCt2nY2a9WLH7biALNOvX17Q4XZXnXjMzq4RS99d4GHS7OeiYmZVSLLBI7rvpAAcdM7NSCi3MKMGpp7rvpgMcdMysd2trRuhp0zYdLHDNNTB7dj1K2+15Ghwz631y86W1nrYmNxQaWtZipk1zraZCXNMxs94lf+kBKDwUetas2perl3DQMbPepdB8aa15RuiqcdAxs96lnIDiodBVU/WgI+lnkl6V9ERe2g6Sbpf0bPq7fd62syUtkPR3SYfkpY+X9Ne07SIpm8ZVUj9J16X0BySNyDvmxPQez0o6sdrnambdQFsBxdPYVFUtajpXAlNapX0LuDMidgXuTK+RNAqYCoxOx8yW1JCOuRiYDuyaHrk8TwJWRMQuwPnAD1JeOwDfBfYCJgLfzQ9uZtZLFRsCDZ7GpgaqHnQi4g/A8lbJRwBXpedXAZ/NS58bEe9GxAvAAmCipB2BbSLiz5HN23N1q2Nyed0ATE61oEOA2yNieUSsAG5n0+BnZr1NsSHQEZ4RugbqNWT6/RGxBCAilkh6X0ofAtyft19zSluTnrdOzx3zYsprraQ3gIH56QWOaUHSdLJaFMPclmvW83kIdN10tYEEKpAWJdI7ekzLxIg5ETEhIiYMHjy4rIKamVn71SvovJKazEh/X03pzcDOefsNBV5O6UMLpLc4RlIfYFuy5rxieZmZWZ3UK+jcAuRGk50I3JyXPjWNSBtJNmDgwdQUt1LSx1N/zQmtjsnldTRwV+r3+R1wsKTt0wCCg1OamZnVSdX7dCT9AtgfGCSpmWxE2XnALyWdBCwGjgGIiL9J+iXwJLAWOC0i1qWsZpCNhOsP3JoeAJcD10haQFbDmZryWi7p+8BDab/vRUTrAQ1mZlZDXsStFS/iZmbWfl7Ezcx6lrZmg7ZuwbNMm1nXN3MmXHJJ27NBW5fnmo6ZdW1NTS0DTo5ng+6WHHTMrGubNWvTgJPj2aC7HQcdM+vaSgUWzyDS7TjomFnXViywSJ4Nuhty0DGzrq3YrNCnnupBBN2Qg46ZdW3FZoWePbveJbMO8JBpM+v6PCt0j+GajpnVlm/y7NVc0zGz2mlqym7qXL06e+2bPHsd13TMrPpytZvjj98YcHJ8k2ev4pqOmVVX69pNIb7Js9dwTcfMqmvWrNIBB3yTZy/ioGNm1dVWLWbAAN/k2Ys46JhZdZWqxQwfnt2D40EEvYaDjplVV6EZBQYMgGuvhYULHXB6GQcdM6uuQjMKuHbTa3n0mplVn2cUsKRuNR1JH5H0WN7jTUlfk3SOpJfy0g/NO+ZsSQsk/V3SIXnp4yX9NW27SJJSej9J16X0BySNqMOpmplZUregExF/j4jGiGgExgOrgV+lzefntkXEPABJo4CpwGhgCjBbUkPa/2JgOrBrekxJ6ScBKyJiF+B84AfVPzMzMyumq/TpTAaei4hFJfY5ApgbEe9GxAvAAmCipB2BbSLizxERwNXAZ/OOuSo9vwGYnKsFmZlZ7XWVoDMV+EXe69MlPS7pZ5K2T2lDgBfz9mlOaUPS89bpLY6JiLXAG8DAyhffzMzKUfegI2lz4HDg+pR0MfAhoBFYAvxnbtcCh0eJ9FLHtC7DdEnzJc1funRp+YU3M7N2qXvQAT4FPBIRrwBExCsRsS4i1gOXARPTfs3AznnHDQVeTulDC6S3OEZSH2BbYHnrAkTEnIiYEBETBg8eXLETM+u2vPyAVUlXCDrHkde0lvpoco4EnkjPbwGmphFpI8kGDDwYEUuAlZI+nvprTgBuzjvmxPT8aOCu1O9jZsXkJuhctAgiNi4/4MBjFaB6fgdLGkDW5/LBiHgjpV1D1rQWwELglBRYkDQL+DKwFvhaRNya0icAVwL9gVuB/y8iQtIWwDXAOLIaztSIeL5UmSZMmBDz58+v7ImadScjRmSBprXhw7MZBMwKkPRwRExocz//8G/JQcd6laambBboxYuzOdLOPRe+8IWshtOaBOvX176M1i2UG3Q8I4FZb9XUBF/+Mrz3XvZ60aLs9Q47wLJlm+7v5QesArpCn46Z1cMZZ2wMODnvvQfvvlt4gk4vP2AV4KBj1lsVqs0ArFrlCTqtahx0zHqD9g6BnjYtGzSwfr2XH7CKcp+OWU930EFw550bX+eGQG+5Jbz11qb7D/SkHVY9rumY9WQzZ7YMODmrV8MWW0Dfvi3T+/aFCy+sTdmsV3LQMevJ5swpvm35crjiipZ9N1dc4aY0q6o2g46kfSRtmZ4fL+lHkoZXv2hm1m6t+27WrSu+77Bh7ruxmiunpnMxsFrSWOCbwCKy5QPMrCspNH1NKR4CbXVQTtBZm+YrOwK4MCIuBLaubrHMrN1mzcr6asoxebJrNVYX5QSdlZLOBo4HfpNW6+zbxjFmVmuLFxff1tCw8e+MGXDHHbUpk1kr5QyZPhb4PHBSRPxD0jDgP6pbLDNrt2HDPFGndXnl1HTGRcSPIuJegIhYDAxo4xgzq7Vzz/X0NdbllRN0/kXSgbkXks4i698xs1orNbPAtGmevsa6vDaXNpA0CPg1cCYwBfgo2bo0a6pfvNrz0gbW5eSWH1i0KAsm+f9nBwxwYLEuodylDdqs6UTEa8DhwE+AnYCje2rAMety8odBw6br3KxenQUks26i6EACSSvJVu9U+rs58EHgaEkREdvUpohmvVRTE5x4YukbPKH0qDWzLqZo0IkI34tjVi+5Gk5bAQe8uJp1K6VqOnuUOjAiHql8ccwMKP9GT49Os26m1H06/1liWwAHlthuZp1RqsksN5hg+PAs4HgQgXUjRQcSRMQBJR4VCTiSFkr6q6THJM1PaTtIul3Ss+nv9nn7ny1pgaS/SzokL318ymeBpIskKaX3k3RdSn9A0ohKlNusogoNgy7WZNbQANdckwUdT9Bp3VBZSxtIGiPpnySdkHtUsAwHRERj3lC7bwF3RsSuwJ3pNZJGAVOB0WRDt2enKXkgm5R0OrBrekxJ6ScBKyJiF+B84AcVLLdZ5xWapHP6dDj00MI3el51lQONdWvlLG3wXeC/0uMA4P+RDaGuliOAq9Lzq4DP5qXPjYh3I+IFYAEwUdKOwDYR8ec0MenVrY7J5XUDMDlXCzLrEgr13axeDfPm+UZP65HKqekcDUwG/hERXwLGAv0q9P4B3CbpYUnTU9r7I2IJQPr7vpQ+BHgx79jmlDYkPW+d3uKYiFgLvAFsshavpOmS5kuav3Tp0oqcmFlZivXdLF7stW6sRyon6LwTEeuBtZK2AV4lu1+nEvaJiD2ATwGnSZpUYt9CNZQokV7qmJYJEXMiYkJETBg8eHBbZTarnGJ9Nx4GbT1U0aAj6ceS9gEelLQdcBnwMPAI8GAl3jwiXk5/XwV+BUwEXklNZqS/r6bdm4Gd8w4fCryc0ocWSG9xjKQ+wLbA8kqU3awiPEmn9TKlajrPAj8EDgPOBu4HPgmcmJrZOkXSlpK2zj0HDgaeAG4BTky7nQjcnJ7fAkxNI9JGkg0YeDA1wa2U9PHUX3NCq2NyeR0N3BVtTTZnVkuepNN6mVJDpi+MiL2BSWS1gyuAW4HPStq1Au/9fuA+SX8hqzn9JiJ+C5wHfFLSs2RB7rxUnr8BvwSeBH4LnBYRudu1ZwA/JRtc8FwqJ8DlwEBJC4Cvk0bCmVVdqdmgW3PfjfUibc4y3WJnaRzwM2D3iGhoa//uyLNMW6flhkHnj0rzbNDWw1VslmlJfSV9RlITWQ3iGeBzFSijWc9UbBi0Z4M2Kzn32ieB44BPkzV/zQWmR8RbNSqbWfdUahi0WS9XqqbzbeDPwMci4jMR0eSAY1YGD4M2K6qtudcuiwgPMTZrDw+DNiuqrLnXzKwdPAzarKhSSxuYWUdNm+YgY1aAazpmZlYzDjpmZlYzDjpmZlYzDjpmZlYzDjpmOe2ZL83MOsSj18xg0/nScstGg0ehmVWQazpm4PnSzGrEQccMPF+aWY046JiB50szqxEHHTPwfGlmNeKgYwaeL82sRjx6zSzH86WZVZ1rOmZmVjMOOmZmVjN1CzqSdpZ0t6SnJP1N0hkp/RxJL0l6LD0OzTvmbEkLJP1d0iF56eMl/TVtu0iSUno/Sdel9Ackjaj5iVrteWYBsy6rnn06a4H/HRGPSNoaeFjS7Wnb+RHxw/ydJY0CpgKjgZ2AOyR9OCLWARcD04H7gXnAFOBW4CRgRUTsImkq8APg2Bqcm9WLZxYw69LqVtOJiCUR8Uh6vhJ4ChhS4pAjgLkR8W5EvAAsACZK2hHYJiL+HBEBXA18Nu+Yq9LzG4DJuVqQ9VCeWcCsS+sSfTqp2Wsc8EBKOl3S45J+Jmn7lDYEeDHvsOaUNiQ9b53e4piIWAu8AQws8P7TJc2XNH/p0qWVOSmrD88sYNal1T3oSNoKuBH4WkS8SdZU9iGgEVgC/Gdu1wKHR4n0Use0TIiYExETImLC4MGD23cC1rV4ZgGzLq2uQUdSX7KA0xQR/w0QEa9ExLqIWA9cBkxMuzcDO+cdPhR4OaUPLZDe4hhJfYBtgeXVORvrEjyzgFmXVs/RawIuB56KiB/lpe+Yt9uRwBPp+S3A1DQibSSwK/BgRCwBVkr6eMrzBODmvGNOTM+PBu5K/T7WU3lmAbMurZ6j1/YBvgD8VdJjKe3bwHGSGsmawRYCpwBExN8k/RJ4kmzk22lp5BrADOBKoD/ZqLVbU/rlwDWSFpDVcKZW9Yysa/DMAmZdlvzDv6UJEybE/Pnz610MM7NuRdLDETGhrf3qPpDAzMx6DwcdMzOrGQcd61o8hY1Zj+alDazr8BQ2Zj2eazpWf7nazfHHewobsx7ONR2rr9a1m0I8hY1Zj+GajtVXoQk6W/MUNmY9hoOO1VdbtRhPYWPWozjoWG3MnAl9+mRT0/Tpk72G0rUYT2Fj1uO4T8eqb+ZMuPjija/Xrdv4+txzN+3TGTDAwcash3JNx6oj/36b/ICTLxdYPEGnWa/hmo5VXjkj0iCr8YAn6DTrRVzTscorZ0QaQEND9ctiZl2Kg45VXrn31eRmGzCzXsNBxyqvrftqGhpgxgyYPbs25TGzLsNBxyqv2JLR114LEbB2rQOOWS/loGOV5xFpZlaER69ZdXhEmpkV4JqOmZnVjIOOmZnVTK8IOpKmSPq7pAWSvlWN9+jIgpeljik2VVlb+QwalD2KlaOtcuZvn75VEy82jGC9NqO5zwjum1n+Kp6t3+egg4qfT3vK35H3LjePSi5a2p68iu2bS89dM6ljn+/MmdlrKXtsvfXG44r9O6v0Aq6d/YybmrJjcucwaFDlPp9yylPq/Qtdq1osgFvOObRVjtGjN55T7lH1BXsjokc/gAbgOeCDwObAX4BRxfYfP358tNe110YMGBCRDc3KHgMGZOkdOWbGjJbpuceMGeXlU6wcbZUzf/txXBuraLnzKgbEvTNKnFSZZco/n/aUv1qfRWeO62xexfadMaO8a9jW59unT+Hj+vSJmDy58LbJkyt3LYqVq73/V/r23fS4zTev3OdTqjyl3r/Q59S3b7atUtevo+dQqGz55Rg1qnL/7yIigPlR5Hs1/9HmDt39AewN/C7v9dnA2cX270jQGT688Ac3fHjHjmloKLytoaH8fAqVo61y5m9/gcI7v9hQ4qTaUabc+bSn/OXoyGfRmeM6m1exfYv9G+jI51upR0euRbnl6sj/lUp/PsXyLbV/Rz6nSijnHIqVLVeOSpe33KCjbN+eS9LRwJSIODm9/gKwV0ScnrfPdGA6wLBhw8YvWrSoXe+x2WbZx7Tpe8P69e0/ptRH0npbsXwKlaOtcm62GUyNJv6NWQxnESqQ13rEZlHkpNpRpvz3Lrf85ejIZ9GZ4zqbV3uuVTFtfb6V0pFrAe37N9re4yv5+RTLt1LXtaPXr5DOlClXDhX6D15gv/Lz1cMRMaGt/XpDn06hS9vi44qIORExISImDB48uN1vUOwG/FI35pc6ptiUZIXSy1lUM7dPW+U8fYcmLmM6I4oEHICXG9p+w3IX+mxoaF/5y9GRz6Izx3U2r2L7tmdaurY+30rpaP6d/Yw7uq1S5Sm1f0c+p0ooJ69iZSu3HFX791ROdag7P6hB81pP6dNZOXB4yfq2+3QqXwb36bhPpyPcp9OFH2Q3wD4PjGTjQILRxfbvSNCJyD6g4cMjpOxvOR9YqWNmzNjYJtvQUDjgFMpn4MDsUawcJcspFfwXuJ6sL6ecgFPsfSZPLn4+7Sl/R9673Dw6elxn8yq2by49d82gY5/vjBktP9qtttp4XLF/Z5W8Fq3z68hnfO212TG5cxg4sHKfTznlKfX+ha5Vpa9fR8+hrXIUCjwdLW+5QafH9+kASDoUuIBsJNvPIuLcYvtOmDAh5s+fX6uidS0jRkCh/qzhw2HhwlqXxsy6Effp5ImIeRHx4Yj4UKmA0yuUGrhfbKLOc3v3JTOzyukVQceS3IqeixZlNelFi7LXucDjiTrNrMp6RfNae/To5jU3n5lZlbh5zTZVbEXPclf6NDPrJAed3qSSN6OYmXWAg05P44ECZtaFOej0JB4oYGZdnAcStNItBxI0NcGsWYUHCYAHCphZ1ZU7kMDLVXd3udrN6tXF9/FAATPrIty81t3NmlU64IAHCphZl+Gg0921VYvxQAEz60IcdLq7UrUYDxQwsy7GQae7KzYM+tprs8EDDjhm1oU46HR3HgZtZt2Ig05XNXMm9OmTBZI+fbLXxUybltVq1q937cbMujQPme6KZs6Eiy/e+Hrduo2vZ8+uT5nMzCrANZ2uaM6c9qWbmXUTDjpd0bp17Us3M+smHHTqqdjknA0Nhfcvlm5m1k24T6deWk9fk5ucE7K/+X06ObntZmbdVF1qOpL+Q9LTkh6X9CtJ26X0EZLelvRYelySd8x4SX+VtEDSRZKU0vtJui6lPyBpRN4xJ0p6Nj1OrPV5llRo+prVq7P02bNhxoyNNZuGhuy1BxGYWTdXl1mmJR0M3BURayX9ACAizkoB49cRMabAMQ8CZwD3A/OAiyLiVkkzgd0j4lRJU4EjI+JYSTsA84EJQAAPA+MjYkWpstVslunNNsuWH2hNyoY+m5l1I116ueqIuC0i1qaX9wNDS+0vaUdgm4j4c2RR8mrgs2nzEcBV6fkNwORUCzoEuD0ilqdAczswpbJn0glexdPMeqGuMJDgy8Ctea9HSnpU0j2S9k1pQ4DmvH2aU1pu24sAKZC9AQzMTy9wTP15FU8z64WqNpBA0h3ABwpsmhURN6d9ZgFrgdyaykuAYRGxTNJ44CZJowEVyCfXNlVsW6ljWpd1OjAdYFitahq5WQNmzcpmih42LAs4nk3AzHqwqgWdiDio1PbUsX8YMDk1mRER7wLvpucPS3oO+DBZLSW/CW4o8HJ63gzsDDRL6gNsCyxP6fu3Oub3Rco6B5gDWZ9OuefYadOmOciYWa9Sr9FrU4CzgMMjYnVe+mBJDen5B4FdgecjYgmwUtLHU3/NCcDN6bBbgNzItKPJBigE8DvgYEnbS9oeODilmZlZndSrT+fHwNbA7a2GRk8CHpf0F7JBAadGxPK0bQbwU2AB8Bwb+4EuBwZKWgB8HfgWQDru+8BD6fG9vLwqr9iNnmZmtkFdhkx3ZR0aMt36Rk/IBgV4iQEz6yW69JDpHqfUjZ5mZraBg04lLF7cvnQzs17KQacSfKOnmVlZHHQqwTd6mpmVxUGnEqZNywYNDB+ezZ02fLgHEZiZFeClDSrFN3qambXJNR0zM6sZBx0zM6sZBx0zM6sZBx0zM6sZBx0zM6sZz73WiqSlwKK8pEHAa3UqTlfi6+BrkOPr4GuQk38dhkfE4LYOcNBpg6T55Uxi19P5Ovga5Pg6+BrkdOQ6uHnNzMxqxkHHzMxqxkGnbXPqXYAuwtfB1yDH18HXIKfd18F9OmZmVjOu6ZiZWc046JiZWc046BQh6T8kPS3pcUm/krRd3razJS2Q9HdJh9SxmFUnaUo6zwWSvlXv8tSKpJ0l3S3pKUl/k3RGSt9B0u2Snk1/t693WatNUoOkRyX9Or3uVddA0naSbkjfB09J2ru3XQMASf+c/i88IekXkrboyHVw0CnudmBMROwOPAOcDSBpFDAVGA1MAWZLaqhbKasonddPgE8Bo4Dj0vn3BmuB/x0RHwM+DpyWzv1bwJ0RsStwZ3rd050BPJX3urddgwuB30bER4GxZNeiV10DSUOArwITImIM0ED2Pdju6+CgU0RE3BYRa9PL+4Gh6fkRwNyIeDciXgAWABPrUcYamAgsiIjnI+I9YC7Z+fd4EbEkIh5Jz1eSfdEMITv/q9JuVwGfrUsBa0TSUODTwE/zknvNNZC0DTAJuBwgIt6LiNfpRdcgTx+gv6Q+wADgZTpwHRx0yvNl4Nb0fAjwYt625pTWE/Wmcy1K0ghgHPAA8P6IWAJZYALeV8ei1cIFwDeB9XlpvekafBBYClyRmhh/KmlLetc1ICJeAn4ILAaWAG9ExG104Dr06qAj6Y7UPtn6cUTePrPImlqackkFsuqp485707kWJGkr4EbgaxHxZr3LU0uSDgNejYiH612WOuoD7AFcHBHjgLfo4U1phaS+miOAkcBOwJaSju9IXr16ueqIOKjUdkknAocBk2PjDU3NwM55uw0lq2b2RL3pXDchqS9ZwGmKiP9Oya9I2jEilkjaEXi1fiWsun2AwyUdCmwBbCPpWnrXNWgGmiPigfT6BrKg05uuAcBBwAsRsRRA0n8D/4sOXIdeXdMpRdIU4Czg8IhYnbfpFmCqpH6SRgK7Ag/Wo4w18BCwq6SRkjYn6zi8pc5lqglJImvHfyoifpS36RbgxPT8RODmWpetViLi7IgYGhEjyD77uyLieHrXNfgH8KKkj6SkycCT9KJrkCwGPi5pQPq/MZmsn7Pd18EzEhQhaQHQD1iWku6PiFPTtllk/TxryZpdbi2cS/eXfuVeQDZa5WcRcW59S1Qbkj4B3Av8lY39Gd8m69f5JTCM7D/iMRGxvC6FrCFJ+wPfiIjDJA2kF10DSY1kAyk2B54HvkT2g73XXAMASf8KHEv2vfcocDKwFe28Dg46ZmZWM25eMzOzmnHQMTOzmnHQMTOzmnHQMTOzmnHQMTOzmnHQMashSR+QNFfSc5KelDRP0odL7L+qjfzm5c+AbtbVeci0WY2km+r+BFwVEZektEZg64i4t8gxqyJiq9qV0qy6XNMxq50DgDW5gAMQEY9FxL2SzpT0UFq/6V9bHyhpR0l/kPRYmh9w35S+UNIgSSMkPZG3/zcknZOefzXVqh6XNLf6p2lWXK+ee82sxsYAm0yeKelgsumUJpJNsnqLpEkR8Ye83T4P/C4izk3rHA1ox/t+CxgZEe+6Kc7qzUHHrP4OTo9H0+utyIJQftB5CPhZmoT0poh4rB35Pw40SboJuKmzhTXrDDevmdXO34DxBdIF/HtENKbHLhFxef4OqdYzCXgJuEbSCa3yWEvL/89b5D3/NNkKsOOBh9MiXGZ14aBjVjt3Af0kfSWXIGlP4E3gy2ntHiQNkdRiMSxJw8nWtrmMbPbrPVrl/QrwPkkDJfUjW5IDSZsBO0fE3WSLsW1HVpMyqwv/4jGrkYgISUcCF0j6FvAOsBD4GvA68OdsgBurgONpuTbJ/sCZktak7S1qOhGxRtL3yGbBfgF4Om1qAK6VtC1Zjer8tNyyWV14yLSZmdWMm9fMzKxmHHTMzKxmHHTMzKxmHHTMzKxmHHTMzKxmHHTMzKxmHHTMzKxm/n8tDR7dKVJukwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los Valks reales del conjunto de prueba contra los Valks predichos por el modelo\n",
    "\n",
    "# El parámetro c hace referencia a que los datos de Valks reales se graficarán en color azul y los predichos en color rojo\n",
    "\n",
    "plt.scatter(test_data[\"Celsius\"], test_data[\"Valks\"], color = \"blue\", label = \"Reales\") # Gráfico de los datos reales\n",
    "\n",
    "plt.scatter(test_data[\"Celsius\"], pred_valks, color = \"red\", label = \"Predicciones\") # Gráfico de los datos predichos\n",
    "\n",
    "plt.xlabel(\"Celsius\") # Graficar grados celsius en el eje horizontal\n",
    "\n",
    "plt.ylabel(\"Valks\") # Graficar Valks en el eje vertical\n",
    "\n",
    "plt.title(\"Regresión lineal: Celsius vs Valks\") # Título del gráfico\n",
    "\n",
    "plt.legend() # Agregar leyenda al gráfico\n",
    "\n",
    "plt.show() # Mostrar gráfico de datos reales vs predicciones del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5c989",
   "metadata": {},
   "source": [
    "En términos generales, en la gráfica anterior se observa que las predicciones realizadas por el modelo implementado se alejan significativamente de los datos reales en Valks del subconjunto de datos de prueba, lo cual se debe principalmente al hecho de que el coeficiente $\\theta_{1}$ que se encuentra multiplicando a la variable predictora del modelo (temperatura en grados celsius), aún sigue siendo considerablemente grande, esto a pesar de que se realizó el entrenamiento del modelo con un total máximo de 500 iteraciones. Adicionalmente, esta diferencia notable entre los datos reales y los predichos también se atribuye a que los datos empleados para la generación del modelo también poseen una cierta variación considerable entre ellos en cuanto a su naturaleza, lo cual ocasiona que al momento de utilizarlos para aplicar el algoritmo, la variación existente entre los nuevos datos predichos también sea considerable, no obstante, dado que al momento de ejecutar el algoritmo, éste mismo no arroja ningún error durante su ejecución sobre el conjunto de datos en cuestión, además de que también logra converger después de una cierta cantidad de iteraciones, se concluye que el algoritmo tiene en general un desempeño mayormente adecuado para predecir la equivalencia en Valks de los datos de temperatura en celsius, pertenecientes al dataset de prueba, por lo que a pesar de que los datos predichos se encuentren alejados de los datos verdaderos, el algoritmo presenta un adecuado desempeño en cuanto a su capacidad de funcionamiento para calcular modelos predictivos que intenten explicar la variabilidad presente en los datos reales, además de que el alejamiento entre datos reales y predichos no se atribuye a algún fallo en la implementación del modelo, sino más bien a la variabilidad de los datos producida a su vez por la propia naturaleza de los mismos (son datos grandes en cuanto a su valor numérico)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
