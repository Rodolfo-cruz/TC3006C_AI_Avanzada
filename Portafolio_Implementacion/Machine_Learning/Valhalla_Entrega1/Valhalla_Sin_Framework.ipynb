{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebf5f41",
   "metadata": {},
   "source": [
    "# Challenge 01: Conversor de Celsius a Valks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2cc9cc",
   "metadata": {},
   "source": [
    "**Autor:** Rodolfo Jesús Cruz Rebollar\n",
    "\n",
    "**Matrícula:** A01368326\n",
    "\n",
    "**Grupo:** 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ebef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías para el análisis, manipulación y graficación de datos\n",
    "\n",
    "import pandas as pd # Pandas para análisis y manipulación de datos\n",
    "\n",
    "import numpy as np # numpy para realizar operaciones matemáticas y matriciales\n",
    "\n",
    "import matplotlib.pyplot as plt # Matplotlib para realizar gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23797d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.4720</td>\n",
       "      <td>-139.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.5790</td>\n",
       "      <td>-156.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.3013</td>\n",
       "      <td>73.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.3380</td>\n",
       "      <td>-165.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.2360</td>\n",
       "      <td>-75.835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celsius    Valks\n",
       "0  61.4720 -139.740\n",
       "1  70.5790 -156.600\n",
       "2  -7.3013   73.269\n",
       "3  71.3380 -165.420\n",
       "4  43.2360  -75.835"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar los datos a analizar, leyéndolos del archivo csv\n",
    "\n",
    "celsius_valks = pd.read_csv(\"Valhalla23.csv\")\n",
    "\n",
    "# Mostrar primeros 5 registros del dataframe para asegurar que los datos se hayan importado correctamente\n",
    "\n",
    "celsius_valks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e679550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Celsius  100 non-null    float64\n",
      " 1   Valks    100 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Mostrar características generales de la base de datos\n",
    "\n",
    "celsius_valks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72506b00",
   "metadata": {},
   "source": [
    "Al observar las características generales de la base de datos, se puede notar que en total se tienen 100 registros de datos con 2 columnas, correspondientes a la temperatura en Celsius y Valks respectivamente, además, se aprecia que ambas columnas de información no presentan datos faltantes, ya que todos los datos en ambas son no nulos, motivo por el cual, al no detectar ninguna inconsistencia o error en la estructura de los datos, a continuación se procederá a separar el conjunto principal de datos en 2 subconjuntos, 1 para el entrenamiento del modelo de regresión lineal y otro para ponerlo a prueba. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad58a46",
   "metadata": {},
   "source": [
    "## Creación del conjunto de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f533bf74",
   "metadata": {},
   "source": [
    "### Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "682543b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>71.719</td>\n",
       "      <td>-182.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>11.710</td>\n",
       "      <td>16.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>55.720</td>\n",
       "      <td>-121.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>49.908</td>\n",
       "      <td>-108.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.579</td>\n",
       "      <td>-156.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "84   71.719 -182.570\n",
       "37   11.710   16.143\n",
       "86   55.720 -121.090\n",
       "63   49.908 -108.590\n",
       "1    70.579 -156.600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librería random que contiene funciones para elegir aleatoriamente elementos de estructuras de datos o generar\n",
    "# valores aleatorios\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "# Generar el conjunto de datos de entrenamiento para el modelo (el 70% de los datos originales se destinará para entrenamiento)\n",
    "\n",
    "train_data = celsius_valks.iloc[rnd.choices(range(celsius_valks.shape[0]), k = round(0.7 * celsius_valks.shape[0])), :]\n",
    "\n",
    "# Mostrar los primeros registros del subconjunto de datos para entrenar el modelo \n",
    "\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0189379",
   "metadata": {},
   "source": [
    "En términos generales, para generar el subconjunto de datos para entrenar el modelo, lo primero que se realizó fue calcular cuántos registros (filas) tiene el conjunto total de datos con ayuda de la función shape que devuelve una tupla con dos elementos, el primero es la cantidad de filas del dataframe y el segundo es la cantidad de columnas del mismo, por lo que en este caso particular, se toma solamente el primer elemento de la tupla devuelta por la función shape (tiene como índice 0) que coresponde a la cantidad de registros del dataframe original, para luego en base a la cantidad de filas, la función range() genera una secuencia de números enteros desde 0 hasta la cantidad de filas menos 1, por lo que al tener 100 filas, range devolverá una secuencia de enteros desde 0 hasta 99 y dicha secuencia de enteros es recibida por la función choices() del módulo random, la cual escoge aleatoriamente una cierta cantidad de elementos de una lista, especificada en su parámetro k, que en este caso, dicha cantidad k se calcula obteniendo el 70% de la cantidad de filas del dataframe original y luego redondeando dicho resultado al entero más cercano, esto con el objetivo de evitar tener errores de formato numérico al momento de ejecutar el renglón de código en caso de que al calcular el porcentaje de datos para entrenamiento, se obtenga una cantidad con decimales. Además de lo anterior, después de calcular el valor k y definir la secuencia de enteros aleatorios para la función choices(), se procede a que la función choices() elige aleatoriamente k valores enteros de la secuencia definida previamente y envía dicha lista de enteros aleatorios al método iloc para decirle que extraiga las filas especificadas en la lista que recibe dicho método , mismas que se encuentran identificadas por su índice numérico (son los enteros aleatorios obtenidos antes) y a su vez también extraiga todas las columnas que conforman a dichas filas. Es importante recalcar que el método iloc identifica filas y columnas mediante su índice numérico en lugar de sus nombres. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4ab63",
   "metadata": {},
   "source": [
    "### Conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cabfb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.3380</td>\n",
       "      <td>-165.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.2360</td>\n",
       "      <td>-75.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34.6880</td>\n",
       "      <td>-55.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76.4890</td>\n",
       "      <td>-183.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-4.2387</td>\n",
       "      <td>61.973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "3   71.3380 -165.420\n",
       "4   43.2360  -75.835\n",
       "7   34.6880  -55.108\n",
       "9   76.4890 -183.460\n",
       "10  -4.2387   61.973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El conjunto de prueba estará conformado por todos los datos que no fueron seleccionados de forma aleatoria al momento de \n",
    "# generar el conjunto de entrenamiento\n",
    "\n",
    "# Obtener los índices numéricos de las filas que no fueron seleccionadas al generar el conjunto de entrenamiento\n",
    "\n",
    "# la función lambda en conjunto con la función filter, verifican si cada índice de fila del dataframe completo \n",
    "# se encuentra entre los índices de fila del subconjunto de entrenamiento, de no ser así, se selecciona dicho índice para\n",
    "# incluir la fila correspondiente al mismo, al conjunto de prueba, esto garantiza que el subconjunto de prueba tenga datos que\n",
    "# el modelo aún no haya visto y finalmente se incluyen los índices filtrados en una nueva lista\n",
    "\n",
    "filas_no_elegidas = list(filter(lambda x: x not in train_data.index.values, celsius_valks.index.values))\n",
    "\n",
    "# Extraer las filas que no estén en el subconjunto de entrenamiento con todas sus columnas\n",
    "\n",
    "test_data = celsius_valks.iloc[filas_no_elegidas, :]\n",
    "\n",
    "# Mostrar los primeros registros del conjunto de prueba para asegurar que los datos estén bien estructurados\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726bc0c",
   "metadata": {},
   "source": [
    "**Nota:** la cantidad de registros extraídos para el conjunto de prueba, corresponde al 30% de la cantidad de registros de la base de datos original (30 registros de 100). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ab3e5",
   "metadata": {},
   "source": [
    "## Regresión lineal con gradiente descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02aa054",
   "metadata": {},
   "source": [
    "Para implementar un modelo de regresión lineal con gradiente descendente para resolver la problemática planteada, en primera instancia es necesario tomar en consideración aquellas ecuaciones en las que está basado el funcionamiento del modelo en sí mismo, entre las que se encuentran: la función de costo denotada como J, las funciones correspondientes a las derivadas parciales respecto a $\\theta_{0}$ y $\\theta_{1}$ de dicha función de costo, además de aquellas otras ecuaciones correspondientes  al cálculo tanto del parámetro $\\theta_{0}$ como del parámetro $\\theta_{1}$, mismos que irán actualizándose a medida que el algoritmo necesite una mayor cantidad de iteraciones para encontrar el punto de convergencia, mismo que se define como el momento en el cual la función de costo J alcanza su mínimo valor posible para los datos en cuestión.\n",
    "\n",
    "Debido a lo anterior, a continuación se mencionan las ecuaciones que se utilizarán para la implementación efectiva del modelo de regresión lineal:\n",
    "\n",
    "**Función de costo J:**\n",
    "\n",
    "$J_{\\theta} = \\frac{1}{2n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})^{2}}$\n",
    "\n",
    "Donde $h_{\\theta}(x_{i}) = \\theta_{0} + \\theta_{1}x_{i}$\n",
    "\n",
    "**Derivadas parciales de J:**\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\theta_{0}} = \\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})}$\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\theta_{1}} = \\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})x_{i}}$\n",
    "\n",
    "**Cálculo de $\\theta_{0}$ y $\\theta_{1}$ mediante gradiente descendente:**\n",
    "\n",
    "$\\theta_{0} = \\theta_{0} - \\alpha\\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})}$\n",
    "\n",
    "$\\theta_{1} = \\theta_{1} - \\alpha\\frac{1}{n}\\sum_{i = 1}^{n}{(h_{\\theta}(x_{i}) - y_{i})x_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573f571",
   "metadata": {},
   "source": [
    "Para definir la función del método de gradiente descendente a continuación, los parámetros $\\theta_{0}$ y $\\theta_{1}$ tendrán ambos un valor inicial de 1, esto debido principalmente a que al asignar inicialmente valores unitarios a dichos parámetros del modelo, se comienza el algoritmo con un modelo básico en el sentido de que al comienzo de todo el proceso iterativo, al no saber todavía con certeza cuáles serán los valores adecuados para los parámetros del modelo, el hecho de asignar un valor unitario a éstos garantiza que al iniciar el proceso, tanto la ordenada al origen como el coeficiente de la variable x tengan una cierta contribución, peso o influencia en las primeras predicciones derivadas del algoritmo, esto mientras se calculan nuevos valores para los parámetros del modelo a medida que avanzan las iteraciones del algoritmo, por lo que después de la primera iteración del algoritmo, los valores unitarios iniciales se reemplazarán por los nuevos valores calculados en dicha iteración y así sucesivamente, por lo cual, se seleccionaron valores iniciales de 1 para los $\\theta$ solamente para comenzar el algoritmo con un \"modelo por default\". \n",
    "\n",
    "Además de lo anterior, para implementar el modelo de regresión lineal con gradiente descendente se necesita definir un parámetro adicional llamado $\\alpha$ que será la tasa de aprendizaje del modelo (rapidez con la que aprende el modelo a identificar patrones en los datos) y otro parámetro conocido como $\\epsilon$ que se refiere al límite máximo de error permitido para el modelo, es decir, el criterio que se utilizará para definir si la función de costo J converge, por lo que en caso de que llegue un momento en el cual el valor de ambas derivadas de la función J sean inferiores al valor de $\\epsilon$, se alcanzará la convergencia del algoritmo y en ese punto terminará todo el proceso iterativo, es decir, terminará el algoritmo en sí. Por otro lado, utilizaremos una tasa de aprendizaje $\\alpha = 0.0001$ debido a que es un valor que no es excesivamente pequeño pero tampoco muy grande, esto en el sentido de que garantizará que el algoritmo aprenda a un ritmo moderado, es decir, que no sea excesivamente rápido o lento, dado que en caso de que dicho valor $\\alpha$ sea muy pequeño, se corre el riesgo de que el algoritmo al aprender a un ritmo muy lento, necesite demasiadas iteraciones, lo cual implicaría que el algoritmo demore mucho tiempo en proporcionar una respuesta a tal punto de que dicha respuesta al no llegar a tiempo, retrase los procesos por ejemplo de alguna empresa, o industria y perjudicando su capacidad para operar de forma eficente, por lo que en resumen un valor de $\\alpha$ muy pequeño puede provocar que el algoritmo se vuelva prácticamente ineficiente sobretodo en situaciones en las que se requiere una respuesta a la brevedad posible. Sin embargo, si se elige un valor de $\\alpha$ grande, se corre el riesgo de que durante el proceso iterativo del algoritmo, se pase por alto el punto mínimo en el que la función J alcanza un valor inferior al $\\epsilon$, provocando que al final de todo el algoritmo, el modelo de regresión lineal resultante no sea el que mejor se ajuste a los datos en cuestión, por lo que en pocas palabras, un $\\alpha$ grande reduciría la capacidad del algoritmo para encontrar el mejor modelo posible para los datos además de que el modelo derivado del mismo no arrojaría predicciones de temperatura suficientemente confiables, lo que podría ocasionar que en vez de resolver la crisis del calentamiento global mencionada en el challenge 1, el planeta Tierra se podría calentar o enfriar en exceso y por consiguiente afectar negativamente a la vida en la Tierra.\n",
    "\n",
    "Adicionalmente, también cabe mencionar que en cuanto al parámetro de error máximo $\\epsilon$, éste mismo tendrá un valor de 0.01 para el problema en cuestión, ya que entre más pequeño sea el valor de éste parámetro, el algoritmo buscará obtener un modelo en su gran mayoría confiable en cuanto a las predicciones que arroje, sin embargo, $\\epsilon$ tampoco puede ser 0, debido a que por la propia naturaleza de los datos involucrados, tampoco resulta posible encontrar algún modelo que prediga correctamente la temperatura en Valks para absolutamente todos los datos en grados celsius, por lo que 0 no es un valor adecuado para el parámetro $\\epsilon$. No obstante si en cambio el valor de $\\epsilon$ es grande, tampoco es recomendable dado que estaríamos permitiendo que el modelo resultante del algoritmo tenga mayor margen de error, lo cual puede causar que las predicciones derivadas del mismo no tengan un grado de confiabilidad suficiente para convertir grados celsius a valks, lo que de nuevo puede llevar a una toma de decisiones errónea y nuevamente eso agravaría la crisis del cambio climático que se desea resolver en la problemática abordada, por lo que 0.01 resulta ser una elección que no es un valor excesivamente pequeño pero tampoco muy grande, por lo que resulta adecuado como valor para el parámetro de error máximo admisible $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8881f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una serie de pandas que contenga ambos valores de theta a lo largo del algoritmo\n",
    "\n",
    "# Incialmente ambos hiperparámetros theta tendrán un valor de 1\n",
    "\n",
    "theta = pd.Series([1, 1], index = [\"theta0\", \"theta1\"])\n",
    "\n",
    "# Definir la tasa de aprendizaje alpha\n",
    "\n",
    "alpha = 0.0001\n",
    "\n",
    "# Definir la máxima proporción permitida de error épsilon\n",
    "\n",
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea158e9d",
   "metadata": {},
   "source": [
    "### Función de hipótesis h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc08f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer una función anónima lambda para evaluar los datos de la variable independiente (Celsius) en la función de hipótesis\n",
    "\n",
    "h = lambda x: theta[\"theta0\"] + theta[\"theta1\"] * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84164d20",
   "metadata": {},
   "source": [
    "### Función de costo J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95f23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de costo que recibe 2 parámetros de entrada: número de registros del dataframe y datos de entrenamiento\n",
    "\n",
    "def J_function(n, data):\n",
    "    \n",
    "    # Calcular el valor de la función J para los datos: primero los datos de temperatura en grados Celsius se multiplican por \n",
    "    # el valor del parámetro theta 1 y después a dichos resultados se les suma el valor de theta 0, para después a dichos \n",
    "    # resultdos restarles los datos de temperatura en Valks, elevar los valores resultantes al cuadrado, sumarlos y finalmente\n",
    "    # multiplicar el resultado de la suma por 1/2n\n",
    "    \n",
    "    J  = (1 / (2 * n)) * (((h(data[\"Celsius\"]) - data[\"Valks\"]) ** 2).sum())\n",
    "    \n",
    "    # Devolver el valor de la función J\n",
    "    \n",
    "    return J\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d830a1e5",
   "metadata": {},
   "source": [
    "### Derivadas parciales de J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1391cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular derivada parcial de J respecto a theta0 que recibe como parámetros de entrada: número de datos de entre-\n",
    "# namiento (n) y los datos de entrenamiento (data)\n",
    "\n",
    "def J_partial_theta0(n, data):\n",
    "    \n",
    "    # Calcular la derivada de J respecto a theta0, primero calculando los residuos del modelo \n",
    "    # (Valks predichos con función h menos Valks reales), luego sumando los residuos obtenidos por muestra y\n",
    "    # por último, multiplicando dicha suma por 1/n\n",
    "    \n",
    "    derivada_theta_0 = (1 / n) * ((h(data[\"Celsius\"]) - data[\"Valks\"]).sum())\n",
    "    \n",
    "    # Devolver el valor de la derivada de J respecto a theta0\n",
    "    \n",
    "    return derivada_theta_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05ad0710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que calcula el valor de la derivada de J respecto a theta1, recibiendo como parámetros de entrada: cantidad de datos\n",
    "# de entrenamiento (n) y los datos de entrenamiento en sí (data)\n",
    "\n",
    "def J_partial_theta1(n, data):\n",
    "    \n",
    "    # Calcular valor de la derivada de J respecto a theta1, primero calculando para cada registro de datos, la diferencia entre\n",
    "    # los Valks predichos con función h menos los Valks reales, después multiplicando las diferencias por los datos de celsius\n",
    "    # luego sumando los productos obtenidos y finalmente multiplicando el resultado de la suma por 1/n\n",
    "    \n",
    "    derivada_theta_1 = (1 / n) * (((h(data[\"Celsius\"]) - data[\"Valks\"]) * data[\"Celsius\"]).sum())\n",
    "    \n",
    "    # Devolver el valor de la derivada de J respecto a theta1\n",
    "    \n",
    "    return derivada_theta_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4df50",
   "metadata": {},
   "source": [
    "### Función de gradiente descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79eddd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular los parámetros adecuados para el modelo de regresión lineal mediante el método del gradiente descendente\n",
    "\n",
    "\"\"\"La función recibe 4 argumentos de entrada: datos para entrenamiento, tasa de aprendizaje alpha, límite máximo de error \n",
    "   permitido para definir la convegencia del algoritmo y el número máximo de iteraciones para generar el modelo (100000).\"\"\"\n",
    "\n",
    "# El parámetro i = 100000 indica que se entrenará el modelo con 100000 iteraciones (más del mínimo solicitado de 100 iteraciones)\n",
    "\n",
    "def gradiente_descendente(data, alpha, epsilon, i = 100000):\n",
    "    \n",
    "    # Longitud de conjunto de datos para entrenamiento\n",
    "    \n",
    "    n = len(data) \n",
    "    \n",
    "    # Definir variable booleana convergencia que indicará si se alcanza o no la convergencia del algoritmo\n",
    "    \n",
    "    convergencia = False # se inicializa en false dado que aún no se encuentra ningún modelo para los datos\n",
    "    \n",
    "    # Inicializar en 1 la variable k que contará el número de iteraciones del ciclo while\n",
    "    \n",
    "    k = 1\n",
    "    \n",
    "    # Ejecutar el algoritmo mientras que no se alcance el máximo de iteraciones y no se encuentre convergencia\n",
    "    # Esto con el propósito de que en caso de que el algoritmo converga, entonces se detenga el algoritmo aunque no se\n",
    "    # alcance el número máximo de iteraciones establecido. Además, el ciclo también se detendrá en caso de que a pesar de \n",
    "    # que el algoritmo no converga, se llegue a la cantidad máxima establecida de iteraciones, lo cual será solamente un paro\n",
    "    # de emergencia en el caso de que no suceda la convergencia y para que el algoritmo no itere infinitamente, sino que arroje\n",
    "    # una respuesta en el máximo de iteraciones establecido aunque no sea el modelo que mejor se ajuste a los datos\n",
    "    \n",
    "    while (k <= i) & (convergencia == False):\n",
    "        \n",
    "        # Calcular el valor de J (función de costo)\n",
    "        \n",
    "        J = J_function(n, data)\n",
    "        \n",
    "        # Calcular el valor de la derivada de J respecto a theta0\n",
    "        \n",
    "        deriv_theta_0 = J_partial_theta0(n, data)\n",
    "        \n",
    "        # Calcular el valor de la derivada de J respecto a theta1\n",
    "        \n",
    "        deriv_theta_1 = J_partial_theta1(n, data)\n",
    "        \n",
    "        # Calcular el valor actualizado del hiperparámetro theta0\n",
    "        \n",
    "        theta[\"theta0\"] -= alpha * deriv_theta_0\n",
    "        \n",
    "        # Calcular el valor actualizado del hiperparámetro theta1\n",
    "        \n",
    "        theta[\"theta1\"] -= alpha * deriv_theta_1\n",
    "        \n",
    "        # Verificar si el valor de las derivadas es inferior al límite máximo epsilon\n",
    "        \n",
    "        if (deriv_theta_0 < epsilon) & (deriv_theta_1 < epsilon):\n",
    "            \n",
    "            # De ser así, se habrá encontrado la convergencia del algoritmo para los datos\n",
    "            \n",
    "            convergencia = True\n",
    "        \n",
    "        # Actualizar el valor del número de iteración k\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    # Devolver el valor de la función J para el subset de datos de entrenamiento\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3bc6d8",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef0254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definir función model_train() exclusivamente para entrenar el modelo, por lo cual, se pasa como argumento de entrada\n",
    "el subconjunto de datos para entrenamiento a dicha función model_train con el objetivo principal de indicar que la función\n",
    "model_train() es exclusivamente para entrenar el modelo, por lo tanto, dicha función devolverá como salida el modelo de\n",
    "regresión encontrado exclusivamente para los datos de entrenamiento, junto con el valor de la función de costo J igualmente\n",
    "para el subset de entrenamiento.\"\"\"\n",
    "\n",
    "def model_train(datos_train):\n",
    "    \n",
    "    # Invocar a la función gradiente descendente para entrenar el modelo utilizando los datos de entrenamiento\n",
    "    # como argumento de entrada de la función gradiente_descendente()\n",
    "    \n",
    "    # Adicionalmente pasar como argumentos a la función gradiente_descendente(): \n",
    "    # alpha: tasa de aprendizaje para el entrenamiento del modelo\n",
    "    # epsilon: límite máximo permitido de error para encontrar el punto de convergencia del algoritmo\n",
    "    \n",
    "    # la función gradiente_descendente devuelve como valor de salida el valor de J para el subset de entrenamiento\n",
    "    \n",
    "    J_training = gradiente_descendente(datos_train, alpha, epsilon)\n",
    "    \n",
    "    # Desplegar el modelo de regresión lineal calculado para los datos \n",
    "    \n",
    "    print(f'El modelo para los datos es: Valks = {theta[\"theta0\"]} + {theta[\"theta1\"]} * Celsius')\n",
    "    \n",
    "    # Desplegar el valor de la función de costo J para el subset de entrenamiento\n",
    "    \n",
    "    print(f'Valor J para el subconjunto de datos de entrenamiento: J = {J_training}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0b71f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo para los datos es: Valks = 48.22624322008204 + -3.0024550810233435 * Celsius\n",
      "Valor J para el subconjunto de datos de entrenamiento: J = 18.553669202859105\n"
     ]
    }
   ],
   "source": [
    "# Realizar el entrenamiento del modelo pasando como argumento de entrada el subset de datos\n",
    "# para entrenamiento\n",
    "\n",
    "model_train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210ceeb",
   "metadata": {},
   "source": [
    "## Prueba del modelo implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50459174",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definir función model_test() exclusivamente para poner a prueba el modelo, por lo cual, se pasa como argumento de entrada\n",
    "el subconjunto de datos para prueba a dicha función model_test() con el objetivo principal de indicar que la función\n",
    "model_test() es exclusivamente para entrenar el modelo, por lo tanto, dicha función devolverá como salida el modelo de\n",
    "regresión encontrado exclusivamente para los datos de prueba, junto con el valor de la función de costo J igualmente\n",
    "para el subset de prueba.\"\"\"\n",
    "\n",
    "def model_test(datos_test):\n",
    "    \n",
    "    # Utilizando los valores de los coeficientes theta del modelo entrenado, predecir la equivalencia en Valks de\n",
    "    # los datos en Celsius del subconjunto de datos para testing o prueba\n",
    "    \n",
    "    predicted_test = h(datos_test[\"Celsius\"])\n",
    "    \n",
    "    # Calcular el valor de la función de costo J para el subconjunto de datos de prueba\n",
    "    \n",
    "    J_test = J_function(len(datos_test), datos_test)\n",
    "    \n",
    "    # Devolver las predicciones para el subset de prueba, además del valor J para el subset de prueba\n",
    "    \n",
    "    return predicted_test, J_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7bb4fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor J para el subconjunto de datos de prueba: J = 29.732198088388007\n",
      "Predicciones para el subconjunto de prueba: \n",
      " 3    -165.962897\n",
      "4     -81.587905\n",
      "7     -55.922919\n",
      "9    -181.428543\n",
      "10     60.952750\n",
      "11   -183.139943\n",
      "12   -179.110648\n",
      "15     65.674711\n",
      "16    -18.356201\n",
      "17   -166.671477\n",
      "18   -129.582149\n",
      "21     97.553578\n",
      "23   -172.150957\n",
      "25   -119.232686\n",
      "27     -9.489951\n",
      "29     56.877217\n",
      "33     94.413010\n",
      "35   -138.964821\n",
      "36   -100.344242\n",
      "39     97.931887\n",
      "40    -23.454369\n",
      "42   -121.568597\n",
      "44     52.167566\n",
      "48   -104.706809\n",
      "50     25.400078\n",
      "52    -88.415488\n",
      "53     59.451822\n",
      "54     72.546730\n",
      "55    -41.355007\n",
      "58    -67.449344\n",
      "59     41.076797\n",
      "60   -117.290098\n",
      "61     31.684217\n",
      "62    -43.636872\n",
      "64   -159.213378\n",
      "70   -144.147059\n",
      "72   -136.208567\n",
      "73     35.158057\n",
      "75      3.195422\n",
      "77     32.888502\n",
      "78    -76.687898\n",
      "79    -33.827852\n",
      "81   -141.177631\n",
      "83    -56.775616\n",
      "88     -5.953059\n",
      "90     85.501723\n",
      "94   -172.156962\n",
      "96    -62.510305\n",
      "97    -32.656894\n",
      "Name: Celsius, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Poner a prueba el modelo previamente entrenado calculando las predicciones para los datos del subset\n",
    "# de prueba \n",
    "\n",
    "# Variables predicciones_valks_test y J_Prueba para almacenar las salidas de la función model_test()\n",
    "# referentes a los resultados \n",
    "\n",
    "predicciones_valks_test, J_prueba = model_test(test_data)\n",
    "\n",
    "# Mostrar el valor de la función de costo J para el subconjunto de datos de prueba\n",
    "    \n",
    "print(f'Valor J para el subconjunto de datos de prueba: J = {J_prueba}')\n",
    "    \n",
    "# Mostrar valores de las predicciones para el subconjunto de datos de prueba\n",
    "    \n",
    "print(\"Predicciones para el subconjunto de prueba: \\n\", predicciones_valks_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34250aec",
   "metadata": {},
   "source": [
    "### Graficar los Valks reales vs los predichos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c6d53be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los Valks reales del conjunto de prueba contra los Valks predichos por el modelo\n",
    "\n",
    "# El parámetro color hace referencia a que los datos de Valks reales se graficarán en color azul y los predichos en color rojo\n",
    "\n",
    "# Gráfico de datos reales\n",
    "\n",
    "plt.scatter(test_data[\"Celsius\"], test_data[\"Valks\"], color = \"blue\", label = \"Reales\")\n",
    "\n",
    "# Gráfico de los datos predichos\n",
    "\n",
    "plt.plot(test_data[\"Celsius\"], predicciones_valks_test, color = \"red\", label = \"Predicciones\", linewidth = 2) \n",
    "\n",
    "plt.xlabel(\"Celsius\") # Graficar grados celsius en el eje horizontal\n",
    "\n",
    "plt.ylabel(\"Valks\") # Graficar Valks en el eje vertical\n",
    "\n",
    "plt.title(\"Regresión lineal: Celsius vs Valks\") # Título del gráfico\n",
    "\n",
    "plt.legend() # Agregar leyenda al gráfico\n",
    "\n",
    "plt.show() # Mostrar gráfico de datos reales vs predicciones del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5c989",
   "metadata": {},
   "source": [
    "En términos generales, en la gráfica anterior se observa que las predicciones realizadas por el modelo implementado se aproximan de forma muy significativa a los datos reales en Valks del subconjunto de datos de prueba, lo cual se debe principalmente al hecho de en el gráfico de Valks reales contra los valks predichos por el modelo, se aprecia que la recta color rojo (valks predichos) se ajusta adecuadamente en su gran mayoría a los datos, por lo cual solamente una reducida minoría de los datos reales se ubican alejados de la recta roja referente al modelo encontrado, no obstante, dicho alejamiento es mínimo. Además de lo anterior, también cabe mencionar que dado el hecho de que los coeficientes del modelo encontrado para representar los datos son lo suficientemente mayores a 0 como para generar valores resultantes medianamente grandes, eso propicia que las predicciones derivadas del modelo también sean lo suficientmente grandes como para ajustarse en gran parte a los datos en valks reales del subconjunto de prueba como se evidencia en el gráfico anterior, motivo por el cual, se concluye que el algoritmo presenta en general un desempeño en su gran mayoría adecuado para predecir la equivalencia en Valks de los datos de temperatura en celsius, pertenecientes al dataset de prueba, por lo cual, además de lo anterior, también se afirma que las predicciones derivadas del modelo encontrado poseen un grado muy alto de precisión y como consecuencia, también poseen un elevado grado de confiabilidad para utilizarse en la toma de decisiones respecto a la temperatura adecuada para configurar la máquina reguladora de temperatura para erradicar el cambio climático mencionada en el challege 1 de Valhalla, por lo cual será posible saber con un alto grado de precisión, con qué cantidad en Valks configurar la máquina reguladora de temperatura para controlar la temperatura ambiental de forma correcta sin que el clima se torne excesivamente frío o cálido como para afectar la vida en el planeta Tierra. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
