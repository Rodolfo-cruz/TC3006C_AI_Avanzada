{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e88403",
   "metadata": {},
   "source": [
    "# Valhalla challenge con Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2a3ccf",
   "metadata": {},
   "source": [
    "**Autor:** Rodolfo Jesús Cruz Rebollar\n",
    "\n",
    "**Matrícula:** A01368326\n",
    "\n",
    "**Grupo:** 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d9ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librería numpy para realizar operaciones matemáticas con arreglos\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Importar librería pandas para manipulación y análsis de datos\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importar matplotlib para realizar gráficos de los datos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importar la función SGDRegressor del módulo linear_model de la librería Scikit-Learn\n",
    "# para implementar regresión lineal con gradiente descendente estocástico\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Además importar el método train_test_split para dividir el conjunto total de datos en\n",
    "# subconjuntos para entrenamiento del modelo y prueba del mismo\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1253772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.4720</td>\n",
       "      <td>-139.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.5790</td>\n",
       "      <td>-156.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.3013</td>\n",
       "      <td>73.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.3380</td>\n",
       "      <td>-165.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.2360</td>\n",
       "      <td>-75.835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celsius    Valks\n",
       "0  61.4720 -139.740\n",
       "1  70.5790 -156.600\n",
       "2  -7.3013   73.269\n",
       "3  71.3380 -165.420\n",
       "4  43.2360  -75.835"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar los datos de temperatura en celsius y Valks en un dataframe\n",
    "\n",
    "temperatura = pd.read_csv(\"Valhalla23.csv\")\n",
    "\n",
    "# Verificar que los datos se hayan importado correctamente\n",
    "# (imprimir primeros registros del dataframe)\n",
    "\n",
    "temperatura.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b7d52",
   "metadata": {},
   "source": [
    "## Creación de subsets para entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db38a1",
   "metadata": {},
   "source": [
    "En cuanto a la creación de los subsets para el entrenamiento y prueba del modelo, se utilizará la función train_test_split() del módulo model_selection perteneciente a su vez a la librería de Scikit-Learn, por lo que éste método tiene la principal función de dividir el conjunto completo de datos en 4 subconjuntos de datos que devuelve como salida, los cuales son: valores de las variables predictoras correspondientes al conjunto de entrenamiento, valores de la variable objetivo que se desea predecir correspondientes de igual manera al conjunto de entrenamiento, valores de las variables predictoras correspondientes al conjunto de prueba y valores de la variable objetivo correspondientes al conjunto de prueba también, por lo que en resumen, en cuanto a nuestro caso particular, tendremos los siguientes subsets de datos como salida de la función train_test_split():\n",
    "\n",
    "1. Datos en celsius del conjunto de entrenamiento (datos en celsius usados para entrenar el modelo)\n",
    "\n",
    "2. Datos en Valks de conjunto de entrenamiento (datos en valks usados para entrenar el modelo)\n",
    "\n",
    "3. Datos en celsius del conjunto de prueba (datos en celsius usados para poner a prueba el modelo)\n",
    "\n",
    "4. Datos en Valks del conjunto de prueba (datos en Valks usados para poner a prueba el modelo)\n",
    "\n",
    "Por lo cual, después de haber dividido el dataset principal en dichos subconjuntos, se procederá a agrupar los 4 subconjuntos de datos en 2 dataframes, el primero de ellos tendrá los valores en celsius y valks que se usarán para entrenamiento, mientras que el segundo dataframe, tendrá los datos en celsius y Valks empleados para probar el modelo.\n",
    "\n",
    "**Nota:** la función train_test_split() primero reorganiza los datos originales de manera aleatoria para luego calcular la cantidad de datos que serán para entrenar y para prueba, éste cálculo lo realiza calculando los porcentajes especificados para entrenamiento y prueba de la cantidad de datos originales, por lo que una vez habiendo calculado dichos porcentajes, procede a tomar aleatoriamente dicha cantidad de datos tanto para el entrenamiento como para la prueba del modelo y así mismo, tras tomar la cantidad calculada de datos para entrenar y probar el modelo, divide los datos para entrenar y para probar en 2 subconjuntos, el primero de ellos que tendrá los datos de las variables predictoras, mientras que el segundo tendrá aquellos otros datos de la variable de respuesta que se desea predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c31efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invocar al método train_test_split() para dividir el conjunto original de datos\n",
    "# en los subconjuntos antes descritos\n",
    "\n",
    "# La función train_test_split() recibe como argumentos los datos de la variable predictora (Celsius),\n",
    "# datos de la variable respuesta (Valks), 30% de los datos originales para prueba y 70%\n",
    "# de los datos originales para entrenamiento\n",
    "\n",
    "# c_train: valores de celsius para entrenar, \n",
    "# c_test: valores de celsius para prueba, \n",
    "# v_train: valores de Valks para entrenar, \n",
    "# v_test: valores de Valks para prueba\n",
    "\n",
    "c_train, c_test, v_train, v_test = train_test_split(temperatura[\"Celsius\"], temperatura[\"Valks\"], \n",
    "                                                   test_size = 0.3, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a5c57",
   "metadata": {},
   "source": [
    "### Subset para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e09b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-5.8114</td>\n",
       "      <td>66.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.4720</td>\n",
       "      <td>-139.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.5380</td>\n",
       "      <td>-30.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.6025</td>\n",
       "      <td>25.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.1760</td>\n",
       "      <td>-12.882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "15  -5.8114   66.370\n",
       "0   61.4720 -139.740\n",
       "13  28.5380  -30.998\n",
       "50   7.6025   25.080\n",
       "16  22.1760  -12.882"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupar los datos en celsius para entrenamiento y los datos de valks para entrenamiento\n",
    "# en un solo dataframe\n",
    "\n",
    "data_train = pd.DataFrame({\"Celsius\": c_train, \"Valks\": v_train})\n",
    "\n",
    "# Mostrar los primeros registros del subset de entrenamiento\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27091126",
   "metadata": {},
   "source": [
    "### Subset para prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59e04fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>62.3460</td>\n",
       "      <td>-122.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.8813</td>\n",
       "      <td>58.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>64.0720</td>\n",
       "      <td>-127.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>33.0800</td>\n",
       "      <td>-56.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>27.3290</td>\n",
       "      <td>-27.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "35  62.3460 -122.730\n",
       "29  -2.8813   58.486\n",
       "70  64.0720 -127.100\n",
       "92  33.0800  -56.911\n",
       "79  27.3290  -27.032"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agrupar los datos en celsius y Valks para prueba en un solo dataframe\n",
    "\n",
    "# Pasar como argumento al constructor de dataframe un diccionario que contenga el nombre de cada columna y los datos\n",
    "# asociados a dicha columna\n",
    "\n",
    "data_test = pd.DataFrame({\"Celsius\": c_test, \"Valks\": v_test})\n",
    "\n",
    "# Mostrar primeros registros del subset para prueba\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f387d",
   "metadata": {},
   "source": [
    "## Creación y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b8eb67",
   "metadata": {},
   "source": [
    "### Configuración del modelo y justificación de sus parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ac839",
   "metadata": {},
   "source": [
    "En primera instancia, para configurar y entrenar el modelo de regresión lineal con gradiente estocástico, se utlizará el parámetro loss = \"squared_error\", mismo que indica que el modelo operará en base a la función de pérdida del error cuadrático, en otras palabras, misma que consiste básicamente en calcular la sumatoria de las diferencias de cuadrados entre los datos reales y las predicciones hechas por el modelo, lo cual se representa por medio de la siguiente expresión:\n",
    "\n",
    "$error = \\sum_{i = 1}^{n}{(y - \\hat{y})^{2}}$ donde $\\hat{y}$ representa las predicciones hechas por el modelo y $y$ a su vez representa los datos reales, por lo cual la función anterior será la función de costo J que se empleará para configurar el modelo de regresión lineal. \n",
    "\n",
    "Además de lo anterior, el parámetro penalty del modelo será \"l2\", mismo que se refiere al hecho de aplicar la regularización estándar a la función J con el principal objetivo de que el modelo logre aproximar los parámetros adecuados del modelo asegurando que éstos se encuentren lo más próximos a 0 posible, por lo cual, el objetivo de dicha regularización sobre J consiste en aplicar la penalización correspondiente a J principalmente en caso de que durante la ejecución del algoritmo, se estén obteniendo coeficientes con un valor bastante elevado y al aplicar dicha penalización, esos valores logren reducirse al mínimo posible, esto garantizará que el modelo entrenado, estime el modelo que mejor se ajuste a los datos en cuestión, asegurando que se obtenga el modelo que tenga el mayor grado de eficiencia posible y a su vez con los menores valores posibles para sus parámetros ($\\theta_{0}$ y $\\theta_{1}$). Por otro lado, también se agregó el parámetro alpha a la configuración del modelo con un valor de 0.05, el cual básicamente tiene la función de controlar la magnitud de la regularización aplicada a la función J al multiplicar la regularización por ese coeficiente (0.05), motivo por el cual, entre mayor sea el valor de dicho alpha, la regularización aplicada sobre J también será mayor y viceversa, por lo cual, en caso de que los parámetros comiencen a tener valores grandes, el algoritmo incrementará el valor del parámetro alpha para aplicar una regularización mayor sobre J y así reducir lo mayor posible el valor de los parámetros de la regresión, además, también se incluye el parámetro fit_intercept = True para configurar el algoritmo, mismo que tiene el propósito de indicar básicamente si los datos están centrados en su media, por lo que al asignar un valor True a dicho parámetro, se está indicando que los datos empleados para entrenar el modelo no se encuentran centrados, lo cual implicará que el algoritmo además de estimar el valor adecuado para la pendiente del modelo $\\theta_{1}$, también deberá estimar el valor adecuado para el intercepto de dicho modelo ($\\theta_{0}$), ya que los datos al no estar centrados, dicho intercepto deberá cumplir con la condición de ser distinto de 0 ($\\theta_{0} \\neq 0$). Adicionalmente, otro parámetro importante en la configuración y además para el entrenamiento del modelo es el parámetro max_iter que tiene asignado un valor de 410000, lo cual indica que el entrenamiento del algoritmo finalizará como máximo cuando se alcancen 410000 épocas de entrenamiento, donde las épocas se definen como las veces que el algoritmo recorre todo el subconjunto de datos de entrenamiento para actualizar los parámetros del modelo con tal de adecuarlos de una mejor manera a los patrones o tendencias de los datos utilizados, por lo que en caso de que el algoritmo no logre converger antes de 410000 iteraciones o épocas, el valor de 410000 en el parámetro max_iter servirá como un paro de emergencia para que el algoritmo no se quede iterando infinitamente y con ello, garantizar la obtención de alguna respuesta de parte del algoritmo dentro de la cantidad establecida de iteraciones para su entrenamiento. Por otra parte, el parámetro tol = 0.01 está asociado con el criterio de paro o de convergencia del algoritmo, en el sentido de que la convergencia del algoritmo ocurrirá cuando el valor de la función de costo J ya no sea inferior al valor de costo mínimo logrado hasta el momento por el algoritmo menos dicho nivel de tolerancia (tol), además de lo anterior, también se incluyó el parámetro learning_rate = \"constant\", mismo que establece que la tasa de aprendizaje del algoritmo sea constante a lo largo del entrenamiento del modelo, en base al hecho de que dicha tasa de aprendizaje denotada como $\\alpha$, se mantendrá constante durante toda la etapa del entrenamiento del modelo con el objetivo principal de estudiar los efectos que tienen otros parámetros diferentes del algoritmo sobre el rendimiento del mismo que no sea la tasa de aprendizaje, además en cada iteración, el algoritmo calculará el valor para el costo J, por lo que en caso de que el algoritmo ya no logre disminuir en 0.01 unidades la pérdida J calculada durante un periodo mínimo de 10 iteraciones, se producirá lo que se conoce como una finalización temprana del entrenamiento del algoritmo, lo cual a su vez se encuentra directamente relacionado con el parámetro booleano early_stopping (se mencionará más adelante) cuyo valor es igual a True. Aparte de todos los parámetros descritos con anterioridad, otro parámetro importante para el entrenamiento del modelo es eta0 que prácticamente hace referencia al valor asignado inicialmente a la tasa de aprendizaje del algoritmo que a su vez significa la rapidez a la que éste mismo aprende los patrones implícitos entre los datos, por lo cual un valor de eta0 grande puede provocar que el algoritmo diverga y como consecuencia se obtengan predicciones muy alejadas de los datos reales, mientras que si dicho valor de eta0 es muy pequeño, se garantiza que el algoritmo eventualmente converga tras una cierta cantidad de iteraciones, por lo general muy alta ya que al aprender a un ritmo muy lento, el algoritmo ocupa muchas más iteraciones para lograr entrenarse adecuadamente. Adicionalmente, el parámetro early_stopping = True se refiere a que se detenga el entrenamiento del modelo en caso de que la puntuación obtenida al momento de que el algoritmo valida el modelo entrenado ya no mejore, por lo que en dicho caso, el algoritmo automáticamente procederá a generar un subconjunto de datos para validación del modelo a partir de los datos de entrenamiento del mismo, por lo cual, el entrenamiento del modelo se detendrá cuando el puntaje de la validación del mismo no mejore al menos por la cantidad de tolerancia establecida (tol) durante la cantidad de iteraciones establecida en el parámetro n_iter_no_change, por lo cual, finalmente, el parámetro n_iter_no_change hace alusión a la cantidad de iteraciones a esperar para detener el entrenamiento del modelo en caso de que durante dicho número de iteraciones, la puntuación de validación del modelo mencionada anteriormente ya no sea menor a la mejor pérdida J obtenida durante todo el proceso de entrenamiento del modelo, por lo que específicamente para el modelo a implementar, el entrenamiento finalizará en automático si durante 10 iteraciones, la puntuación de validación ya no resulte ser inferior a la pérdida óptima J hasta ese momento. \n",
    "\n",
    "**Nota 1:** no confundir alpha (controlador de la magnitud de la regularización) con $\\alpha$ o eta0 (valor inicial de la tasa de aprendizaje).\n",
    "\n",
    "**Nota 2:** el valor de 0.05 para el parámetro alpha se escogió debido a que el algoritmo no necesita un alto nivel de regularización para converger, esto porque al usar un valor para la tasa de aprendizaje $\\alpha$ muy pequeño, prácticamente se consigue que se cumple el hecho de que la J mínima conseguida menos una cierta tolerancia (tol) no pueda continuar disminuyendo, por lo que se logra la convergencia del algoritmo, sin embargo se coloca el coeficiente alpha para regularización para que en caso de obtener valores de $\\theta$ muy grandes sobretodo en las primeras iteraciones del algoritmo, se aplique la penalización a la función J y así lograr disminuir la magnitud de los coeficientes resultantes para no tener al final resultados que sean excesivamente grandes a tal punto que Python ya no pueda manejarlos y arroje como resultado valores inf o nan.\n",
    "\n",
    "**Nota 3:** Se asignó el valor True al parámetro fit_intercept para que el algoritmo también estime el valor adecuado para el intercepto $\\theta_{0}$ aparte de determinar el mejor valor para la pendiente $\\theta_{1}$, dado que los datos con los que vamos a entrenar el modelo, no se encuentran centrados en su media.\n",
    "\n",
    "**Nota 4:** Se eligió entrenar el modelo específicamente con 410000 iteraciones porque al ser una cantidad mayormente considerable de iteraciones, eleva las posibilidades de que el algoritmo finalmente converga, al permitir que los valores de costo J sean cada vez más bajos al punto de que eventualmente, se alcance el punto de convergencia del algoritmo, ya que se habrán permitido una mayor cantidad de actualizaciones para los parámetros $\\theta$ hasta finalmente terminar de ajustarlos de forma adecuada a los datos usados para entrenar el modelo.\n",
    "\n",
    "**Nota 5:** Se eligió una tolerancia (tol) de 0.01 porque al ser un valor mayormente bajo, es adecuado para definir el mínimo cambio que esperamos que ocurra en los valores de pérdida J para continuar con el entrenamiento del modelo, por lo que si dicho cambio esperado es inferior a 0.01, prácticamente se podrá concluir que el cambio sucedido es despreciable al ser un valor muy cercano a 0, por lo cual, podremos considerar que básicamente ya no hay cambio significativo en los valores de J, por lo que ya no tendrá sentido continuar entrenando el modelo y por consiguiente dicho entrenamiento habrá finalizado.\n",
    "\n",
    "**Nota 6:** Se escogió un tipo de tasa de aprendizaje constante porque al tener un $\\alpha$ constante pero considerando el resto de los parámetros para la configuración del algoritmo, es posible explorar otras alternativas de modelos para los datos usados, ya que al variar algunos otros parámetros del algoritmo, se puede explorar qué tan bien se ajustan otros modelos a los datos que tengan una diferente configuración y ver cómo impactan configuraciones diferentes en la calidad de las predicciones derivadas de los distintos modelos entrenados, lo cual amplia prácticamente el espacio de búsqueda de todos los posibles modelos que se pueden ajustar a los datos para finalmente también incrementar la probabilidad de encontrar un modelo en dicho espacio de búsqueda ampliado que se ajuste de la mejor manera posible a nuestros datos que no podríamos encontrar si durante la etapa de entrenamiento del modelo, no se probaran diferentes valores para los demás parámetros del algoritmo aparte de la tasa de aprendizaje. \n",
    "\n",
    "**Nota 7:** Se seleccionó un valor de 0.0001 para el parámetro eta0 (tasa de aprendizaje inicial), ya que al ser un valor mayormente pequeño, permitirá que el modelo durante su etapa de entrenamiento, aprenda a un ritmo mayormente lento, lo cual muy probablemente garantizará que el algoritmo no pase por alto el punto de convergencia que generalmente sucede cuando se asigna un valor inicial grande a la tasa de aprendizaje, por lo que eso también asegurará que el entrenamiento en general sea el adecuado para el modelo y que éste mismo al converger, aprenda los patrones que siguen los datos usados para su entrenamiento y sea capaz de generalizarlos para predecir de forma mayormente correcta las salidas para nuevos datos que el modelo aún no conozca.\n",
    "\n",
    "**Nota 8:** Se elige un valor booleano True para el parámetro early_stopping para que finalice el entrenamiento del modelo en caso de que el puntaje de validación obtenido en su entrenamiento ya no sea inferior al valor mínimo de pérdida obtenido hasta el momento, por lo que si esto sucede durante 10 iteraciones de entrenamiento consecutivas, se asume que ya no hay una mayor mejoría posible para los parámetros del modelo, por lo que el entrenamiento del mismo termina en ese punto. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25c517c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de regresión lineal con gradiente descendente estocástico con los parámetros mostrados\n",
    "\n",
    "regresion_lineal = SGDRegressor(loss = \"squared_error\", penalty = \"l2\", alpha = 0.05, fit_intercept = True, \n",
    "                                max_iter = 410000, tol = 0.01, learning_rate = \"constant\", eta0 = 0.0001, \n",
    "                                early_stopping = True, n_iter_no_change = 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62185f",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d79e5856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.05, early_stopping=True, eta0=0.0001,\n",
       "             learning_rate='constant', max_iter=410000, n_iter_no_change=10,\n",
       "             tol=0.01)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo de regresión lineal creado anteriormente\n",
    "\n",
    "# El primer argumento de la función fit() son los valores de la variable predictora Celsius del\n",
    "# subset de entrenamiento\n",
    "\n",
    "# El segundo argumento de fit() son los valores de la variable objetivo Valks del subset de \n",
    "# entrenamiento\n",
    "\n",
    "\"\"\"Nota: dado que el método fit() admite solamente arreglos de 2 dimensiones para el caso de la varible predictora, \n",
    "   se procede a convertir dicho arreglo 1D que contiene los valores de Celsius a un arreglo de numpy y posteriormente, \n",
    "   se reestructura dicho arreglo con el método reshape() para que sea un arreglo 2D, por lo que el nuevo arreglo 2D tiene\n",
    "   filas que son en realidad otros arreglos con un solo elemento en ellos, además de que el nuevo arreglo 2D también tiene\n",
    "   1 columna de datos, por lo cual, la nueva forma de los datos de celsius es (70, 1) en vez de (70,), por lo cual, el nuevo\n",
    "   arreglo 2D ya puede ser aceptado por el método fit() para entrenar el modelo.\"\"\"\n",
    "\n",
    "regresion_lineal.fit(data_train[\"Celsius\"].to_numpy().reshape(-1, 1), data_train[\"Valks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ae84d",
   "metadata": {},
   "source": [
    "## Prueba del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1ea9d",
   "metadata": {},
   "source": [
    "### Cálculo de las predicciones de los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0ca92241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-135.85359403,   29.35197158, -140.22515021,  -61.72962932,\n",
       "        -47.16368519,  -65.80231897,  -75.52561223,   16.02328422,\n",
       "         40.54680258, -106.1163744 ,   63.6651417 ,    8.10002861,\n",
       "        -55.43823561,   42.57023029,    8.30594258, -158.62823665,\n",
       "       -173.11819776, -159.2259697 ,   31.52381945, -137.72024346,\n",
       "        -71.10593348,    2.17259354,  -99.44253285,  -65.88843306,\n",
       "         34.8969588 ,   53.49861418, -163.84826983, -169.71922419,\n",
       "        -87.45241295, -156.70586634])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular la predicción en Valks para cada uno de los valores de celsius del subset de datos de prueba,\n",
    "# por medio del método predict() del modelo entrenado\n",
    "\n",
    "# Nota: los datos en celsius del subset de datos de prueba, se transforman en un arreglo de numpy \n",
    "# bidimensional para ser aceptado por el método predict() del modelo \n",
    "\n",
    "# Guardar las predicciones calculadas en la variable valks_predicted\n",
    "\n",
    "valks_predicted = regresion_lineal.predict(data_test[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Mostrar las primeras equivalencias en Valks de los datos en celsius del subset de datos de prueba\n",
    "\n",
    "valks_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bbe71",
   "metadata": {},
   "source": [
    "### Gráfica de los datos reales vs las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "844d707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar en un mismo gráfico, los grados celsius vs valks verdaderos del subset de prueba\n",
    "\n",
    "plt.scatter(data_test[\"Celsius\"], data_test[\"Valks\"], color = \"green\", label = \"Reales\")\n",
    "\n",
    "# Graficar dentro del mismo gráfico, los grados celsius del subset de prueba vs las predicciones en Valks\n",
    "# hechas por el modelo\n",
    "\n",
    "# Función plot para trazar la tendencia de las predicciones con una recta que pase por los puntos \n",
    "# correspondientes a las mismas\n",
    "\n",
    "plt.plot(data_test[\"Celsius\"], valks_predicted, color = \"purple\", linewidth = 2, label = \"Predicciones\")\n",
    "\n",
    "# Graficar grados celsius en el eje horizontal\n",
    "\n",
    "plt.xlabel(\"Celsius\") \n",
    "\n",
    "# Graficar Valks en el eje vertical\n",
    "\n",
    "plt.ylabel(\"Valks\") \n",
    "\n",
    "# Título del gráfico\n",
    "\n",
    "plt.title(\"Regresión lineal: Celsius vs Valks\") \n",
    "\n",
    "# Agregar leyenda al gráfico\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gráfico de datos reales vs predicciones del modelo\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ccfb94ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valks = 22.054309465749657 + -2.5327671943532715 * Celsius\n"
     ]
    }
   ],
   "source": [
    "# Mostrar ecuación del modelo calculado para el subconjunto de datos de prueba\n",
    "\n",
    "print(f'Valks = {regresion_lineal.intercept_[0]} + {regresion_lineal.coef_[0]} * Celsius')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52aef4",
   "metadata": {},
   "source": [
    "## Cálculo de métrica de error: error cuadrático medio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf030ce",
   "metadata": {},
   "source": [
    "### Error cuadrático medio (MSE) para subconjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "541e485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  36.77323274, -133.63995551,  -50.22580073,    2.79894687,\n",
       "        -34.11233584,  -38.41297453,  -53.51333254,  -46.17590598,\n",
       "          9.11592153,   69.69566039,   22.91664071, -169.80533827,\n",
       "          7.48887188,  -40.14792006, -118.19260839,  -93.21192555,\n",
       "        -99.1993872 ,  -26.63307431, -171.67452046,  -13.50320918,\n",
       "         39.80748784,  -23.93061171,   48.10888559, -133.52851375,\n",
       "       -115.50787516,  -51.33515276, -170.25617083, -170.30682618,\n",
       "       -121.17874091,   32.78994977,   48.00504214, -167.95895099,\n",
       "        -12.6749943 ,  -93.3081707 , -162.65027095,  -16.3576378 ,\n",
       "       -103.27460961,    0.31328915, -152.93457599,    2.57150438,\n",
       "        -71.3592102 , -142.35520742, -127.93869655,  -15.93213292,\n",
       "       -170.37014536, -129.98263968, -124.63596813, -119.20824803,\n",
       "        -75.52307946, -104.35103567,  -93.37402265,   63.98427037,\n",
       "        -83.31893689,  -90.98562319, -106.95472035, -119.0714786 ,\n",
       "         64.64785537,  -23.64947456,   11.03044025, -128.69599394,\n",
       "         61.01586722,   25.37907296,   37.5994214 ,  -66.52162486,\n",
       "       -118.43575404,   59.04537434,   -7.60439438, -159.59322095,\n",
       "       -117.56954766, -163.85333537])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar la función mean_squared_error() del módulo metrics de la librería Scikit-Learn\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Utilizar el modelo entrenado para predecir los grados Valks a partir de los grados celsius\n",
    "# del subconjunto de datos de entrenamiento\n",
    "\n",
    "predictions_train = regresion_lineal.predict(data_train[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Mostrar las predicciones realizadas\n",
    "\n",
    "predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee22dfe",
   "metadata": {},
   "source": [
    "A continuación, se procederá a calcular el valor del MSE (error cuadrático medio) para el subconjunto de datos de entrenamiento, para lo cual en base a las predicciones en Valks calculadas para cada valor en celsius del subset de entrenamiento, se calculará el valor del MSE mediante la sumatoria de los cuadrados de las diferencias entre los datos en valks reales del conjunto de entrenamiento y las predicciones igualmente en valks que el modelo calculó para cada datos en celsius del susbset de entrenamiento y multiplicando el resultado de dicha sumatoria por $\\frac{1}{n}$, esto se representa matemáticamente por medio de la siguiente expresión:\n",
    "\n",
    "$MSE = \\frac{1}{n}\\sum_{i = 1}^{n}{(y - \\hat{y})^{2}}$\n",
    "\n",
    "Donde n se refiere a la cantidad de observaciones del subconjunto de entrenamiento, $y$ hace referencia a los datos verdaderos en valks del subset de entrenamiento y $\\hat{y}$ representa las predicciones en valks para cada dato en celsius del subconjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10f3b3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para subconjunto de datos de entrenamiento: 386.13185469075336\n"
     ]
    }
   ],
   "source": [
    "# Calcular el valor del MSE para el subconjunto de datos de entrenamiento mediante la función mean_squared_error()\n",
    "\n",
    "# data_train[\"Valks\"] se refiere a los datos en valks reales del conjunto de entrenamiento\n",
    "\n",
    "# predictions_train hace referencia a los valores en valks predichos por el modelo para los \n",
    "# datos del subset de entrenamiento\n",
    "\n",
    "train_MSE = mean_squared_error(data_train[\"Valks\"], predictions_train)\n",
    "\n",
    "# Mostrar el valor del MSE para el subconjunto de datos de entrenamiento\n",
    "\n",
    "print(f'MSE para subconjunto de datos de entrenamiento: {train_MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517d602",
   "metadata": {},
   "source": [
    "### Error cuadrático medio (MSE) para subconjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "31a9e6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para subconjunto de datos de prueba: 382.4533753226244\n"
     ]
    }
   ],
   "source": [
    "# Calcular el valor del MSE para el subconjunto de datos de prueba mediante la función mean_squared_error()\n",
    "\n",
    "# data_test[\"Valks\"] se refiere a los datos en valks reales del conjunto de prueba\n",
    "\n",
    "# valks_predicted se refiere a los datos en valks predichos por el modelo para cada dato en celsius del\n",
    "# subconjunto de prueba\n",
    "\n",
    "test_MSE = mean_squared_error(data_test[\"Valks\"], valks_predicted)\n",
    "\n",
    "# Mostrar el valor del MSE para el subconjunto de datos de prueba\n",
    "\n",
    "print(f'MSE para subconjunto de datos de prueba: {test_MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577362db",
   "metadata": {},
   "source": [
    "### $R^{2}$ para el subconjunto de datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98627d3",
   "metadata": {},
   "source": [
    "A manera de complemento, se procederá a calcular el valor del coeficiente de determinación $R^{2}$ para evaluar modelos de regresión, por lo que en términos generales, el valor de dicho coeficiente hace referencia a la proporción o porcentaje de la variabilidad total de los datos que es explicada por el modelo de regresión calculado por el algoritmo, motivo por el cual, entre más cercano a 1 sea el valor del $R^{2}$, el modelo será capaz de explicar una mayor proporción de variabilidad de los datos, lo cual implicará que dicho modelo sea más confiable para predecir la equivalencia en Valks de una cierta cantidad de grados celsius, lo cual a su vez será benéfico para evitar realizar una configuración errónea de la máquina reguladora de temperatura descrita en el challenge 1 de Valhalla, además el coeficiente de determinación está dado por la expresión:\n",
    "\n",
    "$R^{2} = 1 - \\frac{\\sum_{i = 1}^{n}{(y_{i} - \\hat{y_{i}})^{2}}}{\\sum_{i = 1}^{n}{(y_{i} - \\bar{y})}}$\n",
    "\n",
    "Donde a 1 se le resta el cociente de 2 sumatorias, la primera de ellas es la suma de los cuadrados de las diferencias entre los datos reales en Valks del subconjunto de prueba y los valores predichos en valks para cada dato en celsius del subset de prueba, mientras que la segunda sumatoria (la que está en el denominador) se refiere a la suma de las diferencias entre los datos en valks reales del subconjunto de prueba y la media de dichos datos en valks reales del subconjunto de datos de prueba también. \n",
    "\n",
    "* $y_{i}$ se refiere a los datos en valks reales del subconjunto de prueba.\n",
    "\n",
    "* $n$ se refiere a la cantidad de datos (filas) del subconjunto de prueba.\n",
    "\n",
    "* $\\hat{y_{i}}$ representa los datos en valks predichos por el modelo para el subconjunto de prueba.\n",
    "\n",
    "* $\\bar{y}$ representa la media de los datos en valks reales del subset de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9cabbc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.9523710043326618\n"
     ]
    }
   ],
   "source": [
    "# Calcular el valor del coeficiente de determinación R2 para las predicciones del subset de prueba\n",
    "\n",
    "# Importar la función r2_score() para calcular el coeficiente R^2 del modelo de regresión\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Para obtener el R2, se comparan las predicciones de valks hechas por el modelo para el subset de prueba y \n",
    "# los valores verdaderos de valks del subset de prueba\n",
    "\n",
    "R2 = r2_score(data_test[\"Valks\"], valks_predicted)\n",
    "\n",
    "# Mostrar valor del coeficiente de determinación R2\n",
    "\n",
    "print(f'R2 = {R2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a0890a",
   "metadata": {},
   "source": [
    "Por último, se observa que el valor del coeficiente de determinación $R^{2}$ es igual a 0.9523, lo cual significa que el modelo entrenado es capaz de explicar el 95.23% de la variabilidad total de los datos, lo cual al ser considerablemente superior al 70% u 80% de variabilidad explicada, es posible afirmar que el modelo es capaz de generalizar de forma bastante acertada los patrones y tendencias que siguen los datos analizados, por lo cual, solamente existe un 4.77% de margen de error en las predicciones del modelo de regresión lineal, evidenciando así que el desempeño del modelo en general es en su gran mayoría adecuada, además de que las predicciones de las equivalencias en valks de los grados celsius, derivadas del mismo también son altamente confiables, por lo que el modelo obtenido es una alternativa adecuada para resolver el problema del calentamiento global en la tierra planteado inicialmente en el challenge 1 de Valhalla. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
