{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffdabdb",
   "metadata": {},
   "source": [
    "# Análisis y reporte sobre el desempeño del modelo: Valhalla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bb161",
   "metadata": {},
   "source": [
    "**Autor:** Rodolfo Jesús Cruz Rebollar\n",
    "\n",
    "**Matrícula:** A01368326\n",
    "\n",
    "**Grupo:** 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a4cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librería random para trabajar con valores aleatorios\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "# Definir una semilla con los últimos 4 dígitos de mi matrícula (8326)\n",
    "\n",
    "semilla = rnd.seed(8326)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d8c34",
   "metadata": {},
   "source": [
    "## Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d071704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Numpy para trabajar con arreglos multidimensionales\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Importar Pandas para manipular y analizar datos\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importar matplotlib para realizar gráficos\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importar el regresor lineal con gradiente estocástico de la librería Scikit-Learn\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Importar función train_test_split() del módulo model_selection de Scikit-Learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d47d42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.4720</td>\n",
       "      <td>-139.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.5790</td>\n",
       "      <td>-156.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.3013</td>\n",
       "      <td>73.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.3380</td>\n",
       "      <td>-165.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.2360</td>\n",
       "      <td>-75.835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Celsius    Valks\n",
       "0  61.4720 -139.740\n",
       "1  70.5790 -156.600\n",
       "2  -7.3013   73.269\n",
       "3  71.3380 -165.420\n",
       "4  43.2360  -75.835"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar el set de datos de Valhalla\n",
    "\n",
    "valhalla = pd.read_csv(\"Valhalla23.csv\")\n",
    "\n",
    "# Verificar la correcta importación de los datos\n",
    "\n",
    "valhalla.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73117f1",
   "metadata": {},
   "source": [
    "## Generación de subsets de entrenamiento, prueba y validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa9b16",
   "metadata": {},
   "source": [
    "Los porcentajes para entrenamiento, prueba y validación a considerar serán:\n",
    "\n",
    "* Entrenamiento: 40%\n",
    "\n",
    "* Prueba: 20%\n",
    "\n",
    "* Validación: 40%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ad5ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset total en un subconjunto de entrenamiento y otro para prueba con la función train_test_split()\n",
    "\n",
    "# Nota: se agregó el parámetro random_state con la semilla definida previamente para que al momento de generar los subsets\n",
    "# aleatoriamente, se obtengan los mismos datos para cada subconjunto en las diferentes ocasiones que se corra el código \n",
    "\n",
    "c_train, c_test, v_train, v_test = train_test_split(valhalla[\"Celsius\"], valhalla[\"Valks\"], test_size = 0.6, \n",
    "                                                   train_size = 0.4, random_state = semilla)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e34fec",
   "metadata": {},
   "source": [
    "### Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e82f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>26.9390</td>\n",
       "      <td>-34.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>47.9700</td>\n",
       "      <td>-95.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-5.0706</td>\n",
       "      <td>64.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75.9490</td>\n",
       "      <td>-174.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>27.3290</td>\n",
       "      <td>-27.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "97  26.9390  -34.255\n",
       "51  47.9700  -95.258\n",
       "68  -5.0706   64.106\n",
       "19  75.9490 -174.920\n",
       "79  27.3290  -27.032"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formar el subset de entrenamiento con los datos en celsius y valks para entrenamiento (c_train y v_train)\n",
    "\n",
    "# Introducir los datos como un diccionario al dataframe para que al momento de formar el subset de entrenamiento, \n",
    "# los nombres de sus columnas sean automáticamente las claves del diccionario y cada clave se asocie a la serie de\n",
    "# datos correspondiente\n",
    "\n",
    "datos_train = pd.DataFrame({\"Celsius\": c_train, \"Valks\": v_train})\n",
    "\n",
    "# Verificar que el subset de entrenamiento se haya creado correctamente\n",
    "\n",
    "datos_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e3d36",
   "metadata": {},
   "source": [
    "### Conjuntos de validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040e5c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>34.9720</td>\n",
       "      <td>-54.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-7.0094</td>\n",
       "      <td>69.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60.0280</td>\n",
       "      <td>-142.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>28.9760</td>\n",
       "      <td>-40.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>38.5260</td>\n",
       "      <td>-65.580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "83  34.9720  -54.496\n",
       "95  -7.0094   69.632\n",
       "14  60.0280 -142.490\n",
       "45  28.9760  -40.934\n",
       "82  38.5260  -65.580"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formar el subconjunto de prueba inicial con los datos derivados de la partición del dataset total, contenidos en \n",
    "# las variables c_test y v_test, que corresponden a datos en celsius y valks pero esta vez ambos para prueba\n",
    "\n",
    "# Esta vez, la clave Celsius del diccionario tendrá asociados los datos en celsius destinados para formar el conjunto \n",
    "# de prueba inicial, mientras que la clave Valks se asociará con los datos en valks igualmente destinados para el subset\n",
    "# inicial de prueba\n",
    "\n",
    "# Se denomina subset de prueba inicial porque aún falta realizar otra partición sobre el conjunto de prueba inicial para\n",
    "# formar el conjunto de validación\n",
    "\n",
    "test_0 = pd.DataFrame({\"Celsius\": c_test, \"Valks\": v_test})\n",
    "\n",
    "# Mostrar la correcta generación de subset inicial de prueba\n",
    "\n",
    "test_0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3fcdb",
   "metadata": {},
   "source": [
    "Ahora en base al subset de prueba inicial creado previamente, se creará un tercer subconjunto de datos destinado para la validación del modelo, que se define como la etapa en la cual, se ajustan los hiperparámetros del modelo entrenado para que éstos tengan los mejores valores posibles para que el modelo en si mismo se logre ajustar de manera adecuada a los datos de prueba cuando una vez que se hayan determinado los parámetros óptimos del modelo y ahora sí se proceda a evaluar el grado de desempeño del modelo con los parámetros optimizados en la etapa de validación anterior, por lo cual, para crear el subset de validación, se tomará como base el subset de prueba inicial que ya hemos creado almacenado en test_0, para luego volver a emplear la función train_test_split() de Scikit-Learn, pero ahora dicha función se aplicará sobre el subset de prueba inicial (test_0) obtenido antes y como parámetros de entrada de la función, en esta ocasión, la proporción del subset que se utilizará para \"entrenamiento\" que en realidad será el conjunto de validación, será del 66.67% (2/3), mientras que el 33.33% (1/3) sobrante se destinará para el \"test\" que en realidad será el subset de prueba definitivo para probar el modelo una vez optimizados sus hiperparámetros en la etapa anterior de validación. \n",
    "\n",
    "Además de lo anterior, también es importante mencionar que en relación a la forma en la que se obtuvieron los porcentajes para \"train\" (subset de validación) y \"test\" (subset de prueba definitivo) derivados del subset de prueba inicial test_0, en primera instancia, la proporción para el subset de validación se obtuvo calculando qué proporción corresponde al 40% del 60% de algo, como se muestra a continuación:\n",
    "\n",
    "$\\frac{40\\%}{60\\%} = \\frac{40}{60} = \\frac{4}{6} = \\frac{2}{3} = 0.\\bar{6}$\n",
    "\n",
    "Por lo tanto, lo anterior significa que el 66.67% ($\\frac{2}{3} * 100\\%$) de los datos del subset de prueba inicial (test_0) corresponde en realidad al 40% del conjunto total de datos, ya que:\n",
    "\n",
    "$\\frac{x}{60\\%} = \\frac{2}{3} \\rightarrow x = \\frac{2}{3} * 60\\% \\rightarrow x = 40\\%$\n",
    "\n",
    "La ecuación previa hace referencia a que deseamos saber qué parte del 60% de algo equivale a $\\frac{2}{3}$ de ese algo, por lo cual, se despega la incógnita $x$ y después de realizar las operaciones aritméticas correspondientes, se obtiene que $x = 40\\%$, lo que significa que la proporción del $60\\%$ de algo que equivale a $\\frac{2}{3}$ de ese algo es igual al $40\\%$, lo cual es el porcentaje de datos del conjunto total de datos que será destinado al proceso de validación del modelo. \n",
    "\n",
    "Adicionalmente, dado que ya se obtuvo que $\\frac{2}{3}$ del subset de datos test_0 será destinado a la validación del modelo, el complemento de dicha proporción sabiendo que la totalidad del subset de datos se representa como 1 ($100\\%$), será igual a $\\frac{1}{3}$ o bien, ($1 - \\frac{2}{3}$), por lo cual se utilizará el $\\frac{1}{3}$ restante del subset test_0 para el proceso de prueba del modelo después de terminar la etapa de validación del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10367d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar una 2da división del subconjunto de prueba inicial test_0 para formar posteriormente el subset de \n",
    "# validación y el subset de prueba definitivo\n",
    "\n",
    "c_validacion, c_test_real, v_validacion, v_test_real = train_test_split(test_0[\"Celsius\"], test_0[\"Valks\"], \n",
    "                                                                       train_size = 2/3, test_size = 1/3, \n",
    "                                                                       random_state = semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5d00886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>64.0720</td>\n",
       "      <td>-127.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.3380</td>\n",
       "      <td>-165.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5.4282</td>\n",
       "      <td>33.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>34.9720</td>\n",
       "      <td>-54.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>28.9760</td>\n",
       "      <td>-40.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius    Valks\n",
       "70  64.0720 -127.100\n",
       "3   71.3380 -165.420\n",
       "71   5.4282   33.215\n",
       "83  34.9720  -54.496\n",
       "45  28.9760  -40.934"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formar un dataframe que corresponderá al subset de validación para el modelo\n",
    "\n",
    "# En esta ocasión, el diccionario pasado como argumento al dataframe tendrá las mismas claves, solamente que\n",
    "# los datos asociados a cada una de ellas ahora serán los destinados para validación del modelo definidos arriba\n",
    "\n",
    "validation = pd.DataFrame({\"Celsius\": c_validacion, \"Valks\": v_validacion})\n",
    "\n",
    "# Mostrar la correcta creación del subset de datos para validación \n",
    "\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e53736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Celsius</th>\n",
       "      <th>Valks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70.579</td>\n",
       "      <td>-156.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>55.127</td>\n",
       "      <td>-100.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>57.917</td>\n",
       "      <td>-107.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76.489</td>\n",
       "      <td>-183.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>73.401</td>\n",
       "      <td>-169.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Celsius   Valks\n",
       "1    70.579 -156.60\n",
       "60   55.127 -100.09\n",
       "93   57.917 -107.37\n",
       "9    76.489 -183.46\n",
       "94   73.401 -169.76"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora se procederá a crear el dataframe correspondiente al subset de prueba definitivo \n",
    "\n",
    "# Ahora el diccionario pasado al dataframe asocia cada una de sus claves con los datos en\n",
    "# celsius y en valks destinados específicamente para el test del modelo\n",
    "\n",
    "# Este subset de prueba ya es el definitivo\n",
    "\n",
    "test_definitivo = pd.DataFrame({\"Celsius\": c_test_real, \"Valks\": v_test_real})\n",
    "\n",
    "# Mostrar la correcta generación del subset de prueba definitivo\n",
    "\n",
    "test_definitivo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a1e9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de datos para entrenamiento: 40\n",
      "Cantidad de datos para prueba: 20\n",
      "Cantidad de datos para validación: 40\n"
     ]
    }
   ],
   "source": [
    "# Validar que sean 40 datos para entrenamiento (40% de 100 datos que tiene el conjunto total de datos)\n",
    "\n",
    "print(f'Cantidad de datos para entrenamiento: {datos_train.shape[0]}') \n",
    "\n",
    "# Validar que sean 20 datos para prueba (20% de 100 datos que tiene el conjunto total de datos)\n",
    "\n",
    "print(f'Cantidad de datos para prueba: {test_definitivo.shape[0]}')\n",
    "\n",
    "# Validar que sean 40 datos para validación (40% de 100 datos que tiene el conjunto total de datos)\n",
    "\n",
    "print(f'Cantidad de datos para validación: {validation.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd6584d",
   "metadata": {},
   "source": [
    "## Modelo base de tipo SGDRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f75c2b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(eta0=0.0001, max_iter=1000000.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir un modelo base de tipo SGDRegressor que tenga como parámetros: el error cuadrático como función de \n",
    "# pérdida o costo a usar, una tasa de aprendizaje (eta0) inicial de 1e-04 y que usa la semilla definida \n",
    "# inicialmente para obtener la misma salida del modelo al ejecutar el código varias veces\n",
    "\n",
    "modelo_base = SGDRegressor(loss = \"squared_error\", eta0 = 1e-04, max_iter = 1e+06, random_state = semilla)\n",
    "\n",
    "# Utilizar la función fit() aplicada sobre el modelo creado para entrenarlo usando el subset de entrenamiento\n",
    "\n",
    "modelo_base.fit(datos_train[\"Celsius\"].to_numpy().reshape(-1, 1), datos_train[\"Valks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00cb6d",
   "metadata": {},
   "source": [
    "## Cálcular el MSE (error cuadrático medio) para subset de entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d01049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Del módulo metrics perteneciente a la librería Scikit-Learn importar la función mean_squared_error para calcular el MSE\n",
    "# del modelo para cada subset de datos\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81df1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenar datos de entrenamiento para reorganizarlos y que las predicciones para cada uno estén organizadas correctamente\n",
    "\n",
    "training_sorted = datos_train.sort_values(by = \"Celsius\", ignore_index = True)\n",
    "\n",
    "# Reordenar datos de validación para reorganizarlos y que las predicciones para cada uno estén correctamente organizadas\n",
    "\n",
    "validation_sorted = validation.sort_values(by = \"Celsius\", ignore_index = True)\n",
    "\n",
    "# Reordenar datos de prueba para reorganizarlos y que las predicciones para cada uno estén correctamente organizadas\n",
    "\n",
    "test_sorted = test_definitivo.sort_values(by = \"Celsius\", ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b28629",
   "metadata": {},
   "source": [
    "### MSE para subset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ddd756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para subconjunto de entrenamiento: 110.05915032672912\n"
     ]
    }
   ],
   "source": [
    "# Calcular los datos en Valks predichos para los datos en celsius del subset de entrenamiento\n",
    "# utilizando los coeficientes obtenidos durante el entrenamiento del modelo\n",
    "\n",
    "\"\"\"Nota: dado que el método fit() admite solamente arreglos de 2 dimensiones para el caso de la varible predictora, \n",
    "   se procede a convertir dicho arreglo 1D que contiene los valores de Celsius a un arreglo de numpy y posteriormente, \n",
    "   se reestructura dicho arreglo con el método reshape() para que sea un arreglo 2D, por lo cual, el nuevo arreglo 2D tiene\n",
    "   filas que son otros arreglos con 1 solo elemento, además de que el nuevo arreglo 2D también tiene\n",
    "   1 columna de datos, por lo tanto, la nueva forma de los datos de celsius es (40, 1) en vez de (40,), por lo cual, el nuevo\n",
    "   arreglo 2D ya puede ser aceptado por el método fit() para entrenar el modelo.\"\"\"\n",
    "\n",
    "train_predictions = modelo_base.predict(training_sorted[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Calcular el MSE para correspondiente al subset de entrenamiento del modelo\n",
    "\n",
    "# Se comparan los verdaderos datos de la variable de respuesta contra los datos predichos para dicha\n",
    "# variable \n",
    "\n",
    "MSE_train = mean_squared_error(training_sorted[\"Valks\"], train_predictions)\n",
    "\n",
    "# Mostrar el valor del MSE para el subset de datos de entrenamiento\n",
    "\n",
    "print(f'MSE para subconjunto de entrenamiento: {MSE_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba87c6",
   "metadata": {},
   "source": [
    "### MSE para subset de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3714ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para subconjunto de validación: 149.39443502824105\n"
     ]
    }
   ],
   "source": [
    "# Calcular los datos en Valks predichos para los datos en celsius del subset de validación\n",
    "# mediante la función predict aplicada sobre los datos en celsius de dicho subset de datos\n",
    "\n",
    "validation_predictions = modelo_base.predict(validation_sorted[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Calcular el MSE para correspondiente al subset de validación del modelo\n",
    "\n",
    "# Se comparan los verdaderos datos de la variable de respuesta contra los datos predichos para dicha\n",
    "# variable \n",
    "\n",
    "MSE_validation = mean_squared_error(validation_sorted[\"Valks\"], validation_predictions)\n",
    "\n",
    "# Mostrar el valor del MSE para el subset de datos de validación\n",
    "\n",
    "print(f'MSE para subconjunto de validación: {MSE_validation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32380032",
   "metadata": {},
   "source": [
    "### MSE para subset de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2350eef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para subconjunto de prueba: 167.74772561834524\n"
     ]
    }
   ],
   "source": [
    "# Calcular los datos en Valks predichos para los datos en celsius del subset de prueba\n",
    "# mediante la función predict aplicada sobre los datos en celsius de dicho subset de datos\n",
    "\n",
    "test_predictions = modelo_base.predict(test_sorted[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Calcular el MSE para correspondiente al subset de prueba del modelo\n",
    "\n",
    "# Se comparan los verdaderos datos de la variable de respuesta contra los datos predichos para dicha\n",
    "# variable \n",
    "\n",
    "MSE_test = mean_squared_error(test_sorted[\"Valks\"], test_predictions)\n",
    "\n",
    "# Mostrar el valor del MSE para el subset de datos de prueba\n",
    "\n",
    "print(f'MSE para subconjunto de prueba: {MSE_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a6d1f9",
   "metadata": {},
   "source": [
    "## Gráfica de subsets de entrenamiento, validación, prueba y modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8edeb6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar en un gráfico de dispersión los datos reales del subset de entrenamiento (Celsius vs Valks)\n",
    "\n",
    "plt.scatter(training_sorted[\"Celsius\"], training_sorted[\"Valks\"], color = \"green\", label = \"Reales train\")\n",
    "\n",
    "# Graficar en el mismo gráfico la tendencia de las predicciones de entrenamiento con una recta que pase por ellas\n",
    "\n",
    "#plt.plot(training_sorted[\"Celsius\"], train_predictions, color = \"red\", linewidth = 2, label = \"Modelo obtenido\")\n",
    "\n",
    "# Graficar en el mismo gráfico de dispersión los datos reales del subset de validación (Celsius vs Valks)\n",
    "\n",
    "plt.scatter(validation_sorted[\"Celsius\"], validation_sorted[\"Valks\"], color = \"gold\", label = \"Reales validación\")\n",
    "\n",
    "# Graficar en el mismo gráfico la tendencia de las predicciones de validación con una recta que pase por ellas\n",
    "\n",
    "plt.plot(validation_sorted[\"Celsius\"], validation_predictions, color = \"red\", linewidth = 2, \n",
    "         label = \"Modelo obtenido\")\n",
    "\n",
    "# Graficar en el mismo gráfico de dispersión los datos reales del subset de prueba (Celsius vs Valks)\n",
    "\n",
    "plt.scatter(test_sorted[\"Celsius\"], test_sorted[\"Valks\"], color = \"dodgerblue\", label = \"Reales test\")\n",
    "\n",
    "# Graficar en el mismo gráfico la tendencia de las predicciones de prueba con una recta que pase por ellas\n",
    "\n",
    "#plt.plot(test_sorted[\"Celsius\"], test_predictions, color = \"brown\", linewidth = 2, label = \"Predicciones test\")\n",
    "\n",
    "# Graficar grados celsius en el eje horizontal\n",
    "\n",
    "plt.xlabel(\"Celsius\") \n",
    "\n",
    "# Graficar grados Valks en el eje vertical\n",
    "\n",
    "plt.ylabel(\"Valks\") \n",
    "\n",
    "# Título del gráfico\n",
    "\n",
    "plt.title(\"Celsius vs Valks: train, validation, test\")\n",
    "\n",
    "# Agregar leyenda al gráfico\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gráfico con los datos de los 3 subsets y sus modelos obtenidos\n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0458a",
   "metadata": {},
   "source": [
    "## Creación de instancias para el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0668afb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 23, 30, 33, 16, 9, 11, 24, 37, 8, 38, 22, 31, 19, 17, 21, 29, 34, 10]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una lista de 19 números enteros comprendidos entre 3 y 39, sin repetición\n",
    "\n",
    "# Nota: la lista de enteros ya incluirá al 2\n",
    "\n",
    "instancias_analisis = [2] + rnd.sample(range(3, 40), 19)\n",
    "\n",
    "# Mostrar las instancias (enteros aleatorios del 2 al 39 sin reemplazo e incluyendo al 2) a usar para el análsis\n",
    "\n",
    "instancias_analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c337fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "7     1\n",
       "34    1\n",
       "29    1\n",
       "21    1\n",
       "17    1\n",
       "19    1\n",
       "31    1\n",
       "22    1\n",
       "38    1\n",
       "8     1\n",
       "37    1\n",
       "24    1\n",
       "11    1\n",
       "9     1\n",
       "16    1\n",
       "33    1\n",
       "30    1\n",
       "23    1\n",
       "10    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validar que cada entero de la lista anterior tenga una frecuencia absoluta igual a 1, es decir que \n",
    "# solamente aparezca una vez en la lista y que no haya ningún elemento repetido en ella\n",
    "\n",
    "# Convertimos la lista en serie para poder aplicar el método value_counts() para contar la frecuencia de cada\n",
    "# elemento dentro de la misma\n",
    "\n",
    "pd.Series(instancias_analisis).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ed3da",
   "metadata": {},
   "source": [
    "## 100 modelos entrenados por tamaño de muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c60a8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista vacía que será la lista principal que contenga a los 20 grupos de 100 modelos cada uno\n",
    "\n",
    "totalidad_modelos = []\n",
    "\n",
    "# Ciclo for externo para iterar sobre cada tamaño de muestra y entrenar 100 modelos en base al mismo\n",
    "\n",
    "for tamano_muestra in instancias_analisis:\n",
    "    \n",
    "    # Crear lista vacía para almacenar los 100 modelos entrenados con un cierto tamaño muestral\n",
    "    \n",
    "    grupo_modelos = []\n",
    "    \n",
    "    # ciclo for interno para crear y entrenar 100 modelos con un subconjunto aleatorio del\n",
    "    # subset de entrenamiento de tamaño igual al valor de la variable del ciclo externo\n",
    "    # tamano_muestra\n",
    "    \n",
    "    for i in range(100):\n",
    "        \n",
    "        # Extraer subconjunto aleatorio del subset de entrenamiento para entrenar cada modelo\n",
    "        # el subconjunto será de tamaño igual a tamano_muestra\n",
    "        \n",
    "        # Aplicar método sample sobre el subset de entrenamiento para extraer la muestra aleatoria\n",
    "        # del tamaño especificado y axis = 0 para indicar que se deben muestrear las filas\n",
    "        # del subset de entrenamiento\n",
    "        \n",
    "        model_training = datos_train.sample(tamano_muestra, axis = 0)\n",
    "        \n",
    "        # Definir nuevo modelo de regresión con máximo de 500,000 iteraciones y una tasa de aprendizaje\n",
    "        # inicial de 0.0001 \n",
    "        \n",
    "        new_model = SGDRegressor(max_iter = 500000, eta0 = 0.0001)\n",
    "        \n",
    "        # Entrenar el nuevo modelo generado con el subconjunto aleatorio definido previamente\n",
    "        \n",
    "        new_model.fit(model_training[\"Celsius\"].to_numpy().reshape(-1, 1), model_training[\"Valks\"])\n",
    "        \n",
    "        # Agregar el nuevo modelo entrenado a la lista de modelos definida como grupo_modelos\n",
    "        \n",
    "        grupo_modelos.append(new_model)\n",
    "        \n",
    "    # Agregar el grupo de 100 modelos entrenados grupo_modelos a la lista global de grupos de modelos, junto\n",
    "    # con el tamaño de muestra con el que los modelos del grupo fueron entrenados\n",
    "    \n",
    "    totalidad_modelos.append([grupo_modelos])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea5faa",
   "metadata": {},
   "source": [
    "## MSE por modelo en el subconjunto de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445ead57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Para llevar a cabo esta parte del análisis, se creará una estructura de datos principal de la forma:\n",
    "\n",
    "   [[[MSE_train1, MSE_validation1], [MSE_train2, MSE_validation2], ...], [[[], [], ...], [[], [], ...], ...]\n",
    "   \n",
    "   En la estructura mencionada, la lista externa contendrá 20 listas principales correspondientes a un grupo de 100\n",
    "   modelos entrenados cada una, por lo que cada una de las 20 listas principales contendrá 100 tuplas internas, mismas\n",
    "   que contendrán a su vez 2 valores cada una: el MSE en el subconjunto de entrenamiento para un cierto modelo y \n",
    "   el MSE en el subconjunto de validación para dicho modelo \"\"\"\n",
    "\n",
    "# Crear una lista vacía para almacenar las 20 tuplas principales correspondientes a cada grupo de 100 modelos\n",
    "\n",
    "lista_global_errores = []\n",
    "\n",
    "# Ciclo for para iterar sobre cada uno de los 20 grupos de 100 modelos entrenados\n",
    "\n",
    "for n_grupo in range(len(totalidad_modelos)):\n",
    "    \n",
    "    # Crear lista vacía para almacenar otras 100 tuplas que contendrán cada una el MSE \n",
    "    # de un modelo del grupo en el subconjunto de entrenamiento y en el de validación\n",
    "    \n",
    "    model_group = []\n",
    "    \n",
    "    # Ciclo for interno para iterar sobre cada uno de los 20 grupos de 100 modelos entrenados\n",
    "    \n",
    "    for grupo in totalidad_modelos[n_grupo]:\n",
    "        \n",
    "        # Segundo ciclo for interno para iterar sobre cada uno de los 100 modelos del grupo elegido\n",
    "        # en el ciclo interno previo\n",
    "        \n",
    "        for n_model in range(len(grupo)):\n",
    "            \n",
    "            # Elegir un modelo del grupo de 100 modelos y predecir los datos en Valks a partir de él\n",
    "            # utilizando los datos en celsius del subconjunto de entrenamiento\n",
    "            \n",
    "            # Convertir datos en celsius a un array de numpy y cambiar su forma para que sea una \n",
    "            # estructura de datos bidimensional (2D)\n",
    "            \n",
    "            # Calcular las predicciones en valks usando el modelo seleccionado del grupo a partir del\n",
    "            # subconjunto de entrenamiento con un número cambiante de muestras\n",
    "            \n",
    "            pred_selected = grupo[n_model].predict(model_training[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "            \n",
    "            # Calcular las predicciones en valks usando el modelo seleccionado del grupo a partir del\n",
    "            # subconjunto de validación\n",
    "            \n",
    "            pred_selected_val = grupo[n_model].predict(validation[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "            \n",
    "            # Calcular el valor del MSE para dicho modelo en el subconjunto de entrenamiento de\n",
    "            # tamaño variable y en el conjunto de validación\n",
    "            \n",
    "            MSE_errors_model = [mean_squared_error(model_training[\"Valks\"], pred_selected), #MSE en el subconjunto de train\n",
    "                                mean_squared_error(validation[\"Valks\"], pred_selected_val)] #MSE en el subconjunto de validación\n",
    "            \n",
    "            # Agregar la lista con los errores calculados a la lista model_group donde se almacenan\n",
    "            # las tuplas con los errores calculados para cada uno de los 100 modelos del grupo\n",
    "            \n",
    "            model_group.append(MSE_errors_model)\n",
    "        \n",
    "        # Agregar el grupo de listas model_group a la lista principal par almancenar los grupos de tuplas\n",
    "        # llamada lista_global_errores\n",
    "        \n",
    "        lista_global_errores.append(model_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8f53b",
   "metadata": {},
   "source": [
    "## Promedio de las 100 repeticiones para cada modelo y sus errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faa228e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_MSE_train</th>\n",
       "      <th>AVG_MSE_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3145.682004</td>\n",
       "      <td>3628.905824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587.625601</td>\n",
       "      <td>669.210491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>583.179779</td>\n",
       "      <td>666.054177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581.538855</td>\n",
       "      <td>660.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558.372947</td>\n",
       "      <td>639.794726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>417.040708</td>\n",
       "      <td>482.800869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>631.046779</td>\n",
       "      <td>716.991730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>641.387201</td>\n",
       "      <td>725.624125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>419.947151</td>\n",
       "      <td>483.109660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>508.546535</td>\n",
       "      <td>578.105073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>226.884039</td>\n",
       "      <td>283.445496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>572.980963</td>\n",
       "      <td>651.593897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>710.822515</td>\n",
       "      <td>804.233398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>488.312938</td>\n",
       "      <td>557.144661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>479.150967</td>\n",
       "      <td>547.084876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>398.367326</td>\n",
       "      <td>466.492048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>644.908829</td>\n",
       "      <td>728.251640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>415.796151</td>\n",
       "      <td>479.575161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>595.801914</td>\n",
       "      <td>676.320952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>412.582077</td>\n",
       "      <td>506.914277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AVG_MSE_train  AVG_MSE_validation\n",
       "0     3145.682004         3628.905824\n",
       "1      587.625601          669.210491\n",
       "2      583.179779          666.054177\n",
       "3      581.538855          660.064415\n",
       "4      558.372947          639.794726\n",
       "5      417.040708          482.800869\n",
       "6      631.046779          716.991730\n",
       "7      641.387201          725.624125\n",
       "8      419.947151          483.109660\n",
       "9      508.546535          578.105073\n",
       "10     226.884039          283.445496\n",
       "11     572.980963          651.593897\n",
       "12     710.822515          804.233398\n",
       "13     488.312938          557.144661\n",
       "14     479.150967          547.084876\n",
       "15     398.367326          466.492048\n",
       "16     644.908829          728.251640\n",
       "17     415.796151          479.575161\n",
       "18     595.801914          676.320952\n",
       "19     412.582077          506.914277"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generar una lista vacía para almacenar los errores MSE en el subconjunto de entrenamiento de muestras\n",
    "# cambiantes para cada uno de los 20 grupos de 100 modelos entrenados \n",
    "\n",
    "MSE_train_model_groups = [] \n",
    "\n",
    "# Generar una lista vacía para almacenar los errores MSE en el subconjunto de validación \n",
    "# para cada uno de los 20 grupos de 100 modelos entrenados \n",
    "\n",
    "MSE_val_model_groups = [] \n",
    "\n",
    "# Ciclo for para iterar sobre cada uno de los 20 grupos de 100 modelos (2000 modelos en total)\n",
    "\n",
    "for group_index in range(len(totalidad_modelos)):\n",
    "    \n",
    "    # Definir los datos de los errores MSE para el grupo de modelos elegido\n",
    "    \n",
    "    data_group = pd.DataFrame(lista_global_errores[group_index], columns = [\"MSE_train\", \"MSE_validation\"])\n",
    "    \n",
    "    # Calcular el error MSE promedio del grupo de modelos en cuestión a partir del subconjunto de \n",
    "    # entrenamiento de muestras cambiantes\n",
    "    \n",
    "    AVG_MSE_train = data_group[\"MSE_train\"].mean()\n",
    "    \n",
    "    # Calcular el error MSE promedio del grupo de modelos en cuestión a partir del subconjunto de \n",
    "    # vlidación\n",
    "    \n",
    "    AVG_MSE_validation = data_group[\"MSE_validation\"].mean()\n",
    "    \n",
    "    # Agregar el MSE promedio del grupo de modelos a partir del subconjunto de entrenamiento de muestras\n",
    "    # cambiantes a la lista para los errores MSE a partir del subconjunto de entrenamiento variable \n",
    "    # de los grupos de modelos (MSE_train_model_groups)\n",
    "    \n",
    "    MSE_train_model_groups.append(AVG_MSE_train)\n",
    "    \n",
    "    # Agregar el MSE promedio del grupo de modelos a partir del subconjunto de validación\n",
    "    # a la lista para los errores MSE a partir del subconjunto de validación \n",
    "    # de los grupos de modelos (MSE_val_model_groups)\n",
    "    \n",
    "    MSE_val_model_groups.append(AVG_MSE_validation)\n",
    "    \n",
    "    # Eliminar la variable data_group para que en la próxima iteración, se asigne un nuevo conjunto de\n",
    "    # datos (errores) que corresponderán al próximo grupo elegido de modelos\n",
    "    \n",
    "    del data_group\n",
    "    \n",
    "# Generar un dataframe para almacenar la información referente al error MSE promedio tanto en el \n",
    "# subconjunto de entrenamiento de muestras cambiantes como en el subconjunto de validación, para\n",
    "# cada grupo de 100 modelos\n",
    "\n",
    "df_MSE = pd.DataFrame({\"AVG_MSE_train\": MSE_train_model_groups, \"AVG_MSE_validation\": MSE_val_model_groups})\n",
    "\n",
    "# Mostrar los primeros registros de los MSE promedio para los grupos de modelos\n",
    "\n",
    "df_MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72c20b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_MSE_train</th>\n",
       "      <th>AVG_MSE_validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3145.682004</td>\n",
       "      <td>3628.905824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587.625601</td>\n",
       "      <td>669.210491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>583.179779</td>\n",
       "      <td>666.054177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581.538855</td>\n",
       "      <td>660.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558.372947</td>\n",
       "      <td>639.794726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>417.040708</td>\n",
       "      <td>482.800869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>631.046779</td>\n",
       "      <td>716.991730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>641.387201</td>\n",
       "      <td>725.624125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>419.947151</td>\n",
       "      <td>483.109660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>508.546535</td>\n",
       "      <td>578.105073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>226.884039</td>\n",
       "      <td>283.445496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>572.980963</td>\n",
       "      <td>651.593897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>710.822515</td>\n",
       "      <td>804.233398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>488.312938</td>\n",
       "      <td>557.144661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>479.150967</td>\n",
       "      <td>547.084876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>398.367326</td>\n",
       "      <td>466.492048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>644.908829</td>\n",
       "      <td>728.251640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>415.796151</td>\n",
       "      <td>479.575161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>595.801914</td>\n",
       "      <td>676.320952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>412.582077</td>\n",
       "      <td>506.914277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>149.394435</td>\n",
       "      <td>110.059150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AVG_MSE_train  AVG_MSE_validation\n",
       "0     3145.682004         3628.905824\n",
       "1      587.625601          669.210491\n",
       "2      583.179779          666.054177\n",
       "3      581.538855          660.064415\n",
       "4      558.372947          639.794726\n",
       "5      417.040708          482.800869\n",
       "6      631.046779          716.991730\n",
       "7      641.387201          725.624125\n",
       "8      419.947151          483.109660\n",
       "9      508.546535          578.105073\n",
       "10     226.884039          283.445496\n",
       "11     572.980963          651.593897\n",
       "12     710.822515          804.233398\n",
       "13     488.312938          557.144661\n",
       "14     479.150967          547.084876\n",
       "15     398.367326          466.492048\n",
       "16     644.908829          728.251640\n",
       "17     415.796151          479.575161\n",
       "18     595.801914          676.320952\n",
       "19     412.582077          506.914277\n",
       "20     149.394435          110.059150"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregar a las listas previas, los errores de entrenamiento y validación de la línea base, es decir, \n",
    "# errores para entrenamiento y validación correspondientes al modelo base entrenado con 40 muestras\n",
    "\n",
    "errores_base = pd.DataFrame(np.array([MSE_validation, MSE_train]).reshape(1, 2), \n",
    "                            columns = [\"AVG_MSE_train\", \"AVG_MSE_validation\"])\n",
    "\n",
    "# Agregar la nueva fila definida como dataframe al dataframe con 20 registros previo\n",
    "\n",
    "df_MSE = pd.concat([df_MSE, errores_base], axis = 0, ignore_index = True)\n",
    "\n",
    "# Mostrar dataframe de errores MSE promedio con el nuevo registro (errores del modelo base)\n",
    "\n",
    "df_MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff041e3",
   "metadata": {},
   "source": [
    "**Nota:** el registro 20 del dataframe anterior representa los errores de entrenamiento y validación del modelo base entrenado inicialmente con 40 muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadfd52",
   "metadata": {},
   "source": [
    "## Gráfica de evolución del error promedio de entrenamiento y validación por tamaño de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e839373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_MSE_train</th>\n",
       "      <th>AVG_MSE_validation</th>\n",
       "      <th>Tamaño_muestra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3145.682004</td>\n",
       "      <td>3628.905824</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>587.625601</td>\n",
       "      <td>669.210491</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>226.884039</td>\n",
       "      <td>283.445496</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>631.046779</td>\n",
       "      <td>716.991730</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>412.582077</td>\n",
       "      <td>506.914277</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>641.387201</td>\n",
       "      <td>725.624125</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>417.040708</td>\n",
       "      <td>482.800869</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>398.367326</td>\n",
       "      <td>466.492048</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>479.150967</td>\n",
       "      <td>547.084876</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>644.908829</td>\n",
       "      <td>728.251640</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>710.822515</td>\n",
       "      <td>804.233398</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>583.179779</td>\n",
       "      <td>666.054177</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>419.947151</td>\n",
       "      <td>483.109660</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>415.796151</td>\n",
       "      <td>479.575161</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>581.538855</td>\n",
       "      <td>660.064415</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>488.312938</td>\n",
       "      <td>557.144661</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558.372947</td>\n",
       "      <td>639.794726</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>595.801914</td>\n",
       "      <td>676.320952</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>508.546535</td>\n",
       "      <td>578.105073</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>572.980963</td>\n",
       "      <td>651.593897</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>149.394435</td>\n",
       "      <td>110.059150</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AVG_MSE_train  AVG_MSE_validation  Tamaño_muestra\n",
       "0     3145.682004         3628.905824               2\n",
       "1      587.625601          669.210491               7\n",
       "10     226.884039          283.445496               8\n",
       "6      631.046779          716.991730               9\n",
       "19     412.582077          506.914277              10\n",
       "7      641.387201          725.624125              11\n",
       "5      417.040708          482.800869              16\n",
       "15     398.367326          466.492048              17\n",
       "14     479.150967          547.084876              19\n",
       "16     644.908829          728.251640              21\n",
       "12     710.822515          804.233398              22\n",
       "2      583.179779          666.054177              23\n",
       "8      419.947151          483.109660              24\n",
       "17     415.796151          479.575161              29\n",
       "3      581.538855          660.064415              30\n",
       "13     488.312938          557.144661              31\n",
       "4      558.372947          639.794726              33\n",
       "18     595.801914          676.320952              34\n",
       "9      508.546535          578.105073              37\n",
       "11     572.980963          651.593897              38\n",
       "20     149.394435          110.059150              40"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregar al dataframe de errores promedio, el tamaño de muestra con el que cada grupo de modelos fue entrenado\n",
    "# Se agrega adicionalmente el tamaño de muestra 40 para la última fila de errores MSE promedio \n",
    "# (de los modelos entrenados con 40 muestras)\n",
    "\n",
    "df_MSE[\"Tamaño_muestra\"] = instancias_analisis + [40]\n",
    "\n",
    "# Ordenar los datos de errores MSE promedio por tamaño de muestra de menor a mayor tamaño muestral\n",
    "\n",
    "df_MSE.sort_values(by = \"Tamaño_muestra\", inplace = True)\n",
    "\n",
    "# Mostrar dataframe de errores MSE promedio con la nueva columna de tamaño de muestra\n",
    "\n",
    "df_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eae05fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABUG0lEQVR4nO2deXwV1fXAvycLkLDJEhAISRARlX1HWZVVNtGqYKlLrVKrFLfWpbSKtbT+rFttlRYtgoiAdcUFEREEBMEgOyiCLAkECPsespzfHzMvvCTvJS8kL+8lnO/nM583c5e5Z+7MmzP33HvPFVXFMAzDMAojItQCGIZhGOGPKQvDMAyjSExZGIZhGEViysIwDMMoElMWhmEYRpGYsjAMwzCKxJRFKSMiKiIXl/AcfxCR13yEdxORFSJSqyTn9zpfkitvVABpbxeRJaVR7vlO/noXkTkicluo5SopIpIgIsdFJLI004Yr3v91Efm3iPwpkLQlKM9nGSJyk4jMFZHKJTl/URT5kqioiMh2oD6Q7RU8RVXHhEais6jqX/OHiUhj4K/AEFU9VPZSGcFCVa8JtQwicjtwp6p2P9dzqOpOoFpppy0PqOrdoShDRNoBvwKuU9WMYJZ/3ioLl6Gq+kWohQgEVU0BeoVajpIiIgKIquZ4hUWpalYxzlGs9ME6x/mGiESqanbRKY2yQlVXAQPKoiwzQ+VDRCqLyGERaekVFicip0Sknnt8l4hsEZGDIjJbRBr6OddCEbnT6ziPKUdEWojIPPc8e0XkD274eBF50yvdMBHZ4Mq1UEQu84rbLiK/E5G1InJERGaJSBU/8kSKyLMisl9EfgIG54uvKSL/FZE0EdklIn8J1EwgIl1FZKkr4xoR6Z2vHiaIyNfASeAit1l+r4j8CPxYVL36Sp+vfI9pZ7SI7Hav4SGv+PEi8o6IvCkiR4HbRaShW85Bt9y78qX/n5v+mIisE5FLROQxEdknIiki0j+Qugug3nOfExGJEJE/isgOt5w3RKRmIfU+RERWu/W+VERae8UF9Gy4z9O/gSvEMQ0ddsOniMhEEflURE4AV4nIYBFZJSJH3ToY7+MeeMxrC0XkKRH52q3Dz0WkbnHTuvG3unVyQET+5F5bXx/X0kmc/1KUV9jPRGS1j7RdRWSP9zMuIteJyFp3v7OILHPrNk1E/iUilfzchyki8hev49+7eXaLyB350vqtQze+u5z9L6WI0+rzVUZR/5e7ReRHETkkIi+LiPiSPWBU9bzcgO1AXz9xk4EJXsf3Ap+5+1cD+4H2QGXgn8Air7QKXOzuL8Rp2nvibgeWuPvVgTTgIaCKe9zFjRsPvOnuXwKcAPoB0cDDwBagktd1rAAaArWBTcDdfq7rbuB7oLGbdoErb5Qb/wHwH6AqUM8976/zy+7jvI2AA8AgnA+Qfu5xnFc97ARa4LRmo91y57lyxARYr7npfciQ5KaZ4crfCkj33GO3TjOB4a6MMcBXwCtu/bd10/fxSn8a56stCngD2AaMc+W/C9jmVX5hdVdUvS/EfU6AO9z7exGOmeY9YJqfem8P7AO6AJHAbe7zUPkcno0C9xeYAhwBurl1VgXo7dZtBNAa2AsMz3cPvK9rK84zHOMeP30OaS8HjgPdgUrAs+699Pf/3Qhc43X8PvCQn7RbgX5ex/8DHnX3OwBd3fuf5Nbf/X7+61OAv7j7A916aek+D2/lS1tYHSYAx4CbcZ6zOkBbH2UE8n/5GLjAPWc6MLBE78yyeDGH44bzRzoOHPba7nLj+gI/eaX9GrjV3f8v8IxXXDX3wU3y8QAtxL+yuBlY5Ue28ZxVFn8C3vaKiwB2Ab29ruMXXvHPAP/2c94v8XpZAP1deaNw+m8y8HoRuzIuyC+7j/M+Qr4XGjAXuM2rHv6cL16Bq72OA6nXq32V78YnuWkuzVcX//WqU+8/U2Oc/qrqXmF/w+m38qSf5xU31H1eIt3j6m55FwRQd37rPf9zAswH7vFK29ythygf1zwReCpf2A9Ar3N4NgrcX5yX0xtF/I9eBF7Idw+8r+uPXmnv4exHV3HSPg7M8IqLBc7gX1k8Akx392vjtGYb+En7F2Cy1z09AST6SXs/8H6+Z9iXspiMq+jc40u80xZRh495l+HjfnjKCOT/0t0r/m1cJXiu2/luhhquqhd4ba+64V8CMSLSRUQScb4633fjGgI7PCdQ1eM4X9GNill2Y5yvmqLIX14OkJKvvD1e+yfx33HY0M3rYYfXfiLOl0ya2/w9jPOlXC8AGROBGz353LzdgQZeaVJ85PMOC6RefZ2jsHPucM/rr7yDqnosX3rv8vZ67Z8C9utZm/0p97caRdddYfWen4b54ndwVpnnJxF4KF+9NybvNQf6bPgjT527/4kFIpIuIkdwWk11fWctdvn+0uapP1U9ifNs+ONNYKiIVANuAharapqftG8B14szkuh64DtV3QEgjtnxY9dUdRRngElh1+qh0PtdRB2e63vB1/+lpPc+D+e7svCJ+0J+G+fr8OfAx14vld04f1IARKQqTlNxl49TncD5CvJwodd+CtA0AHHylyc4D5Sv8ooizc3rISGfPBlAXS/lWUNVWwRw3hScloW34q2qqk97pVEf+bzDAqlXX+fIT/7r211IebVFpHq+9OdSr0XVXWH1np889eCmzSKv4vIud0K+eo9V1RnncA3+6jZ/+FvAbKCxqtbE6esomS28aNKAeM+BiMTgPBs+UdVdwDLgOuAWYFohaTfivHSvwfmvv+UVPRHHfNhMVWsAfyCway3qfhdWh+f6XijsPVQqmLLwz1vACGAUeR+gt4Bfikhb92vkr8ByVd3u4xyrcb5aYsUZY/0rr7iPgQtF5H5xOtWri0gXH+d4GxgsIn1EJBqnjyMDWHoO1/Q2MFZE4sWZq/GoJ8L98voceE5EaojT0dpURHoFcF7Pl9wAcTpzq4hIbxGJLzLnWYpTr4XxJ7e+WwC/BGb5SqTO6LKlwN9ceVvj3J/pxSwvkLrzW+8+mAE8ICJN3C/jvwKz1PfIrVeBu90vVRGRqm7naXUfaYtiLxDvrwPXi+o4LbLTItIZ5wUbbN7Beb6udOV7kqJf2m/g9O+14qxVwB9vAWOBnjh9Fh6qA0eB4yJyKfCbAOV9G2cAxeUiEgs8kS++sDqcDvQVZ+5ElIjUEZG2fmQujf9LwJzvyuIjcUZ/eLbch0pVl+O0DBoCc7zC5+P0I7yL8wXRFBjp5/wv4NhW9wJT8XoRuS2Vfji28D04I3yuyn8CVf0B+AVOB9Z+N/1QVT1zDtf7Kk5fwhrgO5zOU29uxelA3AgcwvmTNqAI3BfvtThfXuk4X0e/pxjPVzHrtTC+wukgng88q6qfF5L2Zhzb+W6cF8oTqjrvHMqEwuuuqHr3ZjLOl/AinA7108BvfSVU1WScjvZ/uWVuwel7OBe+BDYAe0RkfyHp7gH+LCLHcPoS3j7H8gJGVTfg1MFMnGfjGE7HfmHzCt7H+fJ+X1VPFFHEDJxO5y9V1fvaf4fzIj+Gcw99fnj4kHcOTj/Elzj35Mt8SfzWoTrzTwbhfBQexPngbOOjjNL6vwSMuJ0fhlGuEZEknJdrtJ+vcKOC4La4DuOYh7YVkm4rzoi0cjGXKtw531sWhmGUA0RkqGterIozdHYdzmgvf+l/htPfkv+r3jhHzvcZ3IZhlA+uxTHPCZAMjFQ/ZhERWYgzN+MW9fIUYJQMM0MZhmEYRWJmKMMwDKNIKqwZqm7dupqUlBRqMQzDMMoVK1eu3K+qcfnDK6yySEpKIjk5OdRiGIZhlCtExKeHATNDGYZhGEViysIwDMMoElMWhmEYRpFU2D4LwyjPZGZmkpqayunTp0MtilFBqVKlCvHx8URHRweU3pSFYYQhqampVK9enaSkJEq6wJlh5EdVOXDgAKmpqTRp0iSgPGaG8mL6uukkvZhExJMRJL2YxPR1xXZAahilwunTp6lTp44pCiMoiAh16tQpVsvVWhYu09dNZ/RHozmZeRKAHUd2MPqj0QCMajUqlKIZ5ymmKIxgUtzny1oWLuPmj8tVFB5OZp5k3PxxIZLIMAwjfDBl4bLzyM5ihRuGERpee+01Dh48GGoxzjtMWbgk1PS90qW/cMOo6ERGRtK2bdvc7emnny46kw+SkpLYv7+w9ZR8s3v3bm644YY8YU8//TQxMTHUrl37nGQ5F7Zv385bb71VdEIfXHnllUWmufPOO9m4ceM5nb8ssT4Llwl9JuTpswCIjY5lQp8JIZTKMEJHTEwMq1evDln5DRs25J133skT9uijha1IGxw8yuLnPy+4gmxWVhZRUf5fo0uXFr368WuvvVYi+coKa1m4jGo1iklDJ1E3ti4AVaKqMGnoJOvcNkKPSHC2c2DOnDncdNNNuccLFy5k6NChAMyYMYNWrVrRsmVLHnnkkQJ5t2/fTsuWLXOPn332WcaPHw/Ali1b6Nu3L23atKF9+/Zs3bo1T/rTp0/zy1/+klatWtGuXTsWLFgAwJQpU7j++usZOHAgzZo14+GHH/Yp98qVK+nVqxcdOnRgwIABpKWlAdC7d28eeeQROnfuzCWXXMLixYsL5H300UdZvHgxbdu25YUXXmDKlCnceOONDB06lP79+3P8+HH69OlD+/btadWqFR9++GFu3mrVquXWU+/evbnhhhu49NJLGTVqFJ7lIXr37p3rx65atWqMGzeONm3a0LVrV/bu3QvA1q1b6dq1K506deLxxx/PPW+ZoqpB2YAqwAqcdYc3AE+64eOBXThry64GBnnleQxnzdofgAFe4R1wVsbaAryEuw5HYVuHDh30XNhzbI8yHq06oaqeyTpzTucwjJKycePGswcQnK0IIiIitE2bNrnbzJkzNTMzUxs3bqzHjx9XVdW7775bp02bprt27dLGjRvrvn37NDMzU6+66ip9//33VVU1MTFR09PTddu2bdqiRYvc8//973/XJ554QlVVO3furO+9956qqp46dUpPnDiRJ/2zzz6rt99+u6qqbtq0SRs3bqynTp3S119/XZs0aaKHDx/WU6dOaUJCgu7cuTPPdZw5c0avuOIK3bdvn6qqzpw5U3/5y1+qqmqvXr30wQcfVFXVTz75RPv06VOgHhYsWKCDBw/OPX799de1UaNGeuDAAVVVzczM1CNHjqiqanp6ujZt2lRzcnJUVbVq1aq556hRo4ampKRodna2du3aVRcvXpwrw7fffuveanT27Nmqqvr73/9en3rqKVVVHTx4sL711luqqjpx4sTc85aUPM+ZC5CsPt6pwWxZZABXq2oboC0wUES6unEvqGpbd/sUQEQux1lwvAUwEHhFRCLd9BOB0UAzdxsYLKHrV6vPJXUu4UTmCVbtWRWsYgwjcIKlLorAY4bybCNGjCAqKoqBAwfy0UcfkZWVxSeffMK1117Lt99+S+/evYmLiyMqKopRo0axaNGigC7v2LFj7Nq1i+uuuw5wZhbHxsbmSbNkyRJuueUWAC699FISExPZvHkzAH369KFmzZpUqVKFyy+/nB078jpN/eGHH1i/fj39+vWjbdu2/OUvfyE1NTU3/vrrrwegQ4cObN++PSCZ+/Xrl9tvoqr84Q9/oHXr1vTt25ddu3bltgi86dy5M/Hx8URERNC2bVufZVWqVIkhQ4YUkGfZsmXceOONAD7NYWVB0PosXA113D2MdrfCntBrgZmqmgFsE5EtQGcR2Q7UUNVlACLyBjAcmBMk0emZ0JPNBzazaMciOjfqHKxiDKNcMmLECF5++WVq165Np06dqF69eq5JpTCioqLIyTm7yqlnQlggeQtLU7ly5dz9yMhIsrKyCuRt0aIFy5YtKzS/r7z+qFq1au7+9OnTSU9PZ+XKlURHR5OUlORzsltRcgJER0fnzn8ojjxlQVD7LEQkUkRWA/uAeaq63I0aIyJrRWSyiNRywxoBKV7ZU92wRu5+/nBf5Y0WkWQRSU5PTz9nuXsk9gBg8c6C9kvDON/p3bs33333Ha+++iojRowAoEuXLnz11Vfs37+f7OxsZsyYQa9evfLkq1+/Pvv27ePAgQNkZGTw8ccfA1CjRg3i4+P54IMPAMjIyODkybxznnr27Mn06Y5Hhc2bN7Nz506aN28ekLzNmzcnPT09V1lkZmayYcOGgK+3evXqHDt2zG/8kSNHqFevHtHR0SxYsKBAy6Y06Nq1K++++y4AM2fOLPXzB0JQlYWqZqtqWyAep5XQEsek1BTHNJUGPOcm99XjpoWE+ypvkqp2VNWOcXEFFnoKmJ6JPQFYvGMxObbeu3GecurUqTxDZz0jkSIjIxkyZAhz5szJNZk0aNCAv/3tb1x11VW5ndTXXnttnvNFR0fz+OOP06VLF4YMGcKll16aGzdt2jReeuklWrduzZVXXsmePXvy5L3nnnvIzs6mVatWjBgxgilTpuT5Ui+MSpUq8c477/DII4/Qpk0b2rZtG9AoJQ+tW7cmKiqKNm3a8MILLxSIHzVqFMnJyXTs2JHp06fnua7S4sUXX+T555+nc+fOpKWlUbNmzVIvoygkkCZgqRQk8gRwQlWf9QpLAj5W1ZYi8hiAqv7NjZuL0xm+HVigqpe64TcDvVX114WV17FjRz3XlfJUlcQXE0k5msLau9fSqn6rczqPYZwrmzZt4rLLLgu1GEaYcPLkSWJiYhARZs6cyYwZM/KMujpXfD1nIrJSVTvmTxu0loWIxInIBe5+DNAX+F5EGngluw5Y7+7PBkaKSGURaYLTkb1CVdOAYyLSVRxj3q1AyWupcNnNFGUYRtiwcuVK2rZtS+vWrXnllVd47rnnis5UygRzUl4DYKo7oikCeFtVPxaRaSLSFseUtB34NYCqbhCRt4GNQBZwr6pmu+f6DTAFiMHp2A5a57aHngk9eWvdWyzasYh7Ot0T7OIMwzD80qNHD9asWRNSGYI5Gmot0M5H+C2F5JkAFJgyrarJQMuCOYKHp99i0Y5FqKp5ADUM47zGZnD74dK6l1I3ti5px9P46dBPoRbHMAwjpJiy8IOI0CPB6bdYtCOwyUWGYRgVFVMWhZBritppysIwwgVzUV6QEydOMHHixDyTHksbUxaF4GlZLN5hI6KM8w9zUX5ueDtATE5OZuzYsT7TnWu9zJ49O8+9yMrKYsyYMXTv3p2IiOC90s1FeSG0ubAN1StVZ+uhrew6uotGNXxOHDeMCom5KC85HTt2pGPHAlMWSsSwYcMYNmxY7nFUVBSvv/56qZbhC2tZFEJURBTdEroBNt/CCB3ypARlOxfORxflI0aM4NNPP809vv3223n33XfZvn07PXr0oH379rRv397nrPCFCxfmznI/cOAA/fv3p127dvz617/O4+9q+PDhdOjQgRYtWjBp0qTc8M8++4z27dvTpk0b+vTpk3vNY8aMAWDHjh306dOH1q1b06dPH3bu3Jkr49ixY7nyyiu56KKLCijdc8GURRGYKco4X8nv7mPWrFn069ePb775hhMnTgAwa9YsRowYwe7du3nkkUf48ssvWb16Nd9++22ur6dAGDVqFPfeey9r1qxh6dKlNGjQIE/8yy+/DMC6deuYMWMGt912W66zvtWrVzNr1izWrVvHrFmzSElJyZM3MzOT3/72t7zzzjusXLmSO+64g3HjxuXGZ2VlsWLFCl588UWefPLJArKNHDmSWbNmAXDmzBnmz5/PoEGDqFevHvPmzeO7775j1qxZfs1NHp588km6d+/OqlWrGDZsWO6LHWDy5MmsXLmS5ORkXnrpJQ4cOEB6ejp33XUX7777LmvWrOF///tfgXOOGTOGW2+9lbVr1zJq1Kg8MqSlpbFkyRI+/vjjUmmRmRmqCKyT2wg1+kTZuOTJjz8zlMdF+Q033MAnn3zCM888w5dffpnrohzIdVE+fPjwIsvx5aI8P0uWLOG3v/0t4N9FOZDrorxx48a5eb1dlANkZ2fnUUZFuSi/5pprGDt2LBkZGXz22Wf07NmTmJgYjhw5wpgxY1i9ejWRkZG58vhj0aJFvPfeewAMHjyYWrVq5ca99NJLvP/++wCkpKTw448/kp6eTs+ePWnSpAmAz36aZcuW5Z7zlltuydOyGj58OBEREVx++eU+XaYXF1MWRdCpYScqR1Zm/b71HDh5gDqxdUItkmGElPPNRXmVKlXo3bs3c+fOZdasWdx8880AvPDCC9SvX581a9aQk5PjU8nlx9fk3oULF/LFF1+wbNkyYmNj6d27N6dPnz6nycDe6b3rpTR8AJoZqggqR1WmS3wXAL5O+TrE0hhG6DnfXJSDY4p6/fXXWbx4MQMGDAAc1+QNGjQgIiKCadOmkZ2dXeg5vK9hzpw5HDp0KPc8tWrVIjY2lu+//55vvvkGgCuuuIKvvvqKbdu2AfgcLnzllVfmuiyfPn063bt3L9Z1FQdTFgHQM+Gs6w/DOF8wF+Vn6d+/P4sWLaJv375UqlQpV6apU6fStWtXNm/enGdBJF888cQTLFq0iPbt2/P555+TkJAAOGa9rKwsWrduzZ/+9Ce6dnUWFI2Li2PSpElcf/31tGnTJlcxe/PSSy/x+uuv07p1a6ZNm8Y//vGPYl1XcSgzF+VlzTm5KJ8+HcaNg507ISEBJkyAUaOYt3Ue/d/sT6eGnVhx14rgCGwYXpiLcqMsKI6Lcuuz8DB9OoweDZ7m744dzjFwxY3XEimRfJf2HcfPHKdapWohFNQwDKPsMTOUh3HjzioKDydPwrhxVKtUjfYN2pOt2SxL8d1JZhiGUZExZeHBa8yzr3Bvl+WGURZUVBOxER4U9/kyZeHB7WzyF547Oc9mchtlQJUqVThw4IApDCMoqCoHDhwIaLivB+uz8DBhQt4+C4DYWCcc6J7gDEn7JvUbMrIyqBwV2EgMwzgX4uPjSU1NJT09PdSiGBWUKlWqEB8fH3B6UxYeRo1yfh96CPbuhehomDQpN7xObB1a1mvJ+n3r+Xb3t7nKwzCCQXR0dO7MXcMIB8wM5c2oUU4fRdWqkJkJvXvniTY/UYZhnK8ETVmISBURWSEia0Rkg4g86YbXFpF5IvKj+1vLK89jIrJFRH4QkQFe4R1EZJ0b95IEc0HsSpXgqquc/c8/zxNlfqIMwzhfCWbLIgO4WlXbAG2BgSLSFXgUmK+qzYD57jEicjkwEmgBDAReEZFI91wTgdFAM3cbGES5YaB7+s8+yxPsaVl8vfNrsnMKn9pvGIZRkQiaslCH4+5htLspcC0w1Q2fCgx3968FZqpqhqpuA7YAnUWkAVBDVZepMzTkDa88wcH1/cK8eeDl76VRjUZcVOsijp05xpq9a4IqgmEYRjgR1D4LEYkUkdXAPmCeqi4H6qtqGoD7W89N3gjwdkSf6oY1cvfzhwePiy+Giy6CQ4cgn8sQm29hGMb5SFCVhapmq2pbIB6nldCykOS++iG0kPCCJxAZLSLJIpJc4iGHfkxR5lTQMIzzkTIZDaWqh4GFOH0Ne13TEu7vPjdZKtDYK1s8sNsNj/cR7qucSaraUVU7ehZhOWc8pqi5c/ME90g8OznPJkwZhnG+EMzRUHEicoG7HwP0Bb4HZgO3ucluAz5092cDI0Wksog0wenIXuGaqo6JSFd3FNStXnmCx1VXQVQULF/umKNcmtZqSoNqDdh/cj/f7/8+6GIYhmGEA8FsWTQAFojIWuBbnD6Lj4GngX4i8iPQzz1GVTcAbwMbgc+Ae1XV07v8G+A1nE7vrcCcIMrtUL06dO8OOTnwxRe5wSJi/RaGYZx3BHM01FpVbaeqrVW1par+2Q0/oKp9VLWZ+3vQK88EVW2qqs1VdY5XeLJ7jqaqOkbLyv7jzxRlfqIMwzjPsBncheGtLLz0k6dl8dWOr6zfwjCM8wJTFoXRpg3Urw+pqbBxY25wi3otqFWlFqlHU9lxZEcIBTQMwygbTFkURkQE9O/v7HuZoiIkIteRoPmJMgzjfMCURVF4TFH551tYJ7dhGOcRpiyKon9/EIFFi/KsdWFOBQ3DOJ8wZVEUcXHQvj1kZDgKw6Xdhe2IjY5l84HN7D2+N4QCGoZhBB9TFoHgw/VHdGQ0Vza+ErAhtIZhVHxMWQSCn/kW5ifKMIzzBVMWgdC1qzOj+/vvYcfZobLefqIMwzAqMqYsAiE6Gvr2dfa9WhddGnUhOiKaNXvWcPj04dDIZhiGUQaYsggUH6aomOgYOjfqjKJ8vfPrEAlmGIYRfExZBIpHWXzxBWRm5gabnyjDMM4HTFkESlISNG8OR486bstdbHKeYRjnA6YsioMPU9SVja9EEL7d/S0nM0/6yWgYhlG+MWVRHHwoi5pVatL2wrZk5WSxPHW5n4yGYRjlG1MWxaFXL6hcGZKTYf/+3GAzRRmGUdExZVEcqlaFHj2ctS3mzcsN9nRym58owzAqKqYsiosPU5Rnct6ylGWcyT4TCqkMwzCCiimL4uLxE+W1el69qvW4tO6lnMo6xXdp34VQOMMwjOBgyqK4tGgBjRrBnj2wdm1ucK4pyvotDMOogARNWYhIYxFZICKbRGSDiNznho8XkV0istrdBnnleUxEtojIDyIywCu8g4isc+NeEhEJltxFIuJz9TxPJ7dNzjMMoyISzJZFFvCQql4GdAXuFZHL3bgXVLWtu30K4MaNBFoAA4FXRCTSTT8RGA00c7eBQZS7aHy4LM9VFjsWk52THQqpDMMwgkbQlIWqpqnqd+7+MWAT0KiQLNcCM1U1Q1W3AVuAziLSAKihqstUVYE3gOHBkjsg+vZ11udesgSOHwcgoWYCCTUTOJJxhPX71odUPMMwjNKmSGUhIvEi8r6IpIvIXhF5V0Tii1OIiCQB7QDPrLUxIrJWRCaLSC03rBGQ4pUt1Q1r5O7nD/dVzmgRSRaR5PT09OKIWDxq14ZOnRwfUQsX5gabKcowjIpKIC2L14HZQAOcl/RHblhAiEg14F3gflU9imNSagq0BdKA5zxJfWTXQsILBqpOUtWOqtoxLi4uUBHPDV+mKFsMyTCMCkogyiJOVV9X1Sx3mwIE9CYWkWgcRTFdVd8DUNW9qpqtqjnAq0BnN3kq0Ngrezyw2w2P9xEeWgqZb7FoxyJUfeozwzCMckkgymK/iPxCRCLd7RfAgaIyuSOW/gtsUtXnvcIbeCW7DvAY+GcDI0Wksog0wenIXqGqacAxEenqnvNW4MOAri6YdOoEF1wAW7bA1q0ANK/TnLjYOPae2MuWg1tCK59hGEYpEoiyuAO4CdiDYza6wQ0rim7ALcDV+YbJPuMOg10LXAU8AKCqG4C3gY3AZ8C9quoZVvQb4DWcTu+twJwAry94REVBv37Ovtu6EBHzE2UYRoWkSGWhqjtVdZiqxqlqPVUdrqo7Asi3RFVFVVt7D5NV1VtUtZUbPsxtOXjyTFDVpqraXFXneIUnq2pLN26MhouNx5cpyvxEGYZRAYnyFyEiD6vqMyLyT3x0KKvq2KBKVh7wKIsvv4QzZ6BSpTzzLQzDMCoKhbUsNrm/ycBKH5sRH++4/zh+HJYuBaB1/dbUqFyDbYe3kXIkpYgTGIZhlA/8KgtV/cj9neprKzsRw5x8pqjIiEi6Ne4G2HwLwzAqDn6VhYh8JCKz/W1lKWRY4+2F1sVMUYZhVDT89lkAz7q/1wMXAm+6xzcD24MoU/miRw+IiYFVq2DvXqhf/+yIKOvkNgyjglCYGeorVf0KaKeqI1T1I3f7OdC97EQMc6pUcZZbBfj8cwA6NuxIlagqbEzfyP6T+wvJbBiGUT4IaAa3iFzkOXAnzAXZl0Y5I58pqlJkJbrGdwVgyc4loZLKMAyj1AhEWTwALBSRhSKyEFgA3B9Mocod3p3cOTmA+YkyDKNiUVifBQCq+pmINAMudYO+V9WM4IpVzmjeHBISYOdOp++iQ4c8fqIMwzDKO4G4KI8Ffg+MUdU1QIKIDAm6ZOUJkQKmqCviryAqIopVe1ZxLONYCIUzDMMoOYG6KD8DXOEepwJ/CZpE5RWPKcp1WV61UlU6NOhAjuawNGVpCAUzDMMoOYEoi6aq+gyQCaCqp/C9xsT5TZ8+EBkJy5bBkSOAl58oM0UZhlHOCURZnBGRGFz/UCLSFLA+i/zUrAlXXAFZWY6vKGzlPMMwKg6BKIsncFyGNxaR6cB84OGgSlVeyef6o3tCdwRh+a7lnM46HULBDMMwSkYgLsrn4czivh2YAXRU1YXBFauc4q0sVKkVU4uW9VpyJvsMK3atCK1shmEYJSCQlgU4a29HApWAniJyffBEKsd06AB168L27bB5M2B+ogzDqBgEMnR2MjAZ+Bkw1N1s6KwvIiIKrJ5nfqIMw6gIFDkpD+iqqpcHXZKKwoABMGOGoyzGjs0dEbU0ZSlZOVlERQRS5YZhGOFFIGaoZSJiyiJQ+vd3fhcsgNOnaVC9ARfXvpjjZ46zes/qkIpmGIZxrgSiLKbiKIwfRGStiKwTkbVFZRKRxiKyQEQ2icgGEbnPDa8tIvNE5Ef3t5ZXnsdEZItb1gCv8A5uuVtE5CURCd95Hg0aQJs2cOoULHGcCJqfKMMwyjuBKIvJwC3AQM72VwwNIF8W8JCqXgZ0Be51WyiPAvNVtRnOMNxHAdy4kUALt6xXRCTSPddEYDTQzN0GBnR1oSLfEFrzE2UYRnknEGWxU1Vnq+o2Vd3h2YrKpKppqvqdu38MZ03vRsC1OK0V3N/h7v61wExVzVDVbcAWoLOINABqqOoyVVXgDa884YnHT5Tr+sPTyb1k5xJyNCdUUhmGYZwzgfS2fi8ibwEf4TVzW1XfC7QQEUkC2gHLgfqqmuaeI01E6rnJGgHfeGVLdcMy3f384b7KGY3TAiEhISFQ8Uqfbt2galVYvx527aJJwyY0qt6IXcd2sSl9Ey3qtQidbIZhGOdAIC2LGBwl0Z9zGDorItWAd4H7VfVoYUl9hGkh4QUDVSepakdV7RgXF8L1mSpVgquucvY//xwRMVOUYRjlmkBmcP/Sx3ZHICcXkWgcRTHdqyWy1zUt4f7uc8NTgcZe2eOB3W54vI/w8Ca/KSrB/EQZhlF+CWRSXryIvC8i+0Rkr4i8KyLxAeQT4L/AJlV93itqNnCbu38b8KFX+EgRqewu3doMWOGarI6JSFf3nLd65QlfPJ3c8+ZBdvbZyXk7FuF0vRiGYZQfAl3PYjbQEKev4CM3rCi64YyiulpEVrvbIOBpoJ+I/Aj0c49R1Q3A28BGHMeF96pqtnuu3wCv4XR6bwXmBHZ5IeTii+Gii+DQIUhO5rK4y6gdU5tdx3ax7fC2UEtnGIZRLAJRFnGq+rqqZrnbFKDIDgFVXaKqoqqtVbWtu32qqgdUtY+qNnN/D3rlmaCqTVW1uarO8QpPVtWWbtwYLS+f5l6mqAiJyJ3NbX6iDMMobwSiLPaLyC9EJNLdfgEcCLZgFYJ88y28TVGGYRjliUCUxR3ATcAeIA24wQ0ziuKqqyA6GpYvh0OHzq6cZ04FDcMoZxSqLNwZ1H9V1WGqGqeq9VR1eCCT8gygenVnzkVODnzxBe0atKNqdFW2HNxC2rG0UEtnGIYRMIUqC7eDOU5EKpWRPBUPL1NUVEQU3RK6ATaE1jCM8kUgZqjtwNci8icRedCzBVmuioOnk9tdPS/XFGX9FoZhlCMCcfex290igOrBFacC0ro11K8PqamwcePZlfOsZWEYRjmiSGWhqk8CiEgN51CPBV2qikREhLPGxbRpMHcuncfeQ6XISqzbu46Dpw5SO6Z2qCU0DMMokkBmcHcUkXXAWmCdiKwRkQ7BF60C4WWKqhJVhc6NOqMoX+/8OrRyGYZhBEig61nco6pJqpoE3EtgM7gND/36gQh89RWcPGl+ogzDKHcEoiyOqWruW01VlwBmiioOcXHQvj1kZMCiRTY5zzCMckcgymKFiPxHRHqLSC8ReQVYKCLtRaR9sAWsMHiZoq5ofAUREsHKtJWcOHMitHIZhmEEQCDKoi1wCfAEMB64DLgSeA54NliCVTg88y0++4walWvQ7sJ2ZOVk8U3qN4XnMwzDCAMCGQ11VVkIUuHp2tWZ0f3997BzJz0Te7IybSWLdiyiz0V9Qi2dYRhGoQTSsjBKg+ho6NvX2Z871/xEGYZRrjBlUZZ4maK6J3QH4JvUbziTfSaEQhmGYRRNUY4EI0TkyrISpsLjURbz5xNXuRaXx13O6azTJO9ODq1chmEYRVCUI8EcnI5sozRISoLmzeHIEVi+3PxEGYZRbgjEDPW5iPzMXf/aKClepijzE2UYRnkhEGXxIPA/4IyIHBWRYyJyNMhyVVy8XJZ7WhZLdi4hOye7kEyGYRihpUhloarVVTVCVaNVtYZ7XKOofCIyWUT2ich6r7DxIrJLRFa72yCvuMdEZIuI/CAiA7zCO4jIOjfupXLfwunVCypXhuRkGmfGkHRBEkczjrJ279pQS2YYhuGXgEZDicgwEXnW3YYEeO4pwEAf4S+oalt3+9Q9/+XASKCFm+cVd5U+gInAaKCZu/k6Z/mhalXo0QNUYd48M0UZhlEuCMTr7NPAfcBGd7vPDSsUVV0EHAxQjmuBmaqaoarbgC1AZxFpANRQ1WWqqsAbwPAAzxm+eJmiPE4FrZPbMIxwJpCWxSCgn6pOVtXJOF/2g4rIUxhjRGSta6aq5YY1AlK80qS6YY3c/fzhPhGR0SKSLCLJ6enpJRAxyHj5ierhzrdYtGMRjj40DMMIPwKdlHeB137NEpQ3EWiK428qjbPDcn31Q2gh4T5R1Umq2lFVO8bFxZVAzCDTogU0agR79tAs9RT1q9Yn/WQ6mw9sDrVkhmEYPglEWfwVWCUiU0RkKrDSDSs2qrpXVbPd+RuvAp3dqFSgsVfSeJylXFPd/fzh5RuRXFOUfP65uSw3DCPsKXIGN5ADdAXec7crVHXmuRTm9kF4uA7wjJSaDYwUkcoi0gSnI3uFqqYBx0SkqzsK6lbgw3MpO+zwmm9hfqIMwwh3CvU6q6o5IjJGVd/GeaEHjIjMAHoDdUUkFcfFeW8RaYtjStoO/NotZ4OIvI3TgZ4F3KuqnokHv8EZWRUDzHG38k/fvs763EuW0DNuAgCLd9iIKMMwwpMiXZQD80Tkd8AsIHelHlUtdKSTqt7sI/i/haSfAEzwEZ4MtAxAzvJF7drQuTN88w0tN+yjZuWa7Diygx2Hd5B4QWKopTMMw8hDIH0Wd+Csu70Ip79iJWCe70oD1xQVOXderhdam29hGEY4EkifxaOq2iTfdlEZyVex8Z5v4ZmcZ6YowzDCkEC8zt5bRrKcf3TqBLVqwZYt9IhsAlgnt2EY4UkgZqh5IvI7EWksIrU9W9AlOx+IispdPa/DyjRiomL4fv/37DuxL8SCGYZh5MX6LEKNa4qq9Pl8rmh8BeB4oTUMwwgnAvE6m7+/wvosShNPv8WXX9KjkbMooU3OMwwj3PCrLETkYa/9G/PFndMMbsMH8fGO+4/jx+l51HGVZcrCMIxwo7CWxUiv/cfyxZVvN+Hhhtu66LpiN1ERUazZu4Yjp4+EWCjDMIyzFKYsxM++r2OjJLheaGPnfknHhh3J0RyWpiwNsVCGYRhnKUxZqJ99X8dGSejRA2JiYNUqetbtAJgpyjCM8KIwZdHGs+Y20Nrd9xy3KiP5zg+qVHGWWwV67qkM2ExuwzDCC7/KQlUjvdbcjnL3PcfRZSnkeYFriur2dQqCsGLXCk5lngqxUIZhGA6BLn5kBBu3k/uCOQtoXb81mTmZLN+1PMRCGYZhOJiyCBeaN4eEBNi/n54xlwLmJ8owjPDBlEW4IJJriuqR4gw2Mz9RhmGEC6YswgnXFNVj4TYAlqYsJTM7M5QSGYZhAKYswos+fSAykgu/WskltS7mZOZJVu1ZFWqpDMMwTFmEFTVrwhVXQFYWPSQJsPkWhmGEB6Yswg3XFNXzJ2cJclMWhmGEA0FTFiIyWUT2ich6r7DaIjJPRH50f2t5xT0mIltE5AcRGeAV3kFE1rlxL4lIxXY14lEWX2wGHHflOZoTSokMwzCC2rKYQkGHg48C81W1GTDfPUZELsdxXNjCzfOKiES6eSYCo4Fm7laxnRh26AB165K4fhfxsRdy6PQhNuzbEGqpDMM4zwmaslDVRcDBfMHXAlPd/anAcK/wmaqaoarbgC1AZxFpANRQ1WWqqsAbXnkqJhER0K8fAvTMagSYKcowjNBT1n0W9VU1DcD9reeGNwJSvNKlumGN3P384T4RkdEikiwiyenp6aUqeJnizrfo+UMGYH6iDMMIPeHSwe2rH0ILCfeJqk5S1Y6q2jEuLq7UhCtz+vcHoMeXWwCnZeE0rAzDMEJDWSuLva5pCfd3nxueCjT2ShcP7HbD432EV2wuvBDatOGylNPUjapJ2vE0th7aGmqpDMM4jylrZTEbuM3dvw340Ct8pIhUFpEmOB3ZK1xT1TER6eqOgrrVK0/FZuBABOhx2rHUmZ8owzBCSTCHzs4AlgHNRSRVRH4FPA30E5EfgX7uMaq6AXgb2Ah8BtyrqtnuqX4DvIbT6b0VmBMsmcMKj+uPDccB8xNlGEZokYpqC+/YsaMmJyeHWoxz58wZqF2blTVO0PHXcFGti9g61kxRhmEEFxFZqaod84eHSwe3kZ9KleDqq2mzF6pLFX469BO7ju4KtVSGYZynmLIIZwYMICoHrjx2AWBDaA3DCB2mLMIZj+uPtYcBm5xX0Zm+bjpJLyYR8WQESS8mMX3d9FCLZBi5mLIIZy6+GJo2pef3pwFrWVRkpq+bzuiPRrPjyA4UZceRHYz+aLQpDCNsMGUR7gwYQKddUJko1u9bz4GTB0ItkREE/vDFHziZeTJP2MnMk4ybPy5EEhlGXkxZhDsDBlA5G7ocjAEcL7RGxUFV+WTzJ+w8utNn/M4jvsMNo6wxZRHuXHUVREfTc/0xILSmKLOpl4z89ffEwifoNaUXQ2YM8ZunXtV6fuMMoywxZRHuVK8O3brRY4dzWJJO7pK87M2mXjJ81d+fv/ozi3cupk5MHUa1GkUM0QXyHT59mC+3fRkCiQ0jL6YsygMDBnBFCkSq8F3adxw/c7zYpyjpy37c/HFmUy8BvuoPoGblmmwdu5U3T13Dqx9B4mEQhYTD0GOnkJGdweC3BjN3y9wyl9kwvDFlUR4YOJDqZ6B9ehTZms2ylGXFPkVJX/b+bOc7juxgVdoq84pbCKqOcvbF0Yyj1KxSE8aNY9TKTLa/CDlPwo4XYeHryugfqnE66zTDZg7jox8+KlO5zzfMzFo4pizKA61bQ/369NiSCUD/N/sX+2H297IPtAM1vka837j2k9rT/F/N+dOXf7JV/fKx/fB2Br812G98Qo3G8MUXsKOgMolQ+PfM44ztPJYz2We4btZ1xP09rsK+zEL5sg4HM2u4KytTFuWBiAh+6tSMnl7vk+I+zAk1E4oVnp+mtZsWCKtMFH2a9CEuNo4fD/7IXxb/hZYTW9LylZY89dVTbD6wOaBzV0SycrJ4YdkLtHilBXO2zCE2OpZKRObGR2bDresj+W6SQL9+fs8j9S/kxYEvMrjZYLI1m/0n91fIPqOyeFn7exmfyT7DQ3Mf8tny/v3nvydHc0pNhsJkC7WyKgpzJFhOGHtLHE+8u5+4h0G9loRKrJnI9vu3F5l/6pqp3P7B7QXCXx70Mvd0uqfQvPN/mk/faX2Jyoa4E7CnOiQcgQmLoxn1wOtk3TyChdsXMnP9TN7b9B6HTh/Kzdv2wraMbDGSm1rcRJNaTQK93HLN6j2ruXP2naxMWwnATS1u4h8nejL/nw/wVNdM+v4ED38NCUfdDPXrQ69e8NFHcOpU3pNVqQKzZ5O4/k6fw2sDvf/hTtKLST5NdaV1fZ6XsbdCiI6I5tK6l/LToZ84kXnCb94LqlzAFfFX0K1xN7oldKNTw05UrVS1xDJ5E+zrLw7+HAmasign1HtY2PN36HsrLLjobLgg5DxR9JfPZ5Me5pq0v1P1DDQ4Cqk14XQ0DKvang8eSsZZLqQgJ86coNXEVmw7vI2nvoQ/5h+MlZCQx4RyJvsMX/z0BbM2zOKD7z/gaMbR3LjOjTozosUIbmpxU6FmrfLKycyTPLnwSZ5b9hzZmk18jXheGfQKQ5sPhcRE2OnD5Fe7Nuza5SiF6dNh3DgnXePGEB8PS5dCVBS/GJbF9NYFswd6/8OdiCcjUD+LYOoTJX9HxT8fz65j/h1xRkdEk5mTWSA8UiLJzl0twSEqIoq2F7Z1lEfjblzZ+Eoa1fC72nNAyJO+/3+huL/mdbacE9swke8awO1r8oYHakZ656uJAPxuKfz4L9j8T6hxGmaf+I5pa6f5zffHL//ItsPbaLMHHvE1H3DnThg7FhYsgKwsKkVWYlCzQUwdPpW9v9vLByM+YGTLkVSNrsqKXSt46POHaPxCY7pP7s6/VvyLPcf3BFoFYc0XP31Bq4mteGbpM+RoDmM7j2XjPRsdRZGc7FtRABw65CgKgFGjYPt2yMlxFPDixfDQQ5CVxZvvwUNfU2BR4cY1Guc/Y7kkLtb3MsiVIiqdkzkzOyebpSlLGTd/HO3+065QRbH7wd28Pvx1YqVSnvBYqcTU66ay8/6dzPjZDMZ0GkO7C9uRozkk707mH8v/wU3v3ET8C/EkvZjEqPdG8cq3r7B6z2qyc7L9lJaX1XtWM2zGML/xgf6/ywJrWZQTpk+8h9TpE7n3W6jzMJyJgiqZ8Fqj3zDqN68UmjczO5ML/1CJg7Gw/mVoke6ET20Dt1/nDN9cf8/6Al/7y1KW0W1yNyIkghXv1qb92vTChaxdG4YOheuuc+zwsbG5USczT/LJ5k+YtWEWn/z4CaezHH9XERJBr8RejGgxgp9d/jPqxtYtfuWEkP0n9/PQ5w/xxpo3AGhVrxWvDn2VLvFdYM8e+MMfYMoU8Pc/S0x0FERhPP+8ozSAF7rCg/3J/czrF9OSzx9eVyrXEiq2HdpG639exnHNyBMu6phcq0ZX5Z/X/JPb297utwUMkH4inblb5/Lpj58yd+tcDp46ePZciM+WS66ZZ/p03nr+dt5ulkWEQnpVuHtNFKMenOIocS+OnznO8tTlfJ3yNV+nfM2ylGUcO3MsT5rqlarTNb5rbsuja3xXZm+ezbj549h5ZCcNqjUgvmY8K3atAKByZGWyszPJ4mwrIppIXr9+KqNa5S0/2JgZqryTlMTnkTvo/xMMHwEfXgbDN8H73xT9svnipy/oN60fl6bDxpfB83dTYPgdMcxOOEX/pv35bNRnuX/GjKwM2v2nHZv2b+LRbo/wt4c/h1Wr8p44JgYeecSxs7//PmzenDdu4EAYPhyGDHEUicuxjGPM/mE2szbM4rMtn+U2/yMlkr4X9WVEixFcd9l1XFDlghJVWWkzfd303D974xqNGXTJIN7Z+A77T+6ncmRlnuj1BL+78ndEZyu89BL8+c9w7BhERzsehOfPz9snERsLkyYVeBn5JC6O7AP7iVSY0RJ+1w/2VYOsSJh23TR+0foXwbvwIHIy8yTdJndj9Z7VtEmDiw9C4hH4tBk8uBQWtIxlRlOnn6FLoy7sPrab1KOpJNRM4Kmrn+Kyupfx6Y+f8umPn7Ji14o8CqFpraYMbjaYwZcMZtexXYyZfTcn9UxufCzRzGr9FENSYuDRRwv2F4HT6nvgAejUCTp2dEyD+RRWdk42G9I38PVOR3ksTVnKtsPb8qQR91+XX2FFR0Rzb6d7eXRvM7745/2M655Jag3IjoRqZ2DXpZOocctdJarj4mLKorwTEZH7dfplE+hzmzOB66d/QERO4ffw7o/v5j8r/8Mfv4KnFuSN2/PiX2iZ8QIHTh3g34P/za87/hpwzE8TFk+geZ3mrG7wJFVuGOkogNq1Yfdup69iwoS8L7pNmxyl8cEH8O23Z8MjI6F3b0dxDB/u/OFcDp8+zAfff8CsDbOYt3Vern04OiKaARcPYGSLkQxrPozqlaufW72VEr46SD1clXQV/xnyH5rVaQaffOK8XH780YkcMsRpGTRrlrdPwlf9FYbX/ffwansYPQxiomL45s5vaF3fR6dGGKOq3PbBbUxbO42mB+HbSVDrdL40AtNWTeXXH/86tzXqj0qRleid1JtBFw9iULNBzv3wMH0605+/nYltsmh+AIb+AAO2QkxWMYWuV89RGh7l0bEjXHhhgWS7j+1macpSvt75NUtTl+a2IPLTqHojUh9MzdOnpUDPX8KSRHhiVU3Gf3C4mEKWDFMW5Z2kpNyO5ByBpPshpSYs/LQ+vZb7t/tn52TT4LkGpJ9MZ/VEaHM0xvmCinF/hw7l7b+OYsS7Tr/C2t+s5WjGUTpO6kiO5rB4xFy69f2l0wn7r3/BvfcGJm9KCsye7SiPhQsh28uG27GjY6oaPhwuuyz3S23/yf28t+k9Zm2YxcLtC3OHLFaJqsKgZoMY0WIEg5sNLvWRKIGQ+EKiz9FIdWLqkP77dGTzZkdJzHGXiG/eHF580WldlQZe99+DAr/6eVVev+QETWs1JXl0cti1xgrj5RUvM2bOGGKjY/nmraq02uDDzFmtGqSm0ui1y9l9fHeB6EiJ5M72dzKo2SCubnI11SpVOxupClu2wFdfwf33wwkfI54iI2HkSPjsMzjgw6NzXBzcdZfz8ZOc7PQx5adRo7zKo2NHqFMnTxJ/Hdh1T0B69T/D44/nCV+cAD3vgGoZ8NO4fcRV9d2nEwzCSlmIyHbgGJANZKlqRxGpDcwCkoDtwE2qeshN/xjwKzf9WFUt0vdBhVMW06fD6NFw0vmyHXc1/LUn/LJ6TyY/+JXfbAu2LeDqN67m4hOV2fz3DOTtt+HGG52X/+WXw9Gj8NZbjIz+kFkbZlE5sjIZ2Y7tuH/T/sxNvgz+8Q/nz7BsmfPnKi4HDzpf3O+/7/wpvZv7l1ziKI3rroPOnZ0vaGDP8T28s/EdZm2YlcfTbmx0LEMvGcrIliMZePFAqkRVKb48AbL72G7mbpnLnC1z+N/G//lMU/M0HM58yKmjrCyoUQPGj4cxYxzzU2mR7/57ODXmbrq1XM6qPasYeslQPhj5ARES/uNWluxcwlVTryIrJ4sZA15l5HV/cvp4fNGoEUN67eKTS3xH546WUoXvv3eUg2dLSytaGFXf9ZvfTKgK27Y5SsOjPFaudEyN+WnSJI/yaLX8dtafScmNbnoAHvgG7lgtxGT6fgcPGgVzmsEDXR/g+QHPF30dpYQ/ZYGqlvmGowzq5gt7BnjU3X8U+D93/3JgDVAZaAJsBSKLKqNDhw5a4XjzTdXERFXQ7+ugjEer/bWaHs847jfLPR/fo4xHH+uDavXqqidPno2cNEkVVOvW1cnznlHGk2frcm9lzY4Q1chI1VWrSucaTpxQ/eAD1dtvV61d2ynfszVooHr33apz56pmZORmSTmSos8vfV67vNolj3w1/lZDb3nvFv34h481IytD31z7pia+kKgyXjTxhUR9c+2bxRItIytDF2xboI/Me0RbT2xdoD68N3kcvWMYuq9ahCO7iOqdd6ru3Vs69eQLz/0XUa1Vyym3UiX9ae5MrfV0LWU8esHfLjjn6w82nvvDeDTyyUhlPPrgJ/ep9uzpXEtCgmrjxs71JSaqPv20aufOuc/HG63R2g/nvQf9f99A9Z//VL3hBtV69fI+T+6zrddff7a+8m+JiV4CetVvYqJzXBTZ2arff++kve8+1W7dVGNifJb1Q230zVbo+83RbO+4QYNUH3usQL7vLnSus/JTlXXn4Z3BuCU+AZLV13vbV2CwNz/K4geggbvfAPjB3X8MeMwr3VzgiqLKqJDKwsOUKaqgXe+rqoxH31zj+6HOys7SC5+9UBmPrmyA6m235U2Qk6N69dWqoB+2iy3wMvy2gfvgPvhgcK4jM1N1wQLVsWOdF4X3H6hmTdWf/1z17bdVjx3LzbLt0Db9vyX/p+3+3S6PvFUnVM19AXm22AmxeV6YvpTJ9kPb9d/f/luHzxyu1f9avUD+IW8N0ZdXvKzPvfRzjR3nhF9xh1fdgPOCSE4OTh35IydH9d57nfJr1dIn3rijgEKL+UuMvr7qdc3IytAzWWc0KztLs3OyNScnp2xlVafuYyfkfcYinozQzUOudK6hYUPVlJSCGbOyVJ97TjOjo1RB91RFx/dyXrj7Y3y8/C+8UHXECNWXX1Zdv96pJ1XnZR4bmzdtbGxgCqG4ZGaqrlunOnmy6j335FF4nu10JPpjLfcDKbeSvJRVjRqqoCNur6aMR3/14a9KX04/+FMWoTJDbQMO4Zhd/6Oqk0TksKpe4JXmkKrWEpF/Ad+o6ptu+H+BOar6jo/zjgZGAyQkJHTY4cPfToXg5Elo2JCJzY5wzxDod1E/Pr/l8wLJFu9YTM8pPWlyPJqtz2Yic+dC//55E/30E7RqBSdPMmwkfHSpE/zbb+Clz2BnDUjYdcyxHQcTVWe01QcfOOaq9evPxlWu7AzFHT4chg1z7MjA5gObeXvD28zaMIv1+9b7PG3V6KqM7TKWtONpzFg3I9fEBr6HU7aIa8HAiwdyzcXX0D2hO5WjKjsRjRqxgt2cqARXbXeCTkZB7AV1Yd++AiNkyoTsbMd899FH7KwdxWV3Z3GyUtHZPAiCiCAIERKRuy/iHvvYz5+2sHze8TuP7CQrJ29v8kNfw7PzgKpVnTkl7dr5F7ZRI/Ye2U39/N0Onj6HXr2crVkz//eiJAMMSoo/mUSceTX5yciADh34MW0Dl/1WICKCDfdsoHnd5sGVk/Drs2ioqrtFpB4wD/gtMNuPsngZWJZPWXyqqu8WVkaF67PIz5gxHJz8Mg0ejiBTlJ0P7CwwT+K+Offx0oqX+P3X8Myaek4/RVRUwXO9+CI88AC7q8Hl9zpD9ja9DNXPwJ2/iuO11/aVzTV5s2XLWcWxbNnZkUAREdCt29kO8iaOCxF/HYhFIQjXXXYdA5sOZODFA2lc053kduqUY/P+7DOn03qzn4lh/v7sZcWJE85Is+RkvmkI3X/lDLv0JioiihzNcb4Q/cySLmsGboY5b0G2QOTsj5xRY4XhYzRYLiF4hxUbHwMUgMLn2axcCV26MHpQNq92cNzGzLphVjClBMJMWeQRQGQ8cBy4C+itqmki0gBYqKrN3c5tVPVvbvq5wHhVLdRPd4VXFmvWQNu23PjzaN65JJOn+zzNI90fyY3O0RwSXkhg17FdLH8VOl//W2fsvy+ys0nvcBlxa37ktXbO8MWfbYIPLxOOz5pW5pOCCrBnjzOy6oMPHA+tmV5uGdq0geuu45rj/+GzqmlnJ5G41Impw9guY3li4RN+T69P6NmRM3PmONvChXDaa6imiO+XUiCT6oLN3r2kXN6Ixgez+bA5XD8Cctw+bl++hTxKw/PrrUhU3WMf+yVJ2+v1Xrmjma7cAQumQqUcePz6Wvz53YMUybm8bMOJQDrQffH446T+4ykuvk/IiFRWjl5J+wbtgyqqP2Xh4zMzuIhIVSBCVY+5+/2BPwOzgduAp93fD90ss4G3ROR5oCHQDPA9aPl8ok0b6NSJW5O/5Z1LHEeBD3d7OHdS3Tep37Dr2C4SjkXSaVd24Q9kZCRxP7+T7LWPcKc77+54NGRHRTJqLdAq+JdTKBde6PzRRo92Rm99+qmjOD791FGaa9YwB9h2Abx/KXxxEWyp7czC/Ue9mxjV63Emr5pcwFFb7BkYsS/OGbk0Z45jkvOmfXtn6Os11zhxv/lNwT/7hAnBvvqiqV+f1WNupOozM7n2B3j7f7DqQojKgeE1L4TTTztf5iIggkQ4pqHcsGD/ijBteztePLCbiByY/KGjKF7uBM37jgzsGidM8P2yDYf6DwTP/6+4ZrA//pH4Dz/k3uVref5KGPflOOaMmhN8eX3hqyMjmBtwEc7opjXABmCcG14HmA/86P7W9sozDmcU1A/ANYGUU6E7uD1MmqRnItC4P0Qr49Fvd32bG/XAZw84o036o3rRRWc7+vzhjrIqdLRIuHH6tOqnn6redZdqREQB2XPAGcnVo4du6dpcn+qB/uI69IH+6NyLnE7GPHlq11YdOVJ16lTVtLSC5Z3LaJmyIjFRP/d1TWG6fX4ROr1lMZ+vcK7/YLJqlaZXj9TqjzkDA77a/lVQiyOcOrjLggpvhgJnfHfDhtzf/Tj/6ApjOo3hn4P+iaqS+GIiKUdTWPoaXHH7H+Gppwo/lz+bcKht8oFyDh3MCkilSvDYY04LolOnc5tHEg4UZtN/5BHnHqqG7neun6lR5eX5CjVPPcWT8x9n/FXQrWFXFt+5tFA/WSUhrOZZlMV2XrQsVFXvuit3PHad/6ujGVkZujx1uTIebfSQaLagunFj0ecpjy0Lb/zJ37Ch6hdf+P/KFQm15KVDuN+/cJcv3DlzRo92aqN1f+/81z/+4eOgFYWflkX4T/U0Cueuu2i7B1rtj+TAqQN8+uOnvLPRGVX8sw1KRNt2jkuNopgwIY+XWKB82YT9yf/MM9Cnj9MR6ouE8HEBXSLC/f6Fu3zhTnQ01Se/yR+WOi3fcR+OLZMV/LwxZVHe6dgRadOGW79zfC9NXTM1V1ncuBH4+c8DO8+oUc7IjMRExzSQmBi4R9RwoCj5K/rLKtzvX7jLVx5o2ZLfDH6C+COw5uRPzFrxepkWb30WFYGXXybt0THEP+Q4GQRocAxSnofInSl5vLye14RyUpZhlAZZWbw2ohl3td5O08zqbHryANGRpeiDDFspr2IzahRxWZUYsOVs0PWbYElSBNMP+XcyeN7hvRLd9u2mKIzyR1QUt/95NpccELZGH+P1aQ+WWdGmLCoCF1zAB62iudVrydUbNsKbLXMYN39c6OQyDKPUiWrRiqcaOh86T258hVPpBV23BwNTFhWEF1ud4NrvIeEwXJYOXVLgncth5xE/az8bhlFuueF3k2l3tCq7q+bw8p+HlkmZpiwqCKlNarPtAtjwCiRPgrkXw+EYSIiqXWRewzDKFxFR0UwY9iIAf4v9jiPvvRX8MoNeglEmTJgvTG3rOAGMzYS3WjnuLCZ8EWrJDMMIBgN7/ooeUU05GAvPTb4L9u8PanmmLCoIo746SMddjk+n/TGwtj5M+sgJNwyj4iEi/O0XzvDZ59ucZN/9dwW1PFMWFYWEBG7cBNUyoe4p+P5lGLWOijPpzDCMAnRL7MHgRldxohL8bf8H8E6BZX5KDVMWFYWKPunMMAyfTBjyAgCvdIKdd93kTHpMSnLmFZUipiwqCjZD1jDOS9pc2Iabq3blTBQ82dOdZL1jh+PSvRQVhs3gNgzDKOf82LoRl17nzLfY8Aq80hG67IJRR4u/OFTYLH5kGIZhlC4r2E2EQlYk/GYw7KwJ/20PfLSD0rItmBnKMAyjnDNuQCRZkYDCwibwU204WckJLy1MWRiGYZRzdlZzvE7nX4M+N7wUMGVhGIZRzkmo6Xu9Fn/h54IpC8MwjHLOhD4TiI3OO3Q+NjqWCX1Kb+h8uVEWIjJQRH4QkS0i8mio5TEMwwgXRrUaxaShk0ismYggJNZMZNLQSYxqVXpD58vF0FkRiQQ2A/2AVOBb4GZV3egvjw2dNQzDKD7lffGjzsAWVf1JVc8AM4FrQyyTYRjGeUN5URaNgBSv41Q3LA8iMlpEkkUkOT09vcyEMwzDqOiUF2UhPsIK2M9UdZKqdlTVjnFxcWUglmEYxvlBeVEWqUBjr+N4oGzWEjQMwzDKjbL4FmgmIk1EpBIwEpgdYpkMwzDOG8rFaCgAERkEvAhEApNVtdABxCKSDuwoA9HOhbpAcJe1KhkmX8kw+UqGyVcySipfoqoWsOOXG2VRkRCRZF9D08IFk69kmHwlw+QrGcGSr7yYoQzDMIwQYsrCMAzDKBJTFqFhUqgFKAKTr2SYfCXD5CsZQZHP+iwMwzCMIrGWhWEYhlEkpiwMwzCMIjFlUcaIyHYRWSciq0Uk5G5xRWSyiOwTkfVeYbVFZJ6I/Oj+1goz+caLyC63Dle7c3BCIVtjEVkgIptEZIOI3OeGh1P9+ZMxXOqwioisEJE1rnxPuuFhUYeFyBcW9efKEikiq0TkY/c4KHVnfRZljIhsBzqqalhM6hGRnsBx4A1VbemGPQMcVNWn3bVDaqnqI2Ek33jguKo+GwqZvGRrADRQ1e9EpDqwEhgO3E741J8/GW8iPOpQgKqqelxEooElwH3A9YRBHRYi30DCoP4ARORBoCNQQ1WHBOv/ay2L8xxVXQQczBd8LTDV3Z+K83IJCX7kCwtUNU1Vv3P3jwGbcLwhh1P9+ZMxLFCH4+5htLspYVKHhcgXFohIPDAYeM0rOCh1Z8qi7FHgcxFZKSKjQy2MH+qraho4LxugXojl8cUYEVnrmqlCZubxICJJQDtgOWFaf/lkhDCpQ9eMshrYB8xT1bCqQz/yQXjU34vAw0COV1hQ6s6URdnTTVXbA9cA97pmFqN4TASaAm2BNOC5UAojItWAd4H7VfVoKGXxhw8Zw6YOVTVbVdvieJPuLCItQyWLL/zIF/L6E5EhwD5VXVkW5ZmyKGNUdbf7uw94H2cVwHBjr2vr9ti894VYnjyo6l73D5wDvEoI69C1Y78LTFfV99zgsKo/XzKGUx16UNXDwEKc/oCwqkPIK1+Y1F83YJjbDzoTuFpE3iRIdWfKogwRkapuJyMiUhXoD6wvPFdImA3c5u7fBnwYQlkK4PkjuFxHiOrQ7fz8L7BJVZ/3igqb+vMnYxjVYZyIXODuxwB9ge8Jkzr0J1841J+qPqaq8aqahLNsw5eq+guCVHc2GqoMEZGLcFoTAFHAW0W5Wg82IjID6I3j1ngv8ATwAfA2kADsBG5U1ZB0MvuRrzdO81+B7cCvPTbaMpatO7AYWMdZm/EfcPoEwqX+/Ml4M+FRh61xOmEjcT5e31bVP4tIHcKgDguRbxphUH9ecvYGfueOhgpK3ZmyMAzDMIrEzFCGYRhGkZiyMAzDMIrElIVhGIZRJKYsDMMwjCIxZWEYhmEUiSkLIyBEpI6Xh809+TxuVirlsiJFZLY43lL/684VONdzLRSRUl+8vjQQkbah9FZaHM5VVhFpKCLvBJDuU898BiM8iQq1AEb5QFUP4IwrD7rXV1XNBoYF49xhRlscb6Gf5o8QkShVzQq2AMUopy3nIKvrseCGok6uquVCaZ7PWMvCOGdE5C4R+VYcX//vikisGz5FRCa6LYOfRKSX62xtk4hM8co/UUSSxWudADd8u4g8KSLfibP2x6VueG0R+cB13vaNO2Eqv0wxIjLTTTMLiPGK6y8iy9zz/s/1l5Q//0IReUFEFrnydhKR98RZG+Avbpokybu+xu9cBYqINBWRz8RxFLnYS/YbRWS9W1eL3NbYn4ERbutshDhrJEwSkc+BN9xyFrvyficiV/qQN0lEvheRqe41v+N1Hx53789697zidY1/FZGvgPtEZKiILBdnTYQvRKR+vjLOWVbvuhKR2926/Mytz2fy3fO6bvpNIvKq+1x8Ls7Madx7sda9h3/3vgdGGaCqttlWrA0YD/wOqOMV9hfgt+7+FBxfNYLjLvko0Arn42Ql0NZNV9v9jcTxudPaPd7uda57gNfc/X8CT7j7VwOrfcj2IDDZ3W8NZOF8EdcFFuGsTQDwCPC4j/wLgf9z9+8DdgMNgMpAKlAHSALWe+X5HTDe3Z8PNHP3u+C4YABnBnUjd/8C9/d24F/56nUlEOMexwJV3P1mQLIPeZNwZhF3c48n48zkza1fd38aMNTrGl/xiqvF2Qm6dwLP+SjnnGT1riv3HD8BNYEqwA6gsdc9r+umz+LsM/I28At3fz1wpbv/tPc9sC34m5mhjJLQ0v3avgCoBsz1ivtIVVVE1gF7VXUdgIhswHkhrAZuEsdNexTOC/lyYK2b3+OUbyXOQjgA3YGfAajql+L0o9RU1SNe5fYEXnLTrBURz/m6uuf/2v3ArgQs83Nds93fdcAGdd04iMhPQGPgsK9MbkvlSuB/crabpbL7+zUwRUTe9ro2n2Wr6il3Pxr4l4i0BbKBS/zkSVHVr939N4GxwLPAVSLyMM6LvDawAfjITTfLK388MEscf0eVgG2FyFdSWed77peIbAQSgZR8abap6mp3fyWQJE5/RnVVXeqGvwUMCVBOoxQwZWGUhCnAcFVdIyK34/hs8pDh/uZ47XuOo0SkCc4XeSdVPSSOeaqKj/zZnH1OfXV0+/JX4ytMcNYiuNnfxQQqO86Xr7cJ1yN3BHBYHXfWeQVSvVtEuuAsVLPafan64oTX/gM4/rDauOc+7SdP/utVEakCvIKzKmOKaybzrl/vcv4JPK+qs8XxMTTeTzmlIat3fXrf28LSxOD73htliPVZGCWhOpAmjgvsUcXMWwPnZXPEtZFfE0CeRZ5y3Jfafi24foR3mpY4piiAb4BuInKxGxcrIv6+fotiL1DPbdlUxv3CdWXZJiI3umWIiLRx95uq6nJVfRzYj9NCOYZTh/6oCaSp4wb7FhxznS8SROQKd/9mnKU/PYphv9viKayTuSawy92/zU+a0pL1nFDVQ8AxEenqBo0szfMbRWPKwigJf8LxsDoPx610wKjqGmAVjmlkMo6ZpijGAx1d09LT+H6xTQSquWkeBla45aXj2MxnuHHfAJcWR2Yv2TNxOnyXAx+T99pHAb8SkTU413atG/53cTrr1+MotDXAAuByT6exj6JeAW4TkW9wzDonfKQBZ6nU29zrqg1MVGfthVdxTGkfAN8WcknjcUxni3EUmS9KS9aS8Ctgkogsw2lpHCkivVGKmNdZwyjHiLNU6seqGlarywUDEamm7nrYIvIo0EBV7wuxWOcN1mdhGEZ5YbCIPIbz3tqB01I0yghrWRiGYRhFYn0WhmEYRpGYsjAMwzCKxJSFYRiGUSSmLAzDMIwiMWVhGIZhFMn/A3O4glWeO8dSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los tamaños de muestra para entrenamiento contra los errores promedio derivados del subconjunto de entrenamiento\n",
    "\n",
    "plt.scatter(df_MSE[\"Tamaño_muestra\"], df_MSE[\"AVG_MSE_train\"], color = \"red\")\n",
    "\n",
    "plt.plot(df_MSE[\"Tamaño_muestra\"], df_MSE[\"AVG_MSE_train\"], color = \"red\", label = \"Evolución en training\", \n",
    "        linewidth = 2)\n",
    "\n",
    "# Graficar los tamaños de muestra para entrenamiento contra los errores promedio derivados del subconjunto de validación\n",
    "\n",
    "plt.scatter(df_MSE[\"Tamaño_muestra\"], df_MSE[\"AVG_MSE_validation\"], color = \"green\")\n",
    "\n",
    "plt.plot(df_MSE[\"Tamaño_muestra\"], df_MSE[\"AVG_MSE_validation\"], color = \"green\", label = \"Evolución en validación\", \n",
    "        linewidth = 2)\n",
    "\n",
    "# Nombre del eje horizontal (x)\n",
    "\n",
    "plt.xlabel(\"Tamaño de muestra para training\")\n",
    "\n",
    "# Nombre del eje vertical (y)\n",
    "\n",
    "plt.ylabel(\"Error promedio\")\n",
    "\n",
    "# Título del gráfico\n",
    "\n",
    "plt.title(\"Evolución del error promedio en training y validación\")\n",
    "\n",
    "# Agregar una leyenda al gráfico\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico elaborado\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7115b5",
   "metadata": {},
   "source": [
    "## Interpretación del gráfico de tamaño muestral vs error promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd147cc3",
   "metadata": {},
   "source": [
    "En términos generales, en cuanto a la gráfica previa, es posible observar que para el modelo entrenado con el mínimo tamaño \n",
    "de muestra de entrenamiento posible (2 muestras), el gráfico muestra que para ese tamaño muestral, el grado de error promedio tanto del entrenamiento como de la validación del modelo es muy elevado, dado que en este caso particular, el error promedio para el entrenamiento fue ligeramente superior a 3000, mientras que de forma similar, el error promedio correspondiente a la validación fue ligeramente superior a 3500, motivo por el cual, al entrenar un modelo con solamente 2 muestras de datos, se tienen errores promedio muy altos, lo cual indica que el modelo en cuestión no se ajusta adecuadamente a los datos, lo cual se encuentra respaldado por el hecho de que los modelos entrenados con muestras de tamaño 2, presentaron un MSE promedio de 3145.68 en el conjunto de entrenamiento, además de un MSE promedio de 3628.90 en el conjunto de validación, lo cual pone de manifiesto que los modelos entrenados con una muestra de tamaño 2 presentan un tipo de ajuste denominado como subajuste (underfitting), esto principalmente debido a que al entrenar los modelos con una cantidad de muestras bastante reducida, dichos modelos no serán capaces de aprender correctamente los patrones detrás de dichos datos, ya que es necesaria una mayor cantidad de éstos para que pueda surgir algún patrón o tendencia claramente definido, además de lo anterior, también cabe mencionar que debido al hecho de que los modelos entrenados con muestras de tamaño 2 tienen valores de MSE muy elevados, se afirma que existe un grado de sesgo alto en dichos modelos, dado que las diferencias entre los valores reales que intentaron predecir y los que finalmente predijeron, son significativamente grandes, por lo que lo anterior referente a tener un sesgo alto señala que los modelos en cuestión no representan con suficiente precisión aquellos datos reales que se intentan predecir, por lo tanto, no son buenos ajustes para los datos reales que son el objetivo central de las predicciones (aproximar lo máximo posible las predicciones a los datos reales), sin embargo, otro criterio para determinar si los modelos constituyen un buen ajuste para los datos reales es por medio del análisis de la varianza de los mismos, por lo cual, en caso de que la varianza sea muy grande, significará que nuevamente las diferencias entre datos reales y predicciones serán muy altas y por tanto el modelo no será preciso y como consecuencia también sus predicciones no serán confiables, por lo que teniendo esto en cuenta, para el caso particular de los modelos entrenados con muestras de tamaño 2, en el gráfico previo se puede apreciar que para dichos modelos en específico, el MSE promedio en el subconjunto de entrenamiento fue ligeramente superior a 3000, mientras que su MSE promedio en el subconjunto de validación fue mayor a 3500, por lo cual se observa una diferencia mayormente significativa entre ambos errores promedio, lo cual indica a su vez que los modelos en cuestión (entrenados con muestras de tamaño 2), como ya se mencionó anteriormente, tienen un alto grado de sesgo, lo cual implica a su vez que los modelos en cuestión entrenados con muestras de tamaño 2, tienen un grado de varianza bajo, lo cual a su vez implica que en el modelo en cuestión, el valor de la variable de respuesta (grados en valks) tiene una baja sensibilidad a cambios en los datos de la variable predictora (grados en celsius), por lo tanto, eso significa que las predicciones del modelo tendrán valores mayormente cercanos entre sí, pero dichas predicciones no representarán de forma confiable los datos reales que se tratan de predecir, por lo cual, conisderando todo lo anterior, se afirma que en efecto, dichos modelos presentan subajuste (underfitting) como se mencionó previamente, provocando a su vez altos errores de predicción y una confiabilidad prácticamente nula de sus predicciones. \n",
    "\n",
    "Por otra parte, también es importante mencionar que respecto al modelo entrenado con 40 muestras, en la gráfica anterior se puede observar que cuando el tamaño de las muestras de entrenamiento es igual a 40, el error MSE promedio en el subconjunto de entrenamiento adopta un valor de 149.39, lo cual es significativamente menor que el MSE promedio para el entrenamiento del modelo entrenado con 2 muestras, mientras que por otro lado, el error MSE promedio en el subconjunto de validación para el modelo entrenado con 40 muestras tiene un valor de 110.05, lo cual resulta ser considerablemente menor que el MSE promedio en el subconjunto de validación para los modelos entrenados con 2 muestras (tamaño muestral mínimo posible para el análisis), por lo cual, en base a lo anteriormente mencionado, se puede afirmar que el sesgo del modelo entrenado con 40 muestras es significativamente menor al del modelo entrenado con solamente 2 muestras, motivo por el cual, eso significa que debido principalmente al hecho de que los MSE promedio tanto en el subconjunto de entrenamiento como de validación para el modelo entrenado con 40 muestras son significativamente menores a los de los modelos entrenados con 2 muestras, se puede afirmar que dado que el modelo entrenado con el mayor número de muestras (modelo base), posee errores MSE promedio significativamente menores, eso implica que el grado de sesgo del mismo es bajo, dado que las diferencias entre los datos reales y las predicciones derivadas de dicho modelo también serán mucho menores, por lo que las predicciones derivadas del modelo base estarán mucho más próximas a los datos reales que se desean predecir, sin embargo, por otro lado, en cuanto a la varianza del modelo entrenado con 40 muestras, es posible afirmar que dado el hecho de que el sesgo de dicho modelo es bajo, entonces ese mismo modelo posee un grado de varianza alto, lo cual implica que dentro del modelo en cuestión, la variable de respuesta (grados en valks) será altamente sensible en su mayoría a cambios o variaciones en los datos de la variable predictora (grados en celsius), lo cual no necesariamente implicará que las predicciones derivadas del modelo sean incorrectas, sino que significará que el modelo será capaz de realizar predicciones que se encuentren dentro de un espacio significativamente más grande de posibles valores que puedan tomar los datos predichos por el modelo, lo cual a su vez podrá aumentar o disminuir notoriamente el grado total de error que tengan las predicciones del modelo, por lo cual será importante calcular otras métricas de error para evaluar el rendimiento del modelo además del cálculo del MSE, como pueden ser el coeficiente de determinación $R^{2}$ para saber qué tanto porcentaje de la variabilidad total de los datos que se desean predecir es capaz de explicar el modelo en cuestión, por lo que en caso de que dicho coeficiente adopte un valor menor a 0.7, podrá considerarse que el modelo no consigue explicar suficiente proporción de variaiblidad de los datos originales, por lo las predicciones derivadas del mismo no serán confiables para tomarlas en cuenta en un proceso de toma de decisiones cuyas implicaciones puedan ser bastante desfavorables para quienes tomen las decisiones.\n",
    "\n",
    "Adicionalmente, otro aspecto que es muy importante mencionar radica en que con base en el gráfico previo, se evidencia que existe una relación entre el cambio en el tipo de ajuste que experimentan los modelos conforme aumenta el tamaño de muestra con el que son entrenados, esto debido a que en el gráfico se consigue apreciar que cuando el tamaño de muestra para entrenamiento es mayormente pequeño, concretamente igual a 2, el nivel de error MSE promedio resulta ser mayormente alto, mientras que también se aprecia que conforme se incrementa gradualmente el tamaño muestral para entrenamiento, el nivel de los errores MSE promedio tiende a disminuir, esto indica principalmente que los modelos entrenados experimentan cambios en cuanto a su grado de varianza y de sesgo, esto principalmente en el sentido de que cuando el tamaño de las muestras de entrenamiento comienza a aumentar, el grado de sesgo de los modelos comienza al mismo tiempo a disminuir, dado que por ejemplo, cuando el tamaño de muestra para entrenamiento aumenta de 2 a 5, se aprecia que los errores MSE promedio disminuyen, por lo que el sesgo para los modelos entrenados con 5 muestras resulta tener situado entre 1000 y 1500, en comparación con el sesgo de los modelos entrenados con 2 muestras que era superior a 3000, además, el grado de varianza para los modelos entrenados con 5 muestras resulta ser mayor al de aquellos entrenados con solo 2 muestras lo que implica que los modelos entrenados con 5 muestras son más sensibles a cambios en los datos de entrada que se les proporcionen en comparación con los de 2 muestras, cuyo grado de sensibilidad a cambios en los datos de entrada es menor, además de que al volver a incrementar el tamaño de muestras de entrenamiento, esta vez a 10 muestras, se observa que en ese caso los errores MSE promedio son notablemente menores que para 5 muestras, por lo cual, el sesgo de los modelos entrenados con 10 muestras resulta ser mayormente próximo a 500, aunque también dicho valor de sesgo resulta ser considerablemente menor al sesgo de los modelos entrenados con 5 muestras, por lo que los modelos entrenados con 10 muestras ofrecen predicciones significativamente más precisas que los entrenados con 5 muestras, además la varianza de los modelos entrenados con 10 muestras resulta ser considerablemente mayor a la de los modelos que se entrenan con 5 muestras, provocando que los modelos entrenados con tamaño muestral de 10 sean significativamente más sensibles a cambios en los datos de entrada que los entrenados con 5 muestras, además por otro lado, al entrenar modelos con 15 muestras, se observa que los errores MSE promedio nuevamente experimentan una ligera disminución en comparación con el caso previo de 10 muestras, lo cual implica que el sesgo de los modelos entrenados con 15 muestras resulta ser inferior a 1000, aunque dicho sesgo a su vez también es aproximadamente igual al de los modelos entrenados con 10 muestras, lo cual implica que los modelos entrenados con 15 muestras arrojan predicciones aproximadamente con la misma cantidad de precisión (aproximadamente la misma lejanía respecto de los datos reales) que los modelos entrenados con 10 muestras, además la varianza de los modelos entrenados con 15 muestras resulta ser aproximadamente idéntica a la de los entrenados con 10 muestras, por lo que los modelos entrenados con 15 muestras tienen aproximadamente la misma cantidad de sensibilidad a cambios en los datos de entrada porporcionados que los modelos entrenados con 10 muestras, por lo que las predicciones de los mismos tienen un margen de variación aproximadamente idéntico que en el caso de 10 muestras, por otro lado, para los modelos entrenados con 20 muestras, dado que los errores MSE promedio vuelven a disminuir ligeramente, el sesgo para los modelos entrenados con 20 muestras resulta tener un valor entre 500 y 1000, mismo que también es ligeramente mayor al sesgo de los modelos entrenados con 15 muestras, por lo cual, los modelos entrenados con 20 muestras tienden a devolver predicciones ligeramente menos precisas que los modelos entrenados con 15 muestras, además de que también la varianza de los modelos entrenados con 20 muestras es ligeramente menor a la de los modelos entrenados con 15 muestras, lo cual conduce a que con 20 muestras de entrenamiento, las predicciones de los modelos poseen una sensbilidad ligeramente más baja a fluctuaciones en los datos de entrada, lo cual lleva a que sus predicciones puedan tener un margen de variación ligeramente menor a las de los modelos entrenados con 15 muestras, mientras que al mismo tiempo, para los modelos entrenados con 25 muestras, los errores MSE promedio nuevamente disminuyen en una ligera proporción que con 20 muestras, por lo que el sesgo de los modelos entrenados con 25 muestras resulta tener un valor considerablemente inferior a 1000, aunque dicho sesgo también es ligeramente inferior al sesgo de los modelos entrenados con 20 muestras, por lo cual, los modelos entrenados con 25 muestras ofrecen predicciones ligeramente más precisas que los entrenados con 20, mientras que del mismo modo, la varianza de los modelos entrenados con 25 muestras resulta ser ligeramente mayor a la de los entrenados con 20, indicando que al entrenar modelos con 25 muestras, las predicciones de dichos modelos podrán presentar una mayor variación que las de aquellos entrenados con 20 muestras, mientras que de forma similar, para modelos que se entrenen con 30 muestras, los MSE promedio nuevamente incrementan ligeramente, provocando que el sesgo para dichos modelos entrenados con 30 muestras tenga un valor nuevamente ubicado entre 500 y 1000 tal como en el caso previo de 20 muestras, provocando que las predicciones de los modelos entrenados con 30 muestras tengan aproximadamente la misma cantidad de precisión que las de aquellos modelos que se entrenan con 20 muestras, además de que la varianza para los modelos entrenados con 30 muestras resulta ser ligeramente menor a la de los modelos entrenados con 25 muestras, lo cual implica que las predicciones de los modelos entrenados con 30 muestras son menos sensibles a variaciones en los datos de entrada, permitiendo que las predicciones de éstos modelos tengan un menor margen de variación que las de los modelos entrenados con 25 muestras, lo que ocasiona que las predicciones de modelos entrenados con 30 muestras ya se vayan acercando de forma notoria a los datos reales, mientras que por otro lado, para los modelos entrenados con 35 muestras, el sesgo resulta tener un valor considerablemente más cercano a 500 que a 1000, lo cual implica que las predicciones de dichos modelos, resultan ser más próximas a los datos reales (más precisas) que aquellas provenientes de modelos entrenados con 30 muestras, incrementando por tanto la confiabilidad de las predicciones de modelos entrenados con 35 muestras, además, la varianza para modelos que se entrenen con 35 muestras resulta ser ligeramente mayor a la de los modelos entrenados con 30 muestras, lo cual significa que las predicciones de los modelos entrenados con 35 muestras tienen una sensibilidad ligeramente mayor a los cambios en los datos de entrada que las de los modelos entrenados con 30 muestras, lo cual implica que las predicciones derivadas de modelos entrenados con 35 muestras poseen un margen de variación aún mayor que las de los modelos entrenados con 30 muestras, por lo que las predicciones que se obtengan de modelos entrenados con 35 muestras tienen un margen de variación más amplio, lo cual propicia que aumente la probabilidad de encontrar valores que se ajusten de la mejor forma posible a los datos reales, dentro de ese espacio más amplio de posibles valores que puedan tomar las predicciones del modelo, por lo que en resumen, al aumentar el número de muestras de entrenamiento, tanto el sesgo como la varianza de las predicciones de los modelos entrenados tendrán una tendencia general a disminuir, conduciendo a obtener predicciones cada vez más cercanas a los datos reales. \n",
    "\n",
    "Por lo cual, considerando lo anterior, se puede afirmar que en un principio cuando el tamaño de muestra para entrenamiento es igual a 2 (tamaño de muestra mínimo posible), el tipo de ajuste que experimenta el modelo es underfitting (subajuste), dado que el modelo al ser entrenado con muy pocas muestras, no pueden aprender algún patrón, o tendencia en particular detrás de los datos, ya que la cantidad altamente reducida de datos para aprender o entrenar modelos propicia que aún no exista algún patrón o tendencia específica subyacente a dichos datos, lo cual entorpece el proceso de aprendizaje o entrenamiento del modelo en cuestión, ya que no logrará aprender patrones o tendencias ocultos en los datos en base a los que es entrenado, resultando de esa manera en un proceso de entrenamiento deficiente y como consecuencia también en un rendimiento igualmente deficiente al predecir la salida en valks para datos en celsius que el modelo aún no conozca, por lo que el modelo no será capaz de predecir más allá de los datos que ha aprendido de su entrenamiento, motivo por el cual, en pocas palabras, a medida que el tamaño de muestra para entrenar los modelos aumenta, el tipo de ajuste de dichos modelos cambia de tal manera que en un principio al tener tamaño de muestra pequeño para entrenar, los modelos tienen underfitt, mientras que posteriormente al ir aumentando de forma gradual el tamaño muestral para el entrenamiento, el underfitt pasa a ser un ajuste de tipo fitt, puesto que al aumentar el tamaño de muestra para entrenar, se va definiendo gradualmente algún patrón o tendencia subyacente a ellos que los modelos puedan aprender durante su etapa de entrenamiento, por lo que las predicciones derivadas de los mismos también experimentan una mejoría gradual, no obstante, es necesario asegurarse de no incrementar de forma excesiva la cantidad de muestras para entrenar el modelo, ya que esto puede ocasionar que el modelo resultante para representar los datos originales se pueda tornar demasiado complejo (por ejemplo tener que agregar una cantidad de variables predictoras mucho mayor al modelo inicial), lo cual puede conducir a tener un overfitt, dado que el modelo al ser altamente complejo, tenderá a \"memorizar\" la salida de los datos de entrenamiento que se le proporcionen, dando como resultado un rendimiento y precisión aparentemente muy favorables al predecir los datos de entrenamiento, pero cuando el modelo se encuentre con datos que no conozca en absoluto, la precisión de sus predicciones decaerá de forma muy significativa, por lo cual lo adecuado es mantener el tamaño de muestra para el entrenamiento en valores que no sean muy bajos pero tampoco muy altos. \n",
    "\n",
    "**Nota 1:** el MSE es la representación del grado de sesgo de los modelos en cuestión.\n",
    "\n",
    "**Nota 2:** Dado que el sesgo y la varianza se contraponen entre sí, a mayor sesgo menor varianza y viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395bf06b",
   "metadata": {},
   "source": [
    "## Tamaño de muestra más adecuado para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485d2bc",
   "metadata": {},
   "source": [
    "En términos generales, en base al gráfico previamente realizado y al análisis para los diferentes tamaños de muestra para entrenamiento de los modelos, se puede observar que en efecto, al aumentar el tamaño muestral para el proceso de entrenamiento de los modelos, éstos mismos se ajustan gradualmente mejor a los datos que intentan predecir, esto se debe principalmente al hecho de que conforme los datos para entrenar los modelos son mayores en cantidad, es posible definir de una mejor manera el patrón o tendencia particular que seguirán dichos datos, por lo cual, en el caso de tomar en cuenta los tamaños de muestra comprendidos entre 35 y 40 sin tomar en cuenta a éste último tamaño, es posible notar en el gráfico anterior que para dichos tamaños muestrales, el MSE promedio tanto en el conjunto de entrenamiento como en el de validación, resulta tener un valor mayormente reducido y próximo a 0, en comparación con el resto de los tamaños de muestra para entrenamiento graficados, lo cual indica que cuando el modelo se entrena con una cantidad de muestras entre 35 y 40, es decir con un tamaño muestral muy cercano a  la máxima cantidad posible de muestras, los errores promedio de las predicciones contra las observaciones reales que se intentan predecir, adoptan los mínimos valores posibles, motivo por el cual, al entrenar el modelo con un tamaño muestral comprendido entre 35 y 40 muestras, prácticamente se logra definir lo mejor posible un determinado patrón o tendencia detrás de los datos que se desean predecir, por lo cual, al usar este tamaño de muestra, también permitirá que los modelos entrenados en base al mismo, puedan aprender con un grado mayor de facilidad dicho patrón o tendencia que subyace a los datos analizados, lo cual conducirá a que como consecuencia de lo anterior, el modelo entrenado tenga una capacidad mayor o más amplia para a su vez generalizar dicho patrón o tendencia aprendido a nuevas instancias que aún no conozca, es decir, que al momento de emplear el patrón o tendencia que haya aprendido de los datos de entrenamiento para predecir el resultado de la variable de respuesta (grados en valks) a partir de los datos de la variable predictora (grados en celsius), sobre un conjunto de datos que el modelo todavía no conozca, las predicciones resultantes de dicho modelo sobre dichos datos desconocidos para el mismo, sean mayormente precisas, en el sentido de que las predicciones derivadas del modelo tengan el mayor acercamiento posible a los valores de los datos verdaderos, motivo por el cual, se puede concluir que el tamaño de muestra más adecuado para el entrenamiento del modelo predictivo es un tamaño muestral entre 35 y 40, por lo cual, se escogerá un valor medio en ese rango, en concreto 38 muestras, como una cantidad mayormente adecuada de muestras para el entrenamiento del modelo.\n",
    "\n",
    "**Nota:** No se eligió la cantidad máxima posible de muestras de entrenamiento (40 muestras) como la más adecuada, puesto que ya existe un modelo base entrenado con dicha cantidad de muestras, por lo que en caso de considerar a 40 como la cantidad más adecuada de muestras para entrenamiento, se generaría otro modelo exactamente con el mismo comportamiento predictivo que el modelo base generado inicialmente, por lo cual, se optó por elegir una cantidad de muestras no igual a 40, pero sí bastante cercana a 40 como lo es 38 muestras, con la finalidad principal de evitar repetir el mismo modelo base creado en un inicio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9af9d",
   "metadata": {},
   "source": [
    "## Entrenamiento de nuevo modelo con la cantidad más adecuada de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df9ef64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación se procederá a crear y configurar otro modelo pero esta vez dicho modelo se entrenará con la\n",
    "# cantidad de muestras más adecuada determinada anteriormente (38 muestras)\n",
    "\n",
    "# Para el nuevo modelo a entrenar con 38 muestras, se pasará como argumento de entrada que dicho modelo tenga\n",
    "# una tasa de aprendizaje inicial (eta0) de 1e-04, además de un máximo de 750,000 iteraciones para su entrenamiento\n",
    "\n",
    "regresion_38 = SGDRegressor(eta0 = 1e-04, max_iter = 750000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5b45115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Celsius    Valks    \n",
       "-8.10020    74.2470     1\n",
       " 55.72000  -121.0900    1\n",
       " 33.08000  -56.9110     1\n",
       " 43.23600  -75.8350     1\n",
       " 45.51000  -87.1070     1\n",
       " 49.48300  -92.4120     1\n",
       " 49.90800  -108.5900    1\n",
       " 50.93600  -94.7800     1\n",
       " 55.46900  -115.0400    1\n",
       " 55.77400  -133.3800    1\n",
       "-7.30130    73.2690     1\n",
       " 56.55200  -129.8700    1\n",
       " 61.42800  -134.0700    1\n",
       " 64.91300  -142.0200    1\n",
       " 69.09000  -140.6400    1\n",
       " 71.57400  -150.5800    1\n",
       " 75.71700  -175.8300    1\n",
       " 75.92900  -166.9400    1\n",
       " 30.59600  -49.3740     1\n",
       " 29.83600  -41.7300     1\n",
       " 27.32900  -27.0320     1\n",
       " 26.93900  -34.2550     1\n",
       "-5.81140    66.3700     1\n",
       "-5.07060    64.1060     1\n",
       "-4.23870    61.9730     1\n",
       "-1.31270    54.2760     1\n",
       "-0.34047    51.1010     1\n",
       " 2.38120    42.1590     1\n",
       " 4.35250    36.2140     1\n",
       " 5.10840    35.1830     1\n",
       " 5.75080    31.9840     1\n",
       " 7.60250    25.0800     1\n",
       " 7.84980    24.6800     1\n",
       " 11.71000   16.1430     1\n",
       " 14.99800   1.3718      1\n",
       " 15.16600   8.7740      1\n",
       " 22.17600  -12.8820     1\n",
       " 75.94900  -174.9200    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear subset de entrenamiento de 38 muestras a partir del subconjunto de entrenamiento original de 40 muestras, utilizando\n",
    "# la función sample de los objetos de tipo dataframe para obtener una muestra aleatoria de 38 registros (filas) para el \n",
    "# entrenamiento del nuevo modelo\n",
    "\n",
    "# El parámetro de entrada n = 38 indica a la función sample que se tomen aleatoriamente \n",
    "# 38 elementos del subconjunto de datos de entrenamiento original de 40 muestras, mientras \n",
    "# que el parámetro replace = False señala a la función sample() que el muestreo de elementos\n",
    "# se realice sin reemplazo (sin elementos repetidos), mientras que el parámetro axis = 0 indica a\n",
    "# la función sample() que realice un muestreo de los registros del dataframe de entrenamiento,\n",
    "# por lo cual, el resultado será un dataframe de 38 registros aleatorios y no repetidos\n",
    "\n",
    "model38_train = datos_train.sample(n = 38, replace = False, axis = 0)\n",
    "\n",
    "# Verificar que ningún registro de la muestra de tamaño 38 esté repetido (la frecuencia absoluta de cada registro debe ser 1)\n",
    "\n",
    "model38_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fa63af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDRegressor(eta0=0.0001, max_iter=750000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el modelo nuevo con la muestra aleatoria de 38 registros obtenida previamente\n",
    "\n",
    "# Los datos en celsius del subconjunto de entrenamiento se convierten a un array de numpy y se\n",
    "# redimensionan para que tengan 2 dimensiones en vez de 1 y así sean aceptados por el método\n",
    "# fit()\n",
    "\n",
    "regresion_38.fit(model38_train[\"Celsius\"].to_numpy().reshape(-1, 1), model38_train[\"Valks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a68c2",
   "metadata": {},
   "source": [
    "### MSE del nuevo modelo sobre el subconjunto de entrenamiento, validación y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ef8943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar las predicciones de los valks del subconjunto de entrenamiento de 38 muestras utilzando el \n",
    "# nuevo modelo entrenado\n",
    "\n",
    "# Nuevamente, los datos de la variable predictora en la columna Celsius se convierten a un arreglo de\n",
    "# numpy y luego se reforma dicho arreglo para que sea de 2 dimensiones, lo cual es requerido por el \n",
    "# método predict()\n",
    "\n",
    "predicted_model38_train = regresion_38.predict(model38_train[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Calcular el error cuadrático medio MSE del modelo en el subconjunto de entrenamiento de 38 muestras\n",
    "\n",
    "MSE_model38_train = mean_squared_error(model38_train[\"Valks\"], predicted_model38_train)\n",
    "\n",
    "# Calcular las predicciones para los Valks del subconjunto de validación con el modelo entrenado con 38 muestras\n",
    "\n",
    "predicted_model38_validation = regresion_38.predict(validation[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Calcular MSE del modelo en el subconjunto de validación \n",
    "\n",
    "MSE_model38_validation = mean_squared_error(validation[\"Valks\"], predicted_model38_validation)\n",
    "\n",
    "# Calcular predicciones para los valks del subconjunto de prueba (test) con el modelo entrenado con 38 muestras\n",
    "\n",
    "predicted_model38_test = regresion_38.predict(test_definitivo[\"Celsius\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Calcular MSE del modelo en el subconjunto de prueba o test, entrenado con 38 muestras\n",
    "\n",
    "MSE_model38_test = mean_squared_error(test_definitivo[\"Valks\"], predicted_model38_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28839239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en el subconjunto de entrenamiento: 85.48710075245062\n"
     ]
    }
   ],
   "source": [
    "# Desplegar en pantalla el valor del MSE en el subconjunto de entrenamiento del modelo entrenado con 38 muestras\n",
    "\n",
    "print(f'MSE en el subconjunto de entrenamiento: {MSE_model38_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2085c4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en el subconjunto de validación: 111.815553626574\n"
     ]
    }
   ],
   "source": [
    "# Desplegar en pantalla el valor del MSE en el subconjunto de validación del modelo entrenado con 38 muestras\n",
    "\n",
    "print(f'MSE en el subconjunto de validación: {MSE_model38_validation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a3eadc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en el subconjunto de prueba/testing: 137.74389759394168\n"
     ]
    }
   ],
   "source": [
    "# Desplegar en pantalla el valor del MSE en el subconjunto de testing o prueba del modelo entrenado con 38 muestras\n",
    "\n",
    "print(f'MSE en el subconjunto de prueba/testing: {MSE_model38_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cc5aa",
   "metadata": {},
   "source": [
    "## Comparación de errores del modelo entrenado con 38 muestras y de los errores para la línea base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6c2c7",
   "metadata": {},
   "source": [
    "### Errores para la línea de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15a0b02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE para subconjunto de entrenamiento: 110.05915032672912\n",
      "MSE para subconjunto de validación: 149.39443502824105\n",
      "MSE para subconjunto de prueba: 167.74772561834524\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el valor del MSE para el subset de datos de entrenamiento\n",
    "\n",
    "print(f'MSE para subconjunto de entrenamiento: {MSE_train}')\n",
    "\n",
    "# Mostrar el valor del MSE para el subset de datos de validación\n",
    "\n",
    "print(f'MSE para subconjunto de validación: {MSE_validation}')\n",
    "\n",
    "# Mostrar el valor del MSE para el subset de datos de prueba\n",
    "\n",
    "print(f'MSE para subconjunto de prueba: {MSE_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b69b1e",
   "metadata": {},
   "source": [
    "### Errores del modelo entrenado con 38 muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f4ea7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE en el subconjunto de entrenamiento: 85.48710075245062\n",
      "MSE en el subconjunto de validación: 111.815553626574\n",
      "MSE en el subconjunto de prueba/testing: 137.74389759394168\n"
     ]
    }
   ],
   "source": [
    "# Desplegar en pantalla el valor del MSE en el subconjunto de entrenamiento del modelo entrenado con 38 muestras\n",
    "\n",
    "print(f'MSE en el subconjunto de entrenamiento: {MSE_model38_train}')\n",
    "\n",
    "# Desplegar en pantalla el valor del MSE en el subconjunto de validación del modelo entrenado con 38 muestras\n",
    "\n",
    "print(f'MSE en el subconjunto de validación: {MSE_model38_validation}')\n",
    "\n",
    "# Desplegar en pantalla el valor del MSE en el subconjunto de testing o prueba del modelo entrenado con 38 muestras\n",
    "\n",
    "print(f'MSE en el subconjunto de prueba/testing: {MSE_model38_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d4462",
   "metadata": {},
   "source": [
    "En base a los errores tanto del modelo base o línea de base y los errores del modelo entrenado con un total de 38 muestras, es posible observar que en relación a los errores en el subconjunto de entrenamiento, el error en el subconjunto de entrenamiento del modelo entrenado con 38 muestras resulta ser medianamente menor que el error en el subconjunto de entrenamiento de la línea base (modelo base), lo cual señala que el modelo entrenado con 38 muestras, posee un grado de sesgo medianamente más bajo que el modelo de la línea base, lo cual indica que las predicciones derivadas del modelo entrenado con 38 muestras, tienden a desviarse o alejarse en una proporción medianamente menor de los datos de entrenamiento reales de dicho modelo, por otro lado, el modelo de la línea base entrenado con las 40 muestras, posee el MSE más alto en su respectivo subconjunto de entrenamiento, por lo cual, éste modelo tiene el menor grado de precisión entre ambos modelos mencionados, junto con el mayor sesgo entre ambos modelos, por lo que las predicciones del modelo de la línea base estarán menos próximas a los datos reales de su subconjunto de entrenamiento correspondiente.\n",
    "\n",
    "Por otra parte, en cuanto al error MSE en el subconjunto de validación general creado inicialmente, el modelo de la línea base posee un MSE de 149.39, mientras que para el modelo entrenado con 38 muestras, dicho MSE de validación es igual a 111.81, por lo cual, en este caso, el modelo entrenado con 38 muestras tiene el MSE menor de ambos en el conjunto de validación general, lo cual significa que dicho modelo consiguió ajustar de la mejor manera sus hiperparámetros hasta el punto en el que tuvieran todos el mejor valor posible, lo cual se refleja en el hecho de que dicho modelo tenga el menor valor de MSE en el subconjunto general para la validación de los modelos, no obstante, por otro lado, aquel modelo que tiene el MSE mayor en el subconjunto de validación es el modelo de la línea base, lo cual indica que dicho modelo, no consiguió ajustar de la mejor manera, los valores de sus hiperparámetros con tal de ajustarse lo mejor posible a los datos reales, por lo cual, las predicciones derivadas del modelo de la línea base no tendrán el mayor grado de precisión posible entre ambos modelos mencionados, ya que el modelo base no tiene coeficientes que representan de la mejor forma posible la variabilidad de los datos originales, mientras que por el contrario, el modelo entrenado con 38 muestras, posee el ajuste más adecuado de sus hiperparámetros, lo cual conduce a que dicho modelo al momento de calcular las predicciones de los datos originales de entrada en grados celsius, los datos de salida en grados valks tengan un grado de precisión mucho mayor que los datos de salida en Valks predichos por el modelo de la línea base, por lo que nuevamente, el modelo de la línea base resulta arrojar predicciones de una menor calidad en cuanto a precisión y nivel de sesgo reducido en comparación con el modelo entrenado con 38 muestras. \n",
    "\n",
    "Por último, respecto a los errores MSE en el subconjunto de prueba general, se logra apreciar que el error MSE para el modelo de la línea base es igual a 167.74, mientras que al mismo tiempo, el error MSE en el subconjunto de prueba para el modelo entrenado con 38 muestras resulta ser igual a 137.74, por lo cual se evidencia que el modelo entrenado con 38 muestras nuevamente es el que tiene el menor error MSE, lo cual, en este contexto en particular, significa que dicho modelo presenta el nivel de rendimiento más alto de los dos modelos mencionados al momento de ponerlo a prueba para predecir los grados en valks a partir de los grados celsius, lo cual implica que ese mismo modelo, nuevamente posee el mayor grado de precisión en cuanto a las predicciones que calcula, por lo cual, las predicciones derivadas del mismo representan de la mejor forma posible a los datos reales en cuestión, lo cual indica que el modelo entrenado con 38 muestras es de una calidad medianamente mayor en cuanto a las predicciones que calcula, mientras que por el contrario, en el caso del modelo de la línea base, éste mismo es el modelo que a su vez posee el mayor MSE en el subconjunto de datos de prueba, lo cual indica que dicho modelo es el que aporta predicciones menos precisas entre ambos modelos descritos, por lo cual, el modelo de la línea base es de una calidad más baja que el modelo entrenado con 38 muestras, dado que el primero (modelo de la línea base) logra calcular predicciones que se aproximan en menor medida a los datos reales que se desean predecir, mientras que el modelo entrenado con 38 muestras aporta predicciones que al contrario, se acercan en su mayoría a los datos verdaderos a predecir, motivo por el cual, bajo este criterio, es mejor el modelo entrenado con 38 muestras para predecir las equivalencias en Valks de los datos en grados celsius reales de los cuales se desea saber los valores de sus equivalencias en valks de una forma altamente precisa y a la vez también altamente confiable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb46438",
   "metadata": {},
   "source": [
    "## Configuración que funcionó mejor y por qué"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04b7276",
   "metadata": {},
   "source": [
    "Finalmente, a manera de conclusión final de todo el análisis realizado con anterioridad, es posible concluir que de los 2 mejores modelos, mismos que fueron tanto el modelo de la línea base entrenado inicialmente junto con el modelo entrenado con 38 muestras, el modelo entrenado con 38 muestras resultó ser el aquel que tuvo la mejor configuración de los 2, la cual consistió en que se entrenara al modelo de regresión lineal con gradiente descendente estocástico con un parámetro eta0 (tasa de aprendizaje inicial del modelo) igual a 1e-04 (1 diezmilésima), además de una cantidad máxima de iteraciones igual a 750 mil, por lo cual, al momento de aplicar ésta configuración durante el entrenamiento del modelo entrenado con 38 muestras, se obtuvo un modelo con un mejor grado de rendimiento que el modelo de la línea base, además de que éste último modelo tiene una configuración con parámetros de eta0 = 1e-04 y número máximo de iteraciones igual a 1 millón, por lo cual, la primera configuración mencionada que corresponde al modelo entrenado con 38 muestras, fue aquella que funcionó mejor, principalmente debido a que a pesar de que ambos modelos tengan el mismo valor de la tasa de aprendizaje inicial (1e-04), su configuración difiere de forma mayormente significativa en cuanto al valor del parámetro max_iter (máximo número de iteraciones para entrenar el modelo) que tiene cada uno de los 2 modelos mencionados, ya que el modelo de la línea base tiene un máximo de iteraciones de 1 millón, mientras que el modelo entrenado con 38 muestras tiene un máximo de iteraciones igual a 750 mil, por lo cual se evidencia que de 1 modelo al otro, existe una diferencia altamente significativa en cuanto al máximo de iteraciones con el que fue entrenado dicho modelo, por lo cual, a pesar de que el modelo entrenado con 38 muestras tiene el menor número máximo de iteraciones, éste mismo fue capaz de recibir un mejor entrenamiento y como consecuencia, eso resultó en predicciones más precisas, sin embargo, el segundo modelo referente al de la línea base y con un máximo de 1 millón iteraciones, no logró arrojar predicciones con el mismo grado de precisión que el modelo entrenado con 38 muestras, motivo por el cual, eso es un indicativo de que no necesariamente a mayor número máximo de iteraciones, aumenta la probabilidad de que el modelo entrenado lleve a cabo un mejor proceso de entrenamiento y en consecuncia sus predicciones sean más precisas y se acerquen más a los datos reales, sino que más allá del número máximo de iteraciones para el entrenamiento de los modelos, la calidad de los datos de entrenamiento en base a los cuales se creen los modelos tiene más impacto en la calidad predictiva de los mismos, lo cual tiene sentido, ya que al configurar y entrenar un modelo con datos de entrenamiento de una mejor calidad, dicho modelo puede aprender de mejor manera los patrones o tendencias subyacentes a los datos que se desean predecir (datos reales), lo cual aunado al hecho de que dicho modelo tiene una tasa de aprendizaje bastante pequeña (aprende a un ritmo mayormente lento), además de un máximo grande de iteraciones, la combinación de esos 3 factores (máximo grande de iteraciones, tasa de aprendizaje muy pequeña y datos de entrenamiento de alta calidad) ocasiona que el modelo en cuestión, durante su proceso de entrenamiento que también tendrá una duración mayormente considerable, adquiera una mayor capacidad de aprender en primera instancia el patrón o tendencia que siguen los datos y posteriormente sea capaz de aplicar dicho aprendizaje para predecir el valor de nuevas instancias o datos que aún no conozca, lo cual es el objetivo ideal de un modelo predictivo, es decir, el ser capaz de generalizar su aprendizaje para predecir de manera acertada datos que nunca antes haya visto, por lo cual, en resumen, la configuración que tuvo el mejor funcionamiento fue aquella cuyo parámetro eta0 es igual a 1e-04 y a su vez, su máxima cantidad de iteraciones es igual a 750 mil porque de esa manera, el modelo tuvo mejores datos en cuanto a su calidad para aprender cómo es la naturaleza subyacente de los datos que se desean predecir, durante su etapa de entrenamiento, por lo que como resultado, el modelo entrenado con 38 muestras termina adquiriendo \"conocimientos\" adicionales sobre el patrón de los datos reales, que el segundo modelo referente al de la línea base entrenado con 40 muestras y 1 millón de iteraciones, no pudo adquirir debido a la calidad menor de los datos de entrenamiento que dicho modelo tuvo para aprender el patrón o tendencia que siguen los datos reales, lo cual explica la diferencia en la calidad de la capacidad predictiva de ambos modelos en el sentido de qué tanta precisión tienen sus predicciones y de su capacidad de generalizar el aprendizaje que adquirieron durante su entrenamiento para predecir la equivalencia en valks para datos en celsius que sean desconocidos para ambos modelos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
